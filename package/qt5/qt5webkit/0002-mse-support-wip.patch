From e0e5a686b11b9f7433c1e50e9a26aa13732bc8a8 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Tue, 4 Nov 2014 18:25:16 +0100
Subject: [PATCH 01/68] Declare more key systems as supported. (ClearKey and
 Youtube PR).

---
 .../platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp     | 6 +++++-
 1 file changed, 5 insertions(+), 1 deletion(-)

diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
index 7bb155a..a79abc4 100644
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
@@ -1644,10 +1644,14 @@ bool MediaPlayerPrivateGStreamer::supportsKeySystem(const String& keySystem, con
     GST_DEBUG ("Checking for KeySystem support with %s and type %s", keySystem.utf8().data(), mimeType.utf8().data());
 
 #if USE(DXDRM)
-    if (equalIgnoringCase(keySystem, "com.microsoft.playready"))
+    if (equalIgnoringCase(keySystem, "com.microsoft.playready") ||
+        equalIgnoringCase(keySystem, "com.youtube.playready"))
         return true;
 #endif
 
+    if (equalIgnoringCase(keySystem, "org.w3.clearkey"))
+        return true;
+
     return false;
 }
 

From 8972eb37403e4f8cd7a78c247ca2987e177394c9 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Mon, 10 Nov 2014 11:07:56 +0100
Subject: [PATCH 02/68] Add the MSE include dir when enabled

---
 Source/WebCore/WebCore.pri | 5 +++++
 1 file changed, 5 insertions(+)

diff --git a/Source/WebCore/WebCore.pri b/Source/WebCore/WebCore.pri
index 8628d95..1413376 100644
--- a/Source/WebCore/WebCore.pri
+++ b/Source/WebCore/WebCore.pri
@@ -197,6 +197,11 @@ enable?(ENCRYPTED_MEDIA_V2) {
     }
 }
 
+enable?(MEDIA_SOURCE) {
+    INCLUDEPATH += \
+        $$SOURCE_DIR/Modules/mediasource
+}
+
 use?(GLIB) {
     PKGCONFIG *= glib-2.0 gio-2.0
 }

From 367d7eec62d155be929ef6e0992dc15b7907f9ef Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Mon, 10 Nov 2014 11:08:28 +0100
Subject: [PATCH 03/68] Add missing function

---
 Source/WebCore/platform/qt/MIMETypeRegistryQt.cpp | 9 +++++++++
 1 file changed, 9 insertions(+)

diff --git a/Source/WebCore/platform/qt/MIMETypeRegistryQt.cpp b/Source/WebCore/platform/qt/MIMETypeRegistryQt.cpp
index 8d167c7..b5a097a 100644
--- a/Source/WebCore/platform/qt/MIMETypeRegistryQt.cpp
+++ b/Source/WebCore/platform/qt/MIMETypeRegistryQt.cpp
@@ -30,6 +30,7 @@
 #include "MIMETypeRegistry.h"
 
 #include <QMimeDatabase>
+#include "NotImplemented.h"
 #include <wtf/Assertions.h>
 #include <wtf/MainThread.h>
 
@@ -143,4 +144,12 @@ bool MIMETypeRegistry::isApplicationPluginMIMEType(const String& mimeType)
         || mimeType.startsWith("application/x-qt-styled-widget", false);
 }
 
+#if ENABLE(MEDIA_SOURCE)
+bool MIMETypeRegistry::isSupportedMediaSourceMIMEType(const String&, const String&)
+{
+    notImplemented();
+    return false;
+}
+#endif
+
 }

From 835bbfd6bef96bcd2effc2190351a839cf9137a9 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Mon, 10 Nov 2014 11:08:45 +0100
Subject: [PATCH 04/68] Use the correct interface

---
 Source/WebCore/Modules/mediasource/MediaSourceRegistry.cpp | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Source/WebCore/Modules/mediasource/MediaSourceRegistry.cpp b/Source/WebCore/Modules/mediasource/MediaSourceRegistry.cpp
index 1c62674..45459df 100644
--- a/Source/WebCore/Modules/mediasource/MediaSourceRegistry.cpp
+++ b/Source/WebCore/Modules/mediasource/MediaSourceRegistry.cpp
@@ -72,7 +72,7 @@ void MediaSourceRegistry::unregisterMediaSourceURL(const KURL& url)
 MediaSource* MediaSourceRegistry::lookupMediaSource(const String& url)
 {
     ASSERT(isMainThread());
-    return m_mediaSources.get(url).get();
+    return m_mediaSources.get(url);
 }
 
 } // namespace WebCore

From c854327f07a6c30070b25b6b4f26bf9ac6f0334b Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Wed, 12 Nov 2014 17:53:30 +0100
Subject: [PATCH 05/68] Start backporting

---
 Source/WTF/wtf/MediaTime.h                         |    4 +
 .../Modules/mediasource/AudioTrackMediaSource.h    |   47 +
 .../Modules/mediasource/AudioTrackMediaSource.idl  |   31 +
 .../Modules/mediasource/DOMURLMediaSource.cpp      |   54 +
 .../Modules/mediasource/DOMURLMediaSource.h        |   52 +
 .../Modules/mediasource/DOMURLMediaSource.idl      |   35 +
 Source/WebCore/Modules/mediasource/MediaSource.cpp |  843 ++++++++--
 Source/WebCore/Modules/mediasource/MediaSource.h   |  112 +-
 Source/WebCore/Modules/mediasource/MediaSource.idl |   25 +-
 Source/WebCore/Modules/mediasource/SampleMap.cpp   |  268 +++
 Source/WebCore/Modules/mediasource/SampleMap.h     |  131 ++
 .../WebCore/Modules/mediasource/SourceBuffer.cpp   | 1733 +++++++++++++++++++-
 Source/WebCore/Modules/mediasource/SourceBuffer.h  |  162 +-
 .../WebCore/Modules/mediasource/SourceBuffer.idl   |   21 +-
 .../Modules/mediasource/SourceBufferList.cpp       |   73 +-
 .../WebCore/Modules/mediasource/SourceBufferList.h |   50 +-
 .../Modules/mediasource/SourceBufferList.idl       |   19 +-
 .../Modules/mediasource/TextTrackMediaSource.h     |   46 +
 .../Modules/mediasource/TextTrackMediaSource.idl   |   31 +
 .../Modules/mediasource/VideoPlaybackQuality.cpp   |   45 +
 .../Modules/mediasource/VideoPlaybackQuality.h     |   57 +
 .../Modules/mediasource/VideoPlaybackQuality.idl   |   39 +
 .../Modules/mediasource/VideoTrackMediaSource.h    |   46 +
 .../Modules/mediasource/VideoTrackMediaSource.idl  |   30 +
 Source/WebCore/dom/EventNames.h                    |    8 +
 Source/WebCore/html/URLRegistry.h                  |   61 +
 Source/WebCore/platform/MediaDescription.h         |   45 +
 Source/WebCore/platform/MediaSample.h              |   78 +
 .../WebCore/platform/graphics/MediaSourcePrivate.h |   22 +-
 .../platform/graphics/MediaSourcePrivateClient.h   |   54 +
 .../platform/graphics/PlatformTimeRanges.cpp       |  271 +++
 .../WebCore/platform/graphics/PlatformTimeRanges.h |  130 ++
 .../platform/graphics/SourceBufferPrivateClient.h  |   94 ++
 33 files changed, 4378 insertions(+), 339 deletions(-)
 create mode 100644 Source/WebCore/Modules/mediasource/AudioTrackMediaSource.h
 create mode 100644 Source/WebCore/Modules/mediasource/AudioTrackMediaSource.idl
 create mode 100644 Source/WebCore/Modules/mediasource/DOMURLMediaSource.cpp
 create mode 100644 Source/WebCore/Modules/mediasource/DOMURLMediaSource.h
 create mode 100644 Source/WebCore/Modules/mediasource/DOMURLMediaSource.idl
 create mode 100644 Source/WebCore/Modules/mediasource/SampleMap.cpp
 create mode 100644 Source/WebCore/Modules/mediasource/SampleMap.h
 create mode 100644 Source/WebCore/Modules/mediasource/TextTrackMediaSource.h
 create mode 100644 Source/WebCore/Modules/mediasource/TextTrackMediaSource.idl
 create mode 100644 Source/WebCore/Modules/mediasource/VideoPlaybackQuality.cpp
 create mode 100644 Source/WebCore/Modules/mediasource/VideoPlaybackQuality.h
 create mode 100644 Source/WebCore/Modules/mediasource/VideoPlaybackQuality.idl
 create mode 100644 Source/WebCore/Modules/mediasource/VideoTrackMediaSource.h
 create mode 100644 Source/WebCore/Modules/mediasource/VideoTrackMediaSource.idl
 create mode 100644 Source/WebCore/html/URLRegistry.h
 create mode 100644 Source/WebCore/platform/MediaDescription.h
 create mode 100644 Source/WebCore/platform/MediaSample.h
 create mode 100644 Source/WebCore/platform/graphics/MediaSourcePrivateClient.h
 create mode 100644 Source/WebCore/platform/graphics/PlatformTimeRanges.cpp
 create mode 100644 Source/WebCore/platform/graphics/PlatformTimeRanges.h
 create mode 100644 Source/WebCore/platform/graphics/SourceBufferPrivateClient.h

diff --git a/Source/WTF/wtf/MediaTime.h b/Source/WTF/wtf/MediaTime.h
index 413b1a7..b452c8b 100644
--- a/Source/WTF/wtf/MediaTime.h
+++ b/Source/WTF/wtf/MediaTime.h
@@ -25,6 +25,8 @@
  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
  * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
+#ifndef WTF_MediaTime_h
+#define WTF_MediaTime_h
 
 #include "FastAllocBase.h"
 
@@ -107,3 +109,5 @@ WTF_EXPORT_PRIVATE extern MediaTime abs(const MediaTime& rhs);
 
 using WTF::MediaTime;
 using WTF::abs;
+
+#endif
diff --git a/Source/WebCore/Modules/mediasource/AudioTrackMediaSource.h b/Source/WebCore/Modules/mediasource/AudioTrackMediaSource.h
new file mode 100644
index 0000000..d9be811
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/AudioTrackMediaSource.h
@@ -0,0 +1,47 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+#ifndef AudioTrackMediaSource_h
+#define AudioTrackMediaSource_h
+
+#if ENABLE(MEDIA_SOURCE) && ENABLE(VIDEO_TRACK)
+
+#include "AudioTrack.h"
+
+namespace WebCore {
+
+class SourceBuffer;
+
+class AudioTrackMediaSource {
+public:
+    static SourceBuffer* sourceBuffer(AudioTrack* track) { return track->sourceBuffer(); }
+};
+
+}
+
+#endif
+
+
+#endif
diff --git a/Source/WebCore/Modules/mediasource/AudioTrackMediaSource.idl b/Source/WebCore/Modules/mediasource/AudioTrackMediaSource.idl
new file mode 100644
index 0000000..7142413
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/AudioTrackMediaSource.idl
@@ -0,0 +1,31 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+[
+    Conditional=MEDIA_SOURCE&VIDEO_TRACK,
+]
+partial interface AudioTrack {
+    readonly attribute SourceBuffer sourceBuffer;
+};
diff --git a/Source/WebCore/Modules/mediasource/DOMURLMediaSource.cpp b/Source/WebCore/Modules/mediasource/DOMURLMediaSource.cpp
new file mode 100644
index 0000000..2051274
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/DOMURLMediaSource.cpp
@@ -0,0 +1,54 @@
+/*
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "config.h"
+#include "DOMURLMediaSource.h"
+
+#if ENABLE(MEDIA_SOURCE)
+
+#include "DOMURL.h"
+#include "MediaSource.h"
+#include <wtf/MainThread.h>
+
+namespace WebCore {
+
+String DOMURLMediaSource::createObjectURL(ScriptExecutionContext* scriptExecutionContext, MediaSource* source)
+{
+    // Since WebWorkers cannot obtain MediaSource objects, we should be on the main thread.
+    ASSERT(isMainThread());
+
+    if (!scriptExecutionContext || !source)
+        return String();
+    return DOMURL::createPublicURL(scriptExecutionContext, source);
+}
+
+} // namespace WebCore
+
+#endif
diff --git a/Source/WebCore/Modules/mediasource/DOMURLMediaSource.h b/Source/WebCore/Modules/mediasource/DOMURLMediaSource.h
new file mode 100644
index 0000000..1eccd4b
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/DOMURLMediaSource.h
@@ -0,0 +1,52 @@
+/*
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef DOMURLMediaSource_h
+#define DOMURLMediaSource_h
+
+#if ENABLE(MEDIA_SOURCE)
+
+#include <wtf/Forward.h>
+
+namespace WebCore {
+
+class MediaSource;
+class ScriptExecutionContext;
+
+class DOMURLMediaSource {
+public:
+    static String createObjectURL(ScriptExecutionContext*, MediaSource*);
+};
+
+} // namespace WebCore
+
+#endif
+
+#endif
diff --git a/Source/WebCore/Modules/mediasource/DOMURLMediaSource.idl b/Source/WebCore/Modules/mediasource/DOMURLMediaSource.idl
new file mode 100644
index 0000000..d154397
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/DOMURLMediaSource.idl
@@ -0,0 +1,35 @@
+/*
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+[
+    Conditional=MEDIA_SOURCE
+]
+partial interface DOMURL {
+    [CallWith=ScriptExecutionContext,TreatReturnedNullStringAs=Null] static DOMString createObjectURL(MediaSource? source);
+};
diff --git a/Source/WebCore/Modules/mediasource/MediaSource.cpp b/Source/WebCore/Modules/mediasource/MediaSource.cpp
index ee63269..2b27a49 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.cpp
+++ b/Source/WebCore/Modules/mediasource/MediaSource.cpp
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2012 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -33,236 +33,679 @@
 
 #if ENABLE(MEDIA_SOURCE)
 
+#include "AudioTrack.h"
+#include "AudioTrackList.h"
 #include "ContentType.h"
 #include "Event.h"
+#include "ExceptionCode.h"
+#include "ExceptionCodePlaceholder.h"
+#include "GenericEventQueue.h"
+#include "HTMLMediaElement.h"
+#include "Logging.h"
 #include "MIMETypeRegistry.h"
+#include "MediaError.h"
+#include "MediaPlayer.h"
+#include "MediaSourceRegistry.h"
 #include "SourceBufferPrivate.h"
+#include "TextTrack.h"
+#include "TextTrackList.h"
 #include "TimeRanges.h"
+#include "VideoTrack.h"
+#include "VideoTrackList.h"
 #include <wtf/Uint8Array.h>
+#include <wtf/text/CString.h>
+#include <wtf/text/WTFString.h>
 
 namespace WebCore {
 
-PassRefPtr<MediaSource> MediaSource::create(ScriptExecutionContext* context)
+URLRegistry* MediaSource::s_registry = 0;
+
+void MediaSource::setRegistry(URLRegistry* registry)
+{
+    ASSERT(!s_registry);
+    s_registry = registry;
+}
+
+PassRefPtr<MediaSource> MediaSource::create(ScriptExecutionContext& context)
 {
     RefPtr<MediaSource> mediaSource(adoptRef(new MediaSource(context)));
     mediaSource->suspendIfNeeded();
     return mediaSource.release();
 }
 
-MediaSource::MediaSource(ScriptExecutionContext* context)
-    : ActiveDOMObject(context)
+MediaSource::MediaSource(ScriptExecutionContext& context)
+    : ActiveDOMObject(&context)
+    , m_mediaElement(0)
+    , m_duration(MediaTime::invalidTime())
+    , m_pendingSeekTime(MediaTime::invalidTime())
     , m_readyState(closedKeyword())
     , m_asyncEventQueue(GenericEventQueue::create(this))
 {
-    m_sourceBuffers = SourceBufferList::create(scriptExecutionContext(), m_asyncEventQueue.get());
-    m_activeSourceBuffers = SourceBufferList::create(scriptExecutionContext(), m_asyncEventQueue.get());
+    LOG(MediaSource, "MediaSource::MediaSource %p", this);
+    m_sourceBuffers = SourceBufferList::create(scriptExecutionContext());
+    m_activeSourceBuffers = SourceBufferList::create(scriptExecutionContext());
 }
 
-const String& MediaSource::openKeyword()
+MediaSource::~MediaSource()
 {
-    DEFINE_STATIC_LOCAL(const String, open, (ASCIILiteral("open")));
+    LOG(MediaSource, "MediaSource::~MediaSource %p", this);
+    ASSERT(isClosed());
+}
+
+const AtomicString& MediaSource::openKeyword()
+{
+    DEFINE_STATIC_LOCAL(const AtomicString, open, ("open", AtomicString::ConstructFromLiteral));
     return open;
 }
 
-const String& MediaSource::closedKeyword()
+const AtomicString& MediaSource::closedKeyword()
 {
-    DEFINE_STATIC_LOCAL(const String, closed, (ASCIILiteral("closed")));
+    DEFINE_STATIC_LOCAL(const AtomicString, closed, ("closed", AtomicString::ConstructFromLiteral));
     return closed;
 }
 
-const String& MediaSource::endedKeyword()
+const AtomicString& MediaSource::endedKeyword()
 {
-    DEFINE_STATIC_LOCAL(const String, ended, (ASCIILiteral("ended")));
+    DEFINE_STATIC_LOCAL(const AtomicString, ended, ("ended", AtomicString::ConstructFromLiteral));
     return ended;
 }
 
-SourceBufferList* MediaSource::sourceBuffers()
+void MediaSource::setPrivateAndOpen(PassOwnPtr<MediaSourcePrivate> mediaSourcePrivate)
 {
-    return m_sourceBuffers.get();
+    ASSERT(!m_private);
+    ASSERT(m_mediaElement);
+    m_private = WTF::move(mediaSourcePrivate);
+    setReadyState(openKeyword());
 }
 
-SourceBufferList* MediaSource::activeSourceBuffers()
+void MediaSource::addedToRegistry()
 {
-    // FIXME(91649): support track selection
-    return m_activeSourceBuffers.get();
+    setPendingActivity(this);
 }
 
-double MediaSource::duration() const
+void MediaSource::removedFromRegistry()
 {
-    return m_readyState == closedKeyword() ? std::numeric_limits<float>::quiet_NaN() : m_private->duration();
+    unsetPendingActivity(this);
 }
 
-void MediaSource::setDuration(double duration, ExceptionCode& ec)
+MediaTime MediaSource::duration() const
 {
-    if (duration < 0.0 || std::isnan(duration)) {
-        ec = INVALID_ACCESS_ERR;
-        return;
+    return m_duration;
+}
+
+MediaTime MediaSource::currentTime() const
+{
+    return m_mediaElement ? m_mediaElement->currentMediaTime() : MediaTime::zeroTime();
+}
+
+PassOwnPtr<PlatformTimeRanges> MediaSource::buffered() const
+{
+    // Implements MediaSource algorithm for HTMLMediaElement.buffered.
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#htmlmediaelement-extensions
+    Vector<PlatformTimeRanges> activeRanges = this->activeRanges();
+
+    // 1. If activeSourceBuffers.length equals 0 then return an empty TimeRanges object and abort these steps.
+    if (activeRanges.isEmpty())
+        return PlatformTimeRanges::create();
+
+    // 2. Let active ranges be the ranges returned by buffered for each SourceBuffer object in activeSourceBuffers.
+    // 3. Let highest end time be the largest range end time in the active ranges.
+    MediaTime highestEndTime = MediaTime::zeroTime();
+    for (auto& ranges : activeRanges) {
+        unsigned length = ranges.length();
+        if (length)
+            highestEndTime = std::max(highestEndTime, ranges.end(length - 1));
     }
-    if (m_readyState != openKeyword()) {
-        ec = INVALID_STATE_ERR;
-        return;
+
+    // Return an empty range if all ranges are empty.
+    if (!highestEndTime)
+        return PlatformTimeRanges::create();
+
+    // 4. Let intersection ranges equal a TimeRange object containing a single range from 0 to highest end time.
+    PlatformTimeRanges intersectionRanges(MediaTime::zeroTime(), highestEndTime);
+
+    // 5. For each SourceBuffer object in activeSourceBuffers run the following steps:
+    bool ended = readyState() == endedKeyword();
+    for (auto& sourceRanges : activeRanges) {
+        // 5.1 Let source ranges equal the ranges returned by the buffered attribute on the current SourceBuffer.
+        // 5.2 If readyState is "ended", then set the end time on the last range in source ranges to highest end time.
+        if (ended && sourceRanges.length())
+            sourceRanges.add(sourceRanges.start(sourceRanges.length() - 1), highestEndTime);
+
+        // 5.3 Let new intersection ranges equal the the intersection between the intersection ranges and the source ranges.
+        // 5.4 Replace the ranges in intersection ranges with the new intersection ranges.
+        intersectionRanges.intersectWith(sourceRanges);
     }
-    m_private->setDuration(duration);
+
+    return PlatformTimeRanges::create(intersectionRanges);
 }
 
-SourceBuffer* MediaSource::addSourceBuffer(const String& type, ExceptionCode& ec)
+void MediaSource::seekToTime(const MediaTime& time)
 {
-    // 3.1 http://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#dom-addsourcebuffer
-    // 1. If type is null or an empty then throw an INVALID_ACCESS_ERR exception and
-    // abort these steps.
-    if (type.isNull() || type.isEmpty()) {
-        ec = INVALID_ACCESS_ERR;
-        return 0;
+    // 2.4.3 Seeking
+    // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#mediasource-seeking
+
+    m_pendingSeekTime = time;
+
+    // Run the following steps as part of the "Wait until the user agent has established whether or not the
+    // media data for the new playback position is available, and, if it is, until it has decoded enough data
+    // to play back that position" step of the seek algorithm:
+    // 1. The media element looks for media segments containing the new playback position in each SourceBuffer
+    // object in activeSourceBuffers.
+    for (auto& sourceBuffer : *m_activeSourceBuffers) {
+        // ↳ If one or more of the objects in activeSourceBuffers is missing media segments for the new
+        // playback position
+        if (!sourceBuffer->buffered()->ranges().contain(time)) {
+            // 1.1 Set the HTMLMediaElement.readyState attribute to HAVE_METADATA.
+            m_private->setReadyState(MediaPlayer::HaveMetadata);
+
+            // 1.2 The media element waits until an appendBuffer() or an appendStream() call causes the coded
+            // frame processing algorithm to set the HTMLMediaElement.readyState attribute to a value greater
+            // than HAVE_METADATA.
+            LOG(MediaSource, "MediaSource::seekToTime(%p) - waitForSeekCompleted()", this);
+            m_private->waitForSeekCompleted();
+            return;
+        }
+        // ↳ Otherwise
+        // Continue
     }
 
-    // 2. If type contains a MIME type that is not supported ..., then throw a
-    // NOT_SUPPORTED_ERR exception and abort these steps.
-    if (!isTypeSupported(type)) {
-        ec = NOT_SUPPORTED_ERR;
-        return 0;
+    completeSeek();
+}
+
+void MediaSource::completeSeek()
+{
+    // 2.4.3 Seeking, ctd.
+    // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#mediasource-seeking
+
+    ASSERT(m_pendingSeekTime.isValid());
+
+    // 2. The media element resets all decoders and initializes each one with data from the appropriate
+    // initialization segment.
+    // 3. The media element feeds coded frames from the active track buffers into the decoders starting
+    // with the closest random access point before the new playback position.
+    for (auto& sourceBuffer : *m_activeSourceBuffers)
+        sourceBuffer->seekToTime(m_pendingSeekTime);
+
+    // 4. Resume the seek algorithm at the "Await a stable state" step.
+    m_private->seekCompleted();
+
+    m_pendingSeekTime = MediaTime::invalidTime();
+    monitorSourceBuffers();
+}
+
+void MediaSource::monitorSourceBuffers()
+{
+    // 2.4.4 SourceBuffer Monitoring
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#buffer-monitoring
+
+    // Note, the behavior if activeSourceBuffers is empty is undefined.
+    if (!m_activeSourceBuffers) {
+        m_private->setReadyState(MediaPlayer::HaveNothing);
+        return;
     }
 
-    // 4. If the readyState attribute is not in the "open" state then throw an
-    // INVALID_STATE_ERR exception and abort these steps.
-    if (!m_private || m_readyState != openKeyword()) {
-        ec = INVALID_STATE_ERR;
-        return 0;
+    // ↳ If buffered for all objects in activeSourceBuffers do not contain TimeRanges for the current
+    // playback position:
+    auto begin = m_activeSourceBuffers->begin();
+    auto end = m_activeSourceBuffers->end();
+    if (std::all_of(begin, end, [](RefPtr<SourceBuffer>& sourceBuffer) {
+        return !sourceBuffer->hasCurrentTime();
+    })) {
+        // 1. Set the HTMLMediaElement.readyState attribute to HAVE_METADATA.
+        // 2. If this is the first transition to HAVE_METADATA, then queue a task to fire a simple event
+        // named loadedmetadata at the media element.
+        m_private->setReadyState(MediaPlayer::HaveMetadata);
+
+        // 3. Abort these steps.
+        return;
     }
 
-    // 5. Create a new SourceBuffer object and associated resources.
-    ContentType contentType(type);
-    Vector<String> codecs = contentType.codecs();
-    OwnPtr<SourceBufferPrivate> sourceBufferPrivate;
-    switch (m_private->addSourceBuffer(contentType.type(), codecs, &sourceBufferPrivate)) {
-    case MediaSourcePrivate::Ok: {
-        ASSERT(sourceBufferPrivate);
-        RefPtr<SourceBuffer> buffer = SourceBuffer::create(sourceBufferPrivate.release(), this);
-
-        // 6. Add the new object to sourceBuffers and fire a addsourcebuffer on that object.
-        m_sourceBuffers->add(buffer);
-        m_activeSourceBuffers->add(buffer);
-        // 7. Return the new object to the caller.
-        return buffer.get();
+    // ↳ If buffered for all objects in activeSourceBuffers contain TimeRanges that include the current
+    // playback position and enough data to ensure uninterrupted playback:
+    if (std::all_of(begin, end, [](RefPtr<SourceBuffer>& sourceBuffer) {
+        return sourceBuffer->hasFutureTime() && sourceBuffer->canPlayThrough();
+    })) {
+        // 1. Set the HTMLMediaElement.readyState attribute to HAVE_ENOUGH_DATA.
+        // 2. Queue a task to fire a simple event named canplaythrough at the media element.
+        // 3. Playback may resume at this point if it was previously suspended by a transition to HAVE_CURRENT_DATA.
+        m_private->setReadyState(MediaPlayer::HaveEnoughData);
+
+        if (m_pendingSeekTime.isValid())
+            completeSeek();
+
+        // 4. Abort these steps.
+        return;
     }
-    case MediaSourcePrivate::NotSupported:
-        // 2 (cont). If type contains a MIME type ... that is not supported with the types 
-        // specified for the other SourceBuffer objects in sourceBuffers, then throw
-        // a NOT_SUPPORTED_ERR exception and abort these steps.
-        ec = NOT_SUPPORTED_ERR;
-        return 0;
-    case MediaSourcePrivate::ReachedIdLimit:
-        // 3 (cont). If the user agent can't handle any more SourceBuffer objects then throw 
-        // a QUOTA_EXCEEDED_ERR exception and abort these steps.
-        ec = QUOTA_EXCEEDED_ERR;
-        return 0;
+
+    // ↳ If buffered for all objects in activeSourceBuffers contain a TimeRange that includes
+    // the current playback position and some time beyond the current playback position, then run the following steps:
+    if (std::all_of(begin, end, [](RefPtr<SourceBuffer>& sourceBuffer) {
+        return sourceBuffer->hasFutureTime();
+    })) {
+        // 1. Set the HTMLMediaElement.readyState attribute to HAVE_FUTURE_DATA.
+        // 2. If the previous value of HTMLMediaElement.readyState was less than HAVE_FUTURE_DATA, then queue a task to fire a simple event named canplay at the media element.
+        // 3. Playback may resume at this point if it was previously suspended by a transition to HAVE_CURRENT_DATA.
+        m_private->setReadyState(MediaPlayer::HaveFutureData);
+
+        if (m_pendingSeekTime.isValid())
+            completeSeek();
+
+        // 4. Abort these steps.
+        return;
     }
 
-    ASSERT_NOT_REACHED();
-    return 0;
+    // ↳ If buffered for at least one object in activeSourceBuffers contains a TimeRange that ends
+    // at the current playback position and does not have a range covering the time immediately
+    // after the current position:
+    // NOTE: Logically, !(all objects do not contain currentTime) == (some objects contain current time)
+
+    // 1. Set the HTMLMediaElement.readyState attribute to HAVE_CURRENT_DATA.
+    // 2. If this is the first transition to HAVE_CURRENT_DATA, then queue a task to fire a simple
+    // event named loadeddata at the media element.
+    // 3. Playback is suspended at this point since the media element doesn't have enough data to
+    // advance the media timeline.
+    m_private->setReadyState(MediaPlayer::HaveCurrentData);
+
+    if (m_pendingSeekTime.isValid())
+        completeSeek();
+
+    // 4. Abort these steps.
 }
 
-void MediaSource::removeSourceBuffer(SourceBuffer* buffer, ExceptionCode& ec)
+void MediaSource::setDuration(double duration, ExceptionCode& ec)
 {
-    // 3.1 http://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#dom-removesourcebuffer
-    // 1. If sourceBuffer is null then throw an INVALID_ACCESS_ERR exception and
-    // abort these steps.
-    if (!buffer) {
+    // 2.1 Attributes - Duration
+    // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#attributes
+
+    // On setting, run the following steps:
+    // 1. If the value being set is negative or NaN then throw an INVALID_ACCESS_ERR exception and abort these steps.
+    if (duration < 0.0 || std::isnan(duration)) {
         ec = INVALID_ACCESS_ERR;
         return;
     }
 
-    // 2. If sourceBuffers is empty then throw an INVALID_STATE_ERR exception and
-    // abort these steps.
-    if (!m_private || !m_sourceBuffers->length()) {
+    // 2. If the readyState attribute is not "open" then throw an INVALID_STATE_ERR exception and abort these steps.
+    if (!isOpen()) {
         ec = INVALID_STATE_ERR;
         return;
     }
 
-    // 3. If sourceBuffer specifies an object that is not in sourceBuffers then
-    // throw a NOT_FOUND_ERR exception and abort these steps.
-    // 6. Remove sourceBuffer from sourceBuffers and fire a removesourcebuffer event
-    // on that object.
-    if (!m_sourceBuffers->remove(buffer)) {
-        ec = NOT_FOUND_ERR;
-        return;
+    // 3. If the updating attribute equals true on any SourceBuffer in sourceBuffers, then throw an INVALID_STATE_ERR
+    // exception and abort these steps.
+    for (auto& sourceBuffer : *m_sourceBuffers) {
+        if (sourceBuffer->updating()) {
+            ec = INVALID_STATE_ERR;
+            return;
+        }
     }
 
-    // 7. Destroy all resources for sourceBuffer.
-    m_activeSourceBuffers->remove(buffer);
-
-    // 4. Remove track information from audioTracks, videoTracks, and textTracks for all tracks 
-    // associated with sourceBuffer and fire a simple event named change on the modified lists.
-    // FIXME(91649): support track selection
-
-    // 5. If sourceBuffer is in activeSourceBuffers, then remove it from that list and fire a
-    // removesourcebuffer event on that object.
-    // FIXME(91649): support track selection
+    // 4. Run the duration change algorithm with new duration set to the value being assigned to this attribute.
+    setDurationInternal(MediaTime::createWithDouble(duration));
 }
 
-const String& MediaSource::readyState() const
+void MediaSource::setDurationInternal(const MediaTime& duration)
 {
-    return m_readyState;
+    // Duration Change Algorithm
+    // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#duration-change-algorithm
+
+    // 1. If the current value of duration is equal to new duration, then return.
+    if (duration == m_duration)
+        return;
+
+    // 2. Set old duration to the current value of duration.
+    MediaTime oldDuration = m_duration;
+
+    // 3. Update duration to new duration.
+    m_duration = duration;
+
+    // 4. If the new duration is less than old duration, then call remove(new duration, old duration)
+    // on all objects in sourceBuffers.
+    if (oldDuration.isValid() && duration < oldDuration) {
+        for (auto& sourceBuffer : *m_sourceBuffers)
+            sourceBuffer->remove(duration, oldDuration, IGNORE_EXCEPTION);
+    }
+
+    // 5. If a user agent is unable to partially render audio frames or text cues that start before and end after the
+    // duration, then run the following steps:
+    // 5.1 Update new duration to the highest end time reported by the buffered attribute across all SourceBuffer objects
+    // in sourceBuffers.
+    // 5.2 Update duration to new duration.
+    // NOTE: Assume UA is able to partially render audio frames.
+
+    // 6. Update the media controller duration to new duration and run the HTMLMediaElement duration change algorithm.
+    LOG(MediaSource, "MediaSource::setDurationInternal(%p) - duration(%g)", this, duration.toDouble());
+    m_private->durationChanged();
 }
 
-void MediaSource::setReadyState(const String& state)
+void MediaSource::setReadyState(const AtomicString& state)
 {
     ASSERT(state == openKeyword() || state == closedKeyword() || state == endedKeyword());
-    if (m_readyState == state)
+
+    AtomicString oldState = readyState();
+    LOG(MediaSource, "MediaSource::setReadyState(%p) : %s -> %s", this, oldState.string().ascii().data(), state.string().ascii().data());
+
+    if (state == closedKeyword()) {
+        m_private.clear();
+        m_mediaElement = 0;
+        m_duration = MediaTime::invalidTime();
+    }
+
+    if (oldState == state)
         return;
 
-    String oldState = m_readyState;
     m_readyState = state;
 
-    if (m_readyState == closedKeyword()) {
-        m_sourceBuffers->clear();
-        m_activeSourceBuffers->clear();
-        m_private.clear();
-        scheduleEvent(eventNames().webkitsourcecloseEvent);
+    onReadyStateChange(oldState, state);
+}
+
+static bool SourceBufferIsUpdating(RefPtr<SourceBuffer>& sourceBuffer)
+{
+    return sourceBuffer->updating();
+}
+
+void MediaSource::endOfStream(ExceptionCode& ec)
+{
+    endOfStream(emptyAtom, ec);
+}
+
+void MediaSource::endOfStream(const AtomicString& error, ExceptionCode& ec)
+{
+    // 2.2 https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#widl-MediaSource-endOfStream-void-EndOfStreamError-error
+    // 1. If the readyState attribute is not in the "open" state then throw an
+    // INVALID_STATE_ERR exception and abort these steps.
+    if (!isOpen()) {
+        ec = INVALID_STATE_ERR;
         return;
     }
 
-    if (oldState == openKeyword() && m_readyState == endedKeyword()) {
-        scheduleEvent(eventNames().webkitsourceendedEvent);
+    // 2. If the updating attribute equals true on any SourceBuffer in sourceBuffers, then throw an
+    // INVALID_STATE_ERR exception and abort these steps.
+    if (std::any_of(m_sourceBuffers->begin(), m_sourceBuffers->end(), SourceBufferIsUpdating)) {
+        ec = INVALID_STATE_ERR;
         return;
     }
 
-    if (m_readyState == openKeyword()) {
-        scheduleEvent(eventNames().webkitsourceopenEvent);
-        return;
+    // 3. Run the end of stream algorithm with the error parameter set to error.
+    streamEndedWithError(error, ec);
+}
+
+void MediaSource::streamEndedWithError(const AtomicString& error, ExceptionCode& ec)
+{
+    DEFINE_STATIC_LOCAL(const AtomicString, network, ("network", AtomicString::ConstructFromLiteral));
+    DEFINE_STATIC_LOCAL(const AtomicString, decode, ("decode", AtomicString::ConstructFromLiteral));
+
+    LOG(MediaSource, "MediaSource::streamEndedWithError(%p) : %s", this, error.string().ascii().data());
+
+    // 2.4.7 https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#end-of-stream-algorithm
+
+    // 3.
+    if (error.isEmpty()) {
+        // ↳ If error is not set, is null, or is an empty string
+        // 1. Run the duration change algorithm with new duration set to the highest end time reported by
+        // the buffered attribute across all SourceBuffer objects in sourceBuffers.
+        MediaTime maxEndTime;
+        for (auto& sourceBuffer : *m_sourceBuffers) {
+            if (auto length = sourceBuffer->buffered()->length())
+                maxEndTime = std::max(sourceBuffer->buffered()->ranges().end(length - 1), maxEndTime);
+        }
+        setDurationInternal(maxEndTime);
+
+        // 2. Notify the media element that it now has all of the media data.
+        m_private->markEndOfStream(MediaSourcePrivate::EosNoError);
+    }
+
+    // NOTE: Do steps 1 & 2 after step 3 (with an empty error) to avoid the MediaSource's readyState being re-opened by a
+    // remove() operation resulting from a duration change.
+    // FIXME: Re-number or update this section once <https://www.w3.org/Bugs/Public/show_bug.cgi?id=26316> is resolved.
+    // 1. Change the readyState attribute value to "ended".
+    // 2. Queue a task to fire a simple event named sourceended at the MediaSource.
+    setReadyState(endedKeyword());
+
+    if (error == network) {
+        // ↳ If error is set to "network"
+        ASSERT(m_mediaElement);
+        if (m_mediaElement->readyState() == HTMLMediaElement::HAVE_NOTHING) {
+            //  ↳ If the HTMLMediaElement.readyState attribute equals HAVE_NOTHING
+            //    Run the "If the media data cannot be fetched at all, due to network errors, causing
+            //    the user agent to give up trying to fetch the resource" steps of the resource fetch algorithm.
+            //    NOTE: This step is handled by HTMLMediaElement::mediaLoadingFailed().
+            m_mediaElement->mediaLoadingFailed(MediaPlayer::NetworkError);
+        } else {
+            //  ↳ If the HTMLMediaElement.readyState attribute is greater than HAVE_NOTHING
+            //    Run the "If the connection is interrupted after some media data has been received, causing the
+            //    user agent to give up trying to fetch the resource" steps of the resource fetch algorithm.
+            //    NOTE: This step is handled by HTMLMediaElement::mediaLoadingFailedFatally().
+            m_mediaElement->mediaLoadingFailedFatally(MediaPlayer::NetworkError);
+        }
+    } else if (error == decode) {
+        // ↳ If error is set to "decode"
+        ASSERT(m_mediaElement);
+        if (m_mediaElement->readyState() == HTMLMediaElement::HAVE_NOTHING) {
+            //  ↳ If the HTMLMediaElement.readyState attribute equals HAVE_NOTHING
+            //    Run the "If the media data can be fetched but is found by inspection to be in an unsupported
+            //    format, or can otherwise not be rendered at all" steps of the resource fetch algorithm.
+            //    NOTE: This step is handled by HTMLMediaElement::mediaLoadingFailed().
+            m_mediaElement->mediaLoadingFailed(MediaPlayer::FormatError);
+        } else {
+            //  ↳ If the HTMLMediaElement.readyState attribute is greater than HAVE_NOTHING
+            //    Run the media data is corrupted steps of the resource fetch algorithm.
+            //    NOTE: This step is handled by HTMLMediaElement::mediaLoadingFailedFatally().
+            m_mediaElement->mediaLoadingFailedFatally(MediaPlayer::DecodeError);
+        }
+    } else if (!error.isEmpty()) {
+        // ↳ Otherwise
+        //   Throw an INVALID_ACCESS_ERR exception.
+        ec = INVALID_ACCESS_ERR;
     }
 }
 
-void MediaSource::endOfStream(const String& error, ExceptionCode& ec)
+SourceBuffer* MediaSource::addSourceBuffer(const String& type, ExceptionCode& ec)
 {
-    // 3.1 http://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#dom-endofstream
-    // 1. If the readyState attribute is not in the "open" state then throw an
+    LOG(MediaSource, "MediaSource::addSourceBuffer(%s) %p", type.ascii().data(), this);
+
+    // 2.2 https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-MediaSource-addSourceBuffer-SourceBuffer-DOMString-type
+    // 1. If type is null or an empty then throw an INVALID_ACCESS_ERR exception and
+    // abort these steps.
+    if (type.isNull() || type.isEmpty()) {
+        ec = INVALID_ACCESS_ERR;
+        return nullptr;
+    }
+
+    // 2. If type contains a MIME type that is not supported ..., then throw a
+    // NOT_SUPPORTED_ERR exception and abort these steps.
+    if (!isTypeSupported(type)) {
+        ec = NOT_SUPPORTED_ERR;
+        return nullptr;
+    }
+
+    // 4. If the readyState attribute is not in the "open" state then throw an
     // INVALID_STATE_ERR exception and abort these steps.
-    if (!m_private || m_readyState != openKeyword()) {
+    if (!isOpen()) {
         ec = INVALID_STATE_ERR;
-        return;
+        return nullptr;
+    }
+
+    // 5. Create a new SourceBuffer object and associated resources.
+    ContentType contentType(type);
+    RefPtr<SourceBufferPrivate> sourceBufferPrivate = createSourceBufferPrivate(contentType, ec);
+
+    if (!sourceBufferPrivate) {
+        ASSERT(ec == NOT_SUPPORTED_ERR || ec == QUOTA_EXCEEDED_ERR);
+        // 2. If type contains a MIME type that is not supported ..., then throw a NOT_SUPPORTED_ERR exception and abort these steps.
+        // 3. If the user agent can't handle any more SourceBuffer objects then throw a QUOTA_EXCEEDED_ERR exception and abort these steps
+        return nullptr;
     }
 
-    MediaSourcePrivate::EndOfStreamStatus eosStatus = MediaSourcePrivate::EosNoError;
+    RefPtr<SourceBuffer> buffer = SourceBuffer::create(sourceBufferPrivate.releaseNonNull(), this);
+    // 6. Add the new object to sourceBuffers and fire a addsourcebuffer on that object.
+    m_sourceBuffers->add(buffer);
+    regenerateActiveSourceBuffers();
+
+    // 7. Return the new object to the caller.
+    return buffer.get();
+}
+
+void MediaSource::removeSourceBuffer(SourceBuffer* buffer, ExceptionCode& ec)
+{
+    LOG(MediaSource, "MediaSource::removeSourceBuffer() %p", this);
+    RefPtr<SourceBuffer> protect(buffer);
 
-    if (error.isNull() || error.isEmpty())
-        eosStatus = MediaSourcePrivate::EosNoError;
-    else if (error == "network")
-        eosStatus = MediaSourcePrivate::EosNetworkError;
-    else if (error == "decode")
-        eosStatus = MediaSourcePrivate::EosDecodeError;
-    else {
+    // 2.2 https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-MediaSource-removeSourceBuffer-void-SourceBuffer-sourceBuffer
+    // 1. If sourceBuffer is null then throw an INVALID_ACCESS_ERR exception and
+    // abort these steps.
+    if (!buffer) {
         ec = INVALID_ACCESS_ERR;
         return;
     }
 
-    // 2. Change the readyState attribute value to "ended".
-    setReadyState(endedKeyword());
-    m_private->endOfStream(eosStatus);
+    // 2. If sourceBuffer specifies an object that is not in sourceBuffers then
+    // throw a NOT_FOUND_ERR exception and abort these steps.
+    if (!m_sourceBuffers->length() || !m_sourceBuffers->contains(buffer)) {
+        ec = NOT_FOUND_ERR;
+        return;
+    }
+
+    // 3. If the sourceBuffer.updating attribute equals true, then run the following steps: ...
+    buffer->abortIfUpdating();
+
+    // 4. Let SourceBuffer audioTracks list equal the AudioTrackList object returned by sourceBuffer.audioTracks.
+    RefPtr<AudioTrackList> audioTracks = buffer->audioTracks();
+
+    // 5. If the SourceBuffer audioTracks list is not empty, then run the following steps:
+    if (audioTracks->length()) {
+        // 5.1 Let HTMLMediaElement audioTracks list equal the AudioTrackList object returned by the audioTracks
+        // attribute on the HTMLMediaElement.
+        // 5.2 Let the removed enabled audio track flag equal false.
+        bool removedEnabledAudioTrack = false;
+
+        // 5.3 For each AudioTrack object in the SourceBuffer audioTracks list, run the following steps:
+        while (audioTracks->length()) {
+            AudioTrack* track = audioTracks->lastItem();
+
+            // 5.3.1 Set the sourceBuffer attribute on the AudioTrack object to null.
+            track->setSourceBuffer(0);
+
+            // 5.3.2 If the enabled attribute on the AudioTrack object is true, then set the removed enabled
+            // audio track flag to true.
+            if (track->enabled())
+                removedEnabledAudioTrack = true;
+
+            // 5.3.3 Remove the AudioTrack object from the HTMLMediaElement audioTracks list.
+            // 5.3.4 Queue a task to fire a trusted event named removetrack, that does not bubble and is not
+            // cancelable, and that uses the TrackEvent interface, at the HTMLMediaElement audioTracks list.
+            if (mediaElement())
+                mediaElement()->removeAudioTrack(track);
+
+            // 5.3.5 Remove the AudioTrack object from the SourceBuffer audioTracks list.
+            // 5.3.6 Queue a task to fire a trusted event named removetrack, that does not bubble and is not
+            // cancelable, and that uses the TrackEvent interface, at the SourceBuffer audioTracks list.
+            audioTracks->remove(track);
+        }
+
+        // 5.4 If the removed enabled audio track flag equals true, then queue a task to fire a simple event
+        // named change at the HTMLMediaElement audioTracks list.
+        if (removedEnabledAudioTrack)
+            mediaElement()->audioTracks()->scheduleChangeEvent();
+    }
+
+    // 6. Let SourceBuffer videoTracks list equal the VideoTrackList object returned by sourceBuffer.videoTracks.
+    RefPtr<VideoTrackList> videoTracks = buffer->videoTracks();
+
+    // 7. If the SourceBuffer videoTracks list is not empty, then run the following steps:
+    if (videoTracks->length()) {
+        // 7.1 Let HTMLMediaElement videoTracks list equal the VideoTrackList object returned by the videoTracks
+        // attribute on the HTMLMediaElement.
+        // 7.2 Let the removed selected video track flag equal false.
+        bool removedSelectedVideoTrack = false;
+
+        // 7.3 For each VideoTrack object in the SourceBuffer videoTracks list, run the following steps:
+        while (videoTracks->length()) {
+            VideoTrack* track = videoTracks->lastItem();
+
+            // 7.3.1 Set the sourceBuffer attribute on the VideoTrack object to null.
+            track->setSourceBuffer(0);
+
+            // 7.3.2 If the selected attribute on the VideoTrack object is true, then set the removed selected
+            // video track flag to true.
+            if (track->selected())
+                removedSelectedVideoTrack = true;
+
+            // 7.3.3 Remove the VideoTrack object from the HTMLMediaElement videoTracks list.
+            // 7.3.4 Queue a task to fire a trusted event named removetrack, that does not bubble and is not
+            // cancelable, and that uses the TrackEvent interface, at the HTMLMediaElement videoTracks list.
+            if (mediaElement())
+                mediaElement()->removeVideoTrack(track);
+
+            // 7.3.5 Remove the VideoTrack object from the SourceBuffer videoTracks list.
+            // 7.3.6 Queue a task to fire a trusted event named removetrack, that does not bubble and is not
+            // cancelable, and that uses the TrackEvent interface, at the SourceBuffer videoTracks list.
+            videoTracks->remove(track);
+        }
+
+        // 7.4 If the removed selected video track flag equals true, then queue a task to fire a simple event
+        // named change at the HTMLMediaElement videoTracks list.
+        if (removedSelectedVideoTrack)
+            mediaElement()->videoTracks()->scheduleChangeEvent();
+    }
+
+    // 8. Let SourceBuffer textTracks list equal the TextTrackList object returned by sourceBuffer.textTracks.
+    RefPtr<TextTrackList> textTracks = buffer->textTracks();
+
+    // 9. If the SourceBuffer textTracks list is not empty, then run the following steps:
+    if (textTracks->length()) {
+        // 9.1 Let HTMLMediaElement textTracks list equal the TextTrackList object returned by the textTracks
+        // attribute on the HTMLMediaElement.
+        // 9.2 Let the removed enabled text track flag equal false.
+        bool removedEnabledTextTrack = false;
+
+        // 9.3 For each TextTrack object in the SourceBuffer textTracks list, run the following steps:
+        while (textTracks->length()) {
+            TextTrack* track = textTracks->lastItem();
+
+            // 9.3.1 Set the sourceBuffer attribute on the TextTrack object to null.
+            track->setSourceBuffer(0);
+
+            // 9.3.2 If the mode attribute on the TextTrack object is set to "showing" or "hidden", then
+            // set the removed enabled text track flag to true.
+            if (track->mode() == TextTrack::showingKeyword() || track->mode() == TextTrack::hiddenKeyword())
+                removedEnabledTextTrack = true;
+
+            // 9.3.3 Remove the TextTrack object from the HTMLMediaElement textTracks list.
+            // 9.3.4 Queue a task to fire a trusted event named removetrack, that does not bubble and is not
+            // cancelable, and that uses the TrackEvent interface, at the HTMLMediaElement textTracks list.
+            if (mediaElement())
+                mediaElement()->removeTextTrack(track);
+
+            // 9.3.5 Remove the TextTrack object from the SourceBuffer textTracks list.
+            // 9.3.6 Queue a task to fire a trusted event named removetrack, that does not bubble and is not
+            // cancelable, and that uses the TrackEvent interface, at the SourceBuffer textTracks list.
+            textTracks->remove(track);
+        }
+        
+        // 9.4 If the removed enabled text track flag equals true, then queue a task to fire a simple event
+        // named change at the HTMLMediaElement textTracks list.
+        if (removedEnabledTextTrack)
+            mediaElement()->textTracks()->scheduleChangeEvent();
+    }
+    
+    
+    // 10. If sourceBuffer is in activeSourceBuffers, then remove sourceBuffer from activeSourceBuffers ...
+    m_activeSourceBuffers->remove(buffer);
+    
+    // 11. Remove sourceBuffer from sourceBuffers and fire a removesourcebuffer event
+    // on that object.
+    m_sourceBuffers->remove(buffer);
+    
+    // 12. Destroy all resources for sourceBuffer.
+    buffer->removedFromMediaSource();
 }
 
 bool MediaSource::isTypeSupported(const String& type)
 {
-    // Section 2.1 isTypeSupported() method steps.
+    LOG(MediaSource, "MediaSource::isTypeSupported(%s)", type.ascii().data());
+
+    // Section 2.2 isTypeSupported() method steps.
     // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#widl-MediaSource-isTypeSupported-boolean-DOMString-type
     // 1. If type is an empty string, then return false.
     if (type.isNull() || type.isEmpty())
@@ -279,59 +722,163 @@ bool MediaSource::isTypeSupported(const String& type)
     // 4. If type contains at a codec that the MediaSource does not support, then return false.
     // 5. If the MediaSource does not support the specified combination of media type, media subtype, and codecs then return false.
     // 6. Return true.
-    return MIMETypeRegistry::isSupportedMediaSourceMIMEType(contentType.type(), codecs);
+    MediaEngineSupportParameters parameters;
+    parameters.type = contentType.type();
+    parameters.codecs = codecs;
+    parameters.isMediaSource = true;
+    return MediaPlayer::supportsType(parameters, 0) != MediaPlayer::IsNotSupported;
 }
 
-void MediaSource::setPrivateAndOpen(PassOwnPtr<MediaSourcePrivate> mediaSourcePrivate)
+bool MediaSource::isOpen() const
 {
-    ASSERT(mediaSourcePrivate);
-    ASSERT(!m_private);
-    m_private = mediaSourcePrivate;
-    setReadyState(openKeyword());
+    return readyState() == openKeyword();
 }
 
-const AtomicString& MediaSource::interfaceName() const
+bool MediaSource::isClosed() const
 {
-    return eventNames().interfaceForMediaSource;
+    return readyState() == closedKeyword();
 }
 
-ScriptExecutionContext* MediaSource::scriptExecutionContext() const
+bool MediaSource::isEnded() const
 {
-    return ActiveDOMObject::scriptExecutionContext();
+    return readyState() == endedKeyword();
+}
+
+void MediaSource::close()
+{
+    setReadyState(closedKeyword());
+}
+
+void MediaSource::sourceBufferDidChangeAcitveState(SourceBuffer*, bool)
+{
+    regenerateActiveSourceBuffers();
+}
+
+bool MediaSource::attachToElement(HTMLMediaElement* element)
+{
+    if (m_mediaElement)
+        return false;
+
+    ASSERT(isClosed());
+
+    m_mediaElement = element;
+    return true;
+}
+
+void MediaSource::openIfInEndedState()
+{
+    if (m_readyState != endedKeyword())
+        return;
+
+    setReadyState(openKeyword());
+    m_private->unmarkEndOfStream();
 }
 
 bool MediaSource::hasPendingActivity() const
 {
-    return m_private || m_asyncEventQueue->hasPendingEvents()
+    return m_private || m_asyncEventQueue.hasPendingEvents()
         || ActiveDOMObject::hasPendingActivity();
 }
 
 void MediaSource::stop()
 {
+    m_asyncEventQueue.close();
+    if (!isClosed())
+        setReadyState(closedKeyword());
     m_private.clear();
-    m_asyncEventQueue->cancelAllEvents();
 }
 
-EventTargetData* MediaSource::eventTargetData()
+void MediaSource::onReadyStateChange(const AtomicString& oldState, const AtomicString& newState)
 {
-    return &m_eventTargetData;
+    if (isOpen()) {
+        scheduleEvent(eventNames().sourceopenEvent);
+        return;
+    }
+
+    if (oldState == openKeyword() && newState == endedKeyword()) {
+        scheduleEvent(eventNames().sourceendedEvent);
+        return;
+    }
+
+    ASSERT(isClosed());
+
+    m_activeSourceBuffers->clear();
+
+    // Clear SourceBuffer references to this object.
+    for (unsigned long i = 0, length =  m_sourceBuffers->length(); i < length; ++i)
+        m_sourceBuffers->item(i)->removedFromMediaSource();
+    m_sourceBuffers->clear();
+    
+    scheduleEvent(eventNames().sourcecloseEvent);
 }
 
-EventTargetData* MediaSource::ensureEventTargetData()
+Vector<PlatformTimeRanges> MediaSource::activeRanges() const
 {
-    return &m_eventTargetData;
+    Vector<PlatformTimeRanges> activeRanges;
+    for (auto& sourceBuffer : *m_activeSourceBuffers)
+        activeRanges.append(sourceBuffer->buffered()->ranges());
+    return activeRanges;
 }
 
-void MediaSource::scheduleEvent(const AtomicString& eventName)
+RefPtr<SourceBufferPrivate> MediaSource::createSourceBufferPrivate(const ContentType& type, ExceptionCode& ec)
 {
-    ASSERT(m_asyncEventQueue);
+    RefPtr<SourceBufferPrivate> sourceBufferPrivate;
+    switch (m_private->addSourceBuffer(type, sourceBufferPrivate)) {
+    case MediaSourcePrivate::Ok: {
+        return sourceBufferPrivate;
+    }
+    case MediaSourcePrivate::NotSupported:
+        // 2.2 https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-MediaSource-addSourceBuffer-SourceBuffer-DOMString-type
+        // Step 2: If type contains a MIME type ... that is not supported with the types
+        // specified for the other SourceBuffer objects in sourceBuffers, then throw
+        // a NOT_SUPPORTED_ERR exception and abort these steps.
+        ec = NOT_SUPPORTED_ERR;
+        return nullptr;
+    case MediaSourcePrivate::ReachedIdLimit:
+        // 2.2 https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-MediaSource-addSourceBuffer-SourceBuffer-DOMString-type
+        // Step 3: If the user agent can't handle any more SourceBuffer objects then throw
+        // a QUOTA_EXCEEDED_ERR exception and abort these steps.
+        ec = QUOTA_EXCEEDED_ERR;
+        return nullptr;
+    }
 
+    ASSERT_NOT_REACHED();
+    return nullptr;
+}
+
+void MediaSource::scheduleEvent(const AtomicString& eventName)
+{
     RefPtr<Event> event = Event::create(eventName, false, false);
     event->setTarget(this);
 
-    m_asyncEventQueue->enqueueEvent(event.release());
+    m_asyncEventQueue.enqueueEvent(event.release());
 }
 
-} // namespace WebCore
+ScriptExecutionContext* MediaSource::scriptExecutionContext() const
+{
+    return ActiveDOMObject::scriptExecutionContext();
+}
+
+EventTargetInterface MediaSource::eventTargetInterface() const
+{
+    return MediaSourceEventTargetInterfaceType;
+}
+
+URLRegistry& MediaSource::registry() const
+{
+    return MediaSourceRegistry::registry();
+}
+
+void MediaSource::regenerateActiveSourceBuffers()
+{
+    Vector<RefPtr<SourceBuffer>> newList;
+    for (auto& sourceBuffer : *m_sourceBuffers) {
+        if (sourceBuffer->active())
+            newList.append(sourceBuffer);
+    }
+    m_activeSourceBuffers->swap(newList);
+}
+
+}
 
 #endif
diff --git a/Source/WebCore/Modules/mediasource/MediaSource.h b/Source/WebCore/Modules/mediasource/MediaSource.h
index 1dbcd0e..6a0e18e 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.h
+++ b/Source/WebCore/Modules/mediasource/MediaSource.h
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2012 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -34,70 +34,118 @@
 #if ENABLE(MEDIA_SOURCE)
 
 #include "ActiveDOMObject.h"
+#include "EventTarget.h"
 #include "GenericEventQueue.h"
 #include "MediaSourcePrivate.h"
+#include "MediaSourcePrivateClient.h"
+#include "ScriptWrappable.h"
 #include "SourceBuffer.h"
 #include "SourceBufferList.h"
+#include "URLRegistry.h"
 #include <wtf/RefCounted.h>
+#include <wtf/Vector.h>
 
 namespace WebCore {
 
-class MediaSource : public RefCounted<MediaSource>, public EventTarget, public ActiveDOMObject {
+class GenericEventQueue;
+
+class MediaSource : public MediaSourcePrivateClient, public ActiveDOMObject, public EventTarget, public ScriptWrappable, public URLRegistrable {
 public:
-    static const String& openKeyword();
-    static const String& closedKeyword();
-    static const String& endedKeyword();
+    static void setRegistry(URLRegistry*);
+    static MediaSource* lookup(const String& url) { return s_registry ? static_cast<MediaSource*>(s_registry->lookup(url)) : 0; }
+
+    static const AtomicString& openKeyword();
+    static const AtomicString& closedKeyword();
+    static const AtomicString& endedKeyword();
+
+    static PassRefPtr<MediaSource> create(ScriptExecutionContext&);
+    virtual ~MediaSource();
+
+    void addedToRegistry();
+    void removedFromRegistry();
+    void openIfInEndedState();
+    bool isOpen() const;
+    bool isClosed() const;
+    bool isEnded() const;
+    void sourceBufferDidChangeAcitveState(SourceBuffer*, bool);
+    void streamEndedWithError(const AtomicString& error, ExceptionCode&);
+
+    // MediaSourcePrivateClient
+    virtual void setPrivateAndOpen(PassOwnPtr<MediaSourcePrivate>) OVERRIDE;
+    virtual MediaTime duration() const;
+    virtual PassOwnPtr<PlatformTimeRanges> buffered() const;
+    virtual void seekToTime(const MediaTime&);
+
+    bool attachToElement(HTMLMediaElement*);
+    void close();
+    void monitorSourceBuffers();
+    bool isSeeking() const { return m_pendingSeekTime.isValid(); }
+    void completeSeek();
+
+    void setDuration(double, ExceptionCode&);
+    void setDurationInternal(const MediaTime&);
+    MediaTime currentTime() const;
+    const AtomicString& readyState() const { return m_readyState; }
+    void setReadyState(const AtomicString&);
+    void endOfStream(ExceptionCode&);
+    void endOfStream(const AtomicString& error, ExceptionCode&);
 
-    static PassRefPtr<MediaSource> create(ScriptExecutionContext*);
-    virtual ~MediaSource() { }
+    HTMLMediaElement* mediaElement() const { return m_mediaElement; }
 
     // MediaSource.idl methods
-    SourceBufferList* sourceBuffers();
-    SourceBufferList* activeSourceBuffers();
-    double duration() const;
-    void setDuration(double, ExceptionCode&);
+    SourceBufferList* sourceBuffers() { return m_sourceBuffers.get(); }
+    SourceBufferList* activeSourceBuffers() { return m_activeSourceBuffers.get(); }
     SourceBuffer* addSourceBuffer(const String& type, ExceptionCode&);
     void removeSourceBuffer(SourceBuffer*, ExceptionCode&);
-    const String& readyState() const;
-    void setReadyState(const String&);
-    void endOfStream(const String& error, ExceptionCode&);
     static bool isTypeSupported(const String& type);
 
-    void setPrivateAndOpen(PassOwnPtr<MediaSourcePrivate>);
+    // ActiveDOMObject interface
+    virtual bool hasPendingActivity() const;
+    virtual void stop();
 
     // EventTarget interface
     virtual const AtomicString& interfaceName() const OVERRIDE;
-    virtual ScriptExecutionContext* scriptExecutionContext() const OVERRIDE;
+    virtual ScriptExecutionContext* scriptExecutionContext() const;
+    virtual void refEventTarget() { ref(); }
+    virtual void derefEventTarget() { deref(); }
 
-    // ActiveDOMObject interface
-    virtual bool hasPendingActivity() const OVERRIDE;
-    virtual void stop() OVERRIDE;
-
-    using RefCounted<MediaSource>::ref;
-    using RefCounted<MediaSource>::deref;
+    // URLRegistrable interface
+    virtual URLRegistry& registry() const;
 
-private:
-    explicit MediaSource(ScriptExecutionContext*);
+    using RefCounted<MediaSourcePrivateClient>::ref;
+    using RefCounted<MediaSourcePrivateClient>::deref;
 
-    virtual EventTargetData* eventTargetData() OVERRIDE;
-    virtual EventTargetData* ensureEventTargetData() OVERRIDE;
+protected:
+    explicit MediaSource(ScriptExecutionContext&);
 
-    virtual void refEventTarget() OVERRIDE { ref(); }
-    virtual void derefEventTarget() OVERRIDE { deref(); }
+    void onReadyStateChange(const AtomicString& oldState, const AtomicString& newState);
+    Vector<PlatformTimeRanges> activeRanges() const;
 
+    RefPtr<SourceBufferPrivate> createSourceBufferPrivate(const ContentType&, ExceptionCode&);
     void scheduleEvent(const AtomicString& eventName);
 
-    EventTargetData m_eventTargetData;
+    void regenerateActiveSourceBuffers();
 
-    String m_readyState;
-    OwnPtr<MediaSourcePrivate> m_private;
+    static URLRegistry* s_registry;
 
+    RefPtr<MediaSourcePrivate> m_private;
     RefPtr<SourceBufferList> m_sourceBuffers;
     RefPtr<SourceBufferList> m_activeSourceBuffers;
+    HTMLMediaElement* m_mediaElement;
+    MediaTime m_duration;
+    MediaTime m_pendingSeekTime;
+    AtomicString m_readyState;
     OwnPtr<GenericEventQueue> m_asyncEventQueue;
+
+private:
+    virtual EventTargetData* eventTargetData() OVERRIDE;
+    virtual EventTargetData* ensureEventTargetData() OVERRIDE;
+
+    EventTargetData m_eventTargetData;
 };
 
-} // namespace WebCore
+}
 
 #endif
+
 #endif
diff --git a/Source/WebCore/Modules/mediasource/MediaSource.idl b/Source/WebCore/Modules/mediasource/MediaSource.idl
index 7b04347..56f284f 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.idl
+++ b/Source/WebCore/Modules/mediasource/MediaSource.idl
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2012 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -28,14 +28,21 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  */
  
+enum EndOfStreamError {
+    "network",
+    "decode"
+};
+
 [
     Conditional=MEDIA_SOURCE,
     ActiveDOMObject,
     EventTarget,
+    EnabledBySetting=MediaSource,
+    JSGenerateToJSObject,
+    JSGenerateToNativeObject,
     Constructor,
     ConstructorCallWith=ScriptExecutionContext,
-    InterfaceName=WebKitMediaSource
-] interface MediaSource {
+] interface MediaSource : EventTarget {
     // All the source buffers created by this object.
     readonly attribute SourceBufferList sourceBuffers;
 
@@ -49,17 +56,7 @@
 
     readonly attribute DOMString readyState;
     
-    [RaisesException] void endOfStream([Default=NullString] optional DOMString error);
+    [RaisesException] void endOfStream(optional EndOfStreamError error);
 
     static boolean isTypeSupported (DOMString type);
-
-    // EventTarget interface
-    void addEventListener(DOMString type,
-                          EventListener listener,
-                          optional boolean useCapture);
-    void removeEventListener(DOMString type,
-                             EventListener listener,
-                             optional boolean useCapture);
-    [RaisesException] boolean dispatchEvent(Event event);
 };
-
diff --git a/Source/WebCore/Modules/mediasource/SampleMap.cpp b/Source/WebCore/Modules/mediasource/SampleMap.cpp
new file mode 100644
index 0000000..a8731c1
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/SampleMap.cpp
@@ -0,0 +1,268 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS''
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
+ * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "config.h"
+#include "SampleMap.h"
+
+#if ENABLE(MEDIA_SOURCE)
+
+#include "MediaSample.h"
+
+namespace WebCore {
+
+template <typename M>
+class SampleIsLessThanMediaTimeComparator {
+public:
+    typedef typename M::value_type value_type;
+    bool operator()(const value_type& value, const MediaTime& time)
+    {
+        MediaTime presentationEndTime = value.second->presentationTime() + value.second->duration();
+        return presentationEndTime <= time;
+    }
+    bool operator()(const MediaTime& time, const value_type& value)
+    {
+        MediaTime presentationStartTime = value.second->presentationTime();
+        return time < presentationStartTime;
+    }
+};
+
+template <typename M>
+class SampleIsGreaterThanMediaTimeComparator {
+public:
+    typedef typename M::value_type value_type;
+    bool operator()(const value_type& value, const MediaTime& time)
+    {
+        MediaTime presentationStartTime = value.second->presentationTime();
+        return presentationStartTime > time;
+    }
+    bool operator()(const MediaTime& time, const value_type& value)
+    {
+        MediaTime presentationEndTime = value.second->presentationTime() + value.second->duration();
+        return time >= presentationEndTime;
+    }
+};
+
+class SampleIsRandomAccess {
+public:
+    bool operator()(DecodeOrderSampleMap::MapType::value_type& value)
+    {
+        return value.second->flags() == MediaSample::IsSync;
+    }
+};
+
+// SamplePresentationTimeIsInsideRangeComparator matches (range.first, range.second]
+struct SamplePresentationTimeIsInsideRangeComparator {
+    bool operator()(std::pair<MediaTime, MediaTime> range, const std::pair<MediaTime, RefPtr<MediaSample>>& value)
+    {
+        return range.second < value.first;
+    }
+    bool operator()(const std::pair<MediaTime, RefPtr<MediaSample>>& value, std::pair<MediaTime, MediaTime> range)
+    {
+        return value.first <= range.first;
+    }
+};
+
+// SamplePresentationTimeIsWithinRangeComparator matches [range.first, range.second)
+struct SamplePresentationTimeIsWithinRangeComparator {
+    bool operator()(std::pair<MediaTime, MediaTime> range, const std::pair<MediaTime, RefPtr<MediaSample>>& value)
+    {
+        return range.second <= value.first;
+    }
+    bool operator()(const std::pair<MediaTime, RefPtr<MediaSample>>& value, std::pair<MediaTime, MediaTime> range)
+    {
+        return value.first < range.first;
+    }
+};
+
+bool SampleMap::empty() const
+{
+    return presentationOrder().m_samples.empty();
+}
+
+void SampleMap::clear()
+{
+    presentationOrder().m_samples.clear();
+    decodeOrder().m_samples.clear();
+    m_totalSize = 0;
+}
+
+void SampleMap::addSample(PassRefPtr<MediaSample> prpSample)
+{
+    RefPtr<MediaSample> sample = prpSample;
+    ASSERT(sample);
+
+    MediaTime presentationTime = sample->presentationTime();
+
+    presentationOrder().m_samples.insert(PresentationOrderSampleMap::MapType::value_type(presentationTime, sample));
+
+    auto decodeKey = DecodeOrderSampleMap::KeyType(sample->decodeTime(), presentationTime);
+    decodeOrder().m_samples.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, sample));
+
+    m_totalSize += sample->sizeInBytes();
+}
+
+void SampleMap::removeSample(MediaSample* sample)
+{
+    ASSERT(sample);
+    MediaTime presentationTime = sample->presentationTime();
+
+    presentationOrder().m_samples.erase(presentationTime);
+
+    auto decodeKey = DecodeOrderSampleMap::KeyType(sample->decodeTime(), presentationTime);
+    decodeOrder().m_samples.erase(decodeKey);
+
+    m_totalSize -= sample->sizeInBytes();
+}
+
+PresentationOrderSampleMap::iterator PresentationOrderSampleMap::findSampleWithPresentationTime(const MediaTime& time)
+{
+    auto range = m_samples.equal_range(time);
+    if (range.first == range.second)
+        return end();
+    return range.first;
+}
+
+PresentationOrderSampleMap::iterator PresentationOrderSampleMap::findSampleContainingPresentationTime(const MediaTime& time)
+{
+    auto range = std::equal_range(begin(), end(), time, SampleIsLessThanMediaTimeComparator<MapType>());
+    if (range.first == range.second)
+        return end();
+    return range.first;
+}
+
+PresentationOrderSampleMap::iterator PresentationOrderSampleMap::findSampleOnOrAfterPresentationTime(const MediaTime& time)
+{
+    return m_samples.lower_bound(time);
+}
+
+DecodeOrderSampleMap::iterator DecodeOrderSampleMap::findSampleWithDecodeKey(const KeyType& key)
+{
+    return m_samples.find(key);
+}
+
+PresentationOrderSampleMap::reverse_iterator PresentationOrderSampleMap::reverseFindSampleContainingPresentationTime(const MediaTime& time)
+{
+    auto range = std::equal_range(rbegin(), rend(), time, SampleIsGreaterThanMediaTimeComparator<MapType>());
+    if (range.first == range.second)
+        return rend();
+    return range.first;
+}
+
+PresentationOrderSampleMap::reverse_iterator PresentationOrderSampleMap::reverseFindSampleBeforePresentationTime(const MediaTime& time)
+{
+    return std::lower_bound(rbegin(), rend(), time, SampleIsGreaterThanMediaTimeComparator<MapType>());
+}
+
+DecodeOrderSampleMap::reverse_iterator DecodeOrderSampleMap::reverseFindSampleWithDecodeKey(const KeyType& key)
+{
+    DecodeOrderSampleMap::iterator found = findSampleWithDecodeKey(key);
+    if (found == end())
+        return rend();
+    return --reverse_iterator(found);
+}
+
+DecodeOrderSampleMap::reverse_iterator DecodeOrderSampleMap::findSyncSamplePriorToPresentationTime(const MediaTime& time, const MediaTime& threshold)
+{
+    PresentationOrderSampleMap::reverse_iterator reverseCurrentSamplePTS = m_presentationOrder.reverseFindSampleBeforePresentationTime(time);
+    if (reverseCurrentSamplePTS == m_presentationOrder.rend())
+        return rend();
+
+    const RefPtr<MediaSample>& sample = reverseCurrentSamplePTS->second;
+    reverse_iterator reverseCurrentSampleDTS = reverseFindSampleWithDecodeKey(KeyType(sample->decodeTime(), sample->presentationTime()));
+
+    reverse_iterator foundSample = findSyncSamplePriorToDecodeIterator(reverseCurrentSampleDTS);
+    if (foundSample == rend())
+        return rend();
+    if (foundSample->second->presentationTime() < time - threshold)
+        return rend();
+    return foundSample;
+}
+
+DecodeOrderSampleMap::reverse_iterator DecodeOrderSampleMap::findSyncSamplePriorToDecodeIterator(reverse_iterator iterator)
+{
+    return std::find_if(iterator, rend(), SampleIsRandomAccess());
+}
+
+DecodeOrderSampleMap::iterator DecodeOrderSampleMap::findSyncSampleAfterPresentationTime(const MediaTime& time, const MediaTime& threshold)
+{
+    PresentationOrderSampleMap::iterator currentSamplePTS = m_presentationOrder.findSampleOnOrAfterPresentationTime(time);
+    if (currentSamplePTS == m_presentationOrder.end())
+        return end();
+
+    const RefPtr<MediaSample>& sample = currentSamplePTS->second;
+    iterator currentSampleDTS = findSampleWithDecodeKey(KeyType(sample->decodeTime(), sample->presentationTime()));
+    
+    MediaTime upperBound = time + threshold;
+    iterator foundSample = std::find_if(currentSampleDTS, end(), SampleIsRandomAccess());
+    if (foundSample == end())
+        return end();
+    if (foundSample->second->presentationTime() > upperBound)
+        return end();
+    return foundSample;
+}
+
+DecodeOrderSampleMap::iterator DecodeOrderSampleMap::findSyncSampleAfterDecodeIterator(iterator currentSampleDTS)
+{
+    if (currentSampleDTS == end())
+        return end();
+    return std::find_if(++currentSampleDTS, end(), SampleIsRandomAccess());
+}
+
+PresentationOrderSampleMap::iterator_range PresentationOrderSampleMap::findSamplesBetweenPresentationTimes(const MediaTime& beginTime, const MediaTime& endTime)
+{
+    std::pair<MediaTime, MediaTime> range(beginTime, endTime);
+    return std::equal_range(begin(), end(), range, SamplePresentationTimeIsInsideRangeComparator());
+}
+
+PresentationOrderSampleMap::iterator_range PresentationOrderSampleMap::findSamplesWithinPresentationRange(const MediaTime& beginTime, const MediaTime& endTime)
+{
+    std::pair<MediaTime, MediaTime> range(beginTime, endTime);
+    return std::equal_range(begin(), end(), range, SamplePresentationTimeIsWithinRangeComparator());
+}
+
+PresentationOrderSampleMap::iterator_range PresentationOrderSampleMap::findSamplesWithinPresentationRangeFromEnd(const MediaTime& beginTime, const MediaTime& endTime)
+{
+    reverse_iterator rangeEnd = std::find_if(rbegin(), rend(), [&beginTime] (PresentationOrderSampleMap::MapType::value_type value) {
+        return value.second->presentationTime() <= beginTime;
+    });
+
+    reverse_iterator rangeStart = std::find_if(rbegin(), rangeEnd, [&endTime] (PresentationOrderSampleMap::MapType::value_type value) {
+        return value.second->presentationTime() <= endTime;
+    });
+
+    return iterator_range(rangeStart.base(), rangeEnd.base());
+}
+
+DecodeOrderSampleMap::reverse_iterator_range DecodeOrderSampleMap::findDependentSamples(MediaSample* sample)
+{
+    ASSERT(sample);
+    reverse_iterator currentDecodeIter = reverseFindSampleWithDecodeKey(KeyType(sample->decodeTime(), sample->presentationTime()));
+    reverse_iterator nextSyncSample = findSyncSamplePriorToDecodeIterator(currentDecodeIter);
+    return reverse_iterator_range(currentDecodeIter, nextSyncSample);
+}
+
+}
+
+#endif
diff --git a/Source/WebCore/Modules/mediasource/SampleMap.h b/Source/WebCore/Modules/mediasource/SampleMap.h
new file mode 100644
index 0000000..348bdb1
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/SampleMap.h
@@ -0,0 +1,131 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS''
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
+ * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef SampleMap_h
+#define SampleMap_h
+
+#if ENABLE(MEDIA_SOURCE)
+
+#include <map>
+#include <wtf/MediaTime.h>
+#include <wtf/RefPtr.h>
+
+namespace WebCore {
+
+class MediaSample;
+class SampleMap;
+
+class PresentationOrderSampleMap {
+    friend class SampleMap;
+public:
+    typedef std::map<MediaTime, RefPtr <MediaSample> > MapType;
+    typedef MapType::iterator iterator;
+    typedef MapType::reverse_iterator reverse_iterator;
+    typedef std::pair<iterator, iterator> iterator_range;
+
+    iterator begin() { return m_samples.begin(); }
+    iterator end() { return m_samples.end(); }
+    reverse_iterator rbegin() { return m_samples.rbegin(); }
+    reverse_iterator rend() { return m_samples.rend(); }
+
+    iterator findSampleWithPresentationTime(const MediaTime&);
+    iterator findSampleContainingPresentationTime(const MediaTime&);
+    iterator findSampleOnOrAfterPresentationTime(const MediaTime&);
+    reverse_iterator reverseFindSampleContainingPresentationTime(const MediaTime&);
+    reverse_iterator reverseFindSampleBeforePresentationTime(const MediaTime&);
+    iterator_range findSamplesBetweenPresentationTimes(const MediaTime&, const MediaTime&);
+    iterator_range findSamplesWithinPresentationRange(const MediaTime&, const MediaTime&);
+    iterator_range findSamplesWithinPresentationRangeFromEnd(const MediaTime&, const MediaTime&);
+
+private:
+    MapType m_samples;
+};
+
+class DecodeOrderSampleMap {
+    friend class SampleMap;
+public:
+    typedef std::pair<MediaTime, MediaTime> KeyType;
+    typedef std::map<KeyType, RefPtr <MediaSample> > MapType;
+    typedef MapType::iterator iterator;
+    typedef MapType::const_iterator const_iterator;
+    typedef MapType::reverse_iterator reverse_iterator;
+    typedef std::pair<reverse_iterator, reverse_iterator> reverse_iterator_range;
+
+    iterator begin() { return m_samples.begin(); }
+    iterator end() { return m_samples.end(); }
+    reverse_iterator rbegin() { return m_samples.rbegin(); }
+    reverse_iterator rend() { return m_samples.rend(); }
+
+    iterator findSampleWithDecodeKey(const KeyType&);
+    reverse_iterator reverseFindSampleWithDecodeKey(const KeyType&);
+    reverse_iterator findSyncSamplePriorToPresentationTime(const MediaTime&, const MediaTime& threshold = MediaTime::positiveInfiniteTime());
+    reverse_iterator findSyncSamplePriorToDecodeIterator(reverse_iterator);
+    iterator findSyncSampleAfterPresentationTime(const MediaTime&, const MediaTime& threshold = MediaTime::positiveInfiniteTime());
+    iterator findSyncSampleAfterDecodeIterator(iterator);
+    reverse_iterator_range findDependentSamples(MediaSample*);
+
+private:
+    MapType m_samples;
+    PresentationOrderSampleMap m_presentationOrder;
+};
+
+class SampleMap {
+public:
+    SampleMap()
+        : m_totalSize(0)
+    {
+    }
+
+    bool empty() const;
+    void clear();
+    void addSample(PassRefPtr<MediaSample>);
+    void removeSample(MediaSample*);
+    size_t sizeInBytes() const { return m_totalSize; }
+
+    template<typename I>
+    void addRange(I begin, I end);
+
+    DecodeOrderSampleMap& decodeOrder() { return m_decodeOrder; }
+    const DecodeOrderSampleMap& decodeOrder() const { return m_decodeOrder; }
+    PresentationOrderSampleMap& presentationOrder() { return m_decodeOrder.m_presentationOrder; }
+    const PresentationOrderSampleMap& presentationOrder() const { return m_decodeOrder.m_presentationOrder; }
+
+private:
+    DecodeOrderSampleMap m_decodeOrder;
+    size_t m_totalSize;
+};
+
+template<typename I>
+void SampleMap::addRange(I begin, I end)
+{
+    for (I iter = begin; iter != end; ++iter)
+        addSample(iter->second);
+}
+
+}
+
+#endif
+
+#endif // SampleMap_h
diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index ff80df5..9b69c66 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -1,5 +1,6 @@
 /*
- * Copyright (C) 2012 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ * Copyright (C) 2013-2014 Apple Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -33,121 +34,276 @@
 
 #if ENABLE(MEDIA_SOURCE)
 
+#include "AudioTrackList.h"
+#include "Event.h"
+#include "ExceptionCodePlaceholder.h"
+#include "GenericEventQueue.h"
+#include "HTMLMediaElement.h"
+#include "InbandTextTrack.h"
+#include "Logging.h"
+#include "MediaDescription.h"
+#include "MediaSample.h"
 #include "MediaSource.h"
+#include "SampleMap.h"
 #include "SourceBufferPrivate.h"
+#include "TextTrackList.h"
 #include "TimeRanges.h"
-#include <wtf/Uint8Array.h>
+#include "VideoTrackList.h"
+#include <limits>
+#include <map>
+#include <runtime/JSLock.h>
+#include <runtime/VM.h>
+#include <wtf/CurrentTime.h>
+#include <wtf/NeverDestroyed.h>
+#if !LOG_DISABLED
+#include <wtf/text/StringBuilder.h>
+#endif
 
 namespace WebCore {
 
-PassRefPtr<SourceBuffer> SourceBuffer::create(PassOwnPtr<SourceBufferPrivate> sourceBufferPrivate, PassRefPtr<MediaSource> source)
+static double ExponentialMovingAverageCoefficient = 0.1;
+
+// Allow hasCurrentTime() to be off by as much as the length of a 24fps video frame
+static const MediaTime& currentTimeFudgeFactor()
+{
+    static NeverDestroyed<MediaTime> fudgeFactor(1, 24);
+    return fudgeFactor;
+}
+
+struct SourceBuffer::TrackBuffer {
+    MediaTime lastDecodeTimestamp;
+    MediaTime lastFrameDuration;
+    MediaTime highestPresentationTimestamp;
+    MediaTime lastEnqueuedPresentationTime;
+    MediaTime lastEnqueuedDecodeEndTime;
+    bool needRandomAccessFlag;
+    bool enabled;
+    bool needsReenqueueing;
+    SampleMap samples;
+    DecodeOrderSampleMap::MapType decodeQueue;
+    RefPtr<MediaDescription> description;
+
+    TrackBuffer()
+        : lastDecodeTimestamp(MediaTime::invalidTime())
+        , lastFrameDuration(MediaTime::invalidTime())
+        , highestPresentationTimestamp(MediaTime::invalidTime())
+        , lastEnqueuedPresentationTime(MediaTime::invalidTime())
+        , lastEnqueuedDecodeEndTime(MediaTime::invalidTime())
+        , needRandomAccessFlag(true)
+        , enabled(false)
+        , needsReenqueueing(false)
+    {
+    }
+};
+
+PassRefPtr<SourceBuffer> SourceBuffer::create(PassRefPtr<SourceBufferPrivate> sourceBufferPrivate, MediaSource* source)
 {
-    return adoptRef(new SourceBuffer(sourceBufferPrivate, source));
+    RefPtr<SourceBuffer> sourceBuffer(adoptRef(new SourceBuffer(WTF::move(sourceBufferPrivate), source)));
+    sourceBuffer->suspendIfNeeded();
+    return sourceBuffer.releaseNonNull();
 }
 
-SourceBuffer::SourceBuffer(PassOwnPtr<SourceBufferPrivate> sourceBufferPrivate, PassRefPtr<MediaSource> source)
-    : m_private(sourceBufferPrivate)
+SourceBuffer::SourceBuffer(PassRefPtr<SourceBufferPrivate> sourceBufferPrivate, MediaSource* source)
+    : ActiveDOMObject(source->scriptExecutionContext())
+    , m_private(WTF::move(sourceBufferPrivate))
     , m_source(source)
-    , m_timestampOffset(0)
+    , m_asyncEventQueue(*this)
+    , m_appendBufferTimer(this, &SourceBuffer::appendBufferTimerFired)
+    , m_highestPresentationEndTimestamp(MediaTime::invalidTime())
+    , m_buffered(TimeRanges::create())
+    , m_appendState(WaitingForSegment)
+    , m_timeOfBufferingMonitor(monotonicallyIncreasingTime())
+    , m_bufferedSinceLastMonitor(0)
+    , m_averageBufferRate(0)
+    , m_reportedExtraMemoryCost(0)
+    , m_pendingRemoveStart(MediaTime::invalidTime())
+    , m_pendingRemoveEnd(MediaTime::invalidTime())
+    , m_removeTimer(this, &SourceBuffer::removeTimerFired)
+    , m_updating(false)
+    , m_receivedFirstInitializationSegment(false)
+    , m_active(false)
+    , m_bufferFull(false)
 {
-    ASSERT(m_private);
     ASSERT(m_source);
+
+    m_private->setClient(this);
 }
 
 SourceBuffer::~SourceBuffer()
 {
+    ASSERT(isRemoved());
+
+    m_private->setClient(0);
 }
 
 PassRefPtr<TimeRanges> SourceBuffer::buffered(ExceptionCode& ec) const
 {
     // Section 3.1 buffered attribute steps.
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#attributes-1
     // 1. If this object has been removed from the sourceBuffers attribute of the parent media source then throw an
     //    INVALID_STATE_ERR exception and abort these steps.
     if (isRemoved()) {
         ec = INVALID_STATE_ERR;
-        return 0;
+        return nullptr;
     }
 
     // 2. Return a new static normalized TimeRanges object for the media segments buffered.
-    return m_private->buffered();
+    return m_buffered->copy();
+}
+
+const RefPtr<TimeRanges>& SourceBuffer::buffered() const
+{
+    return m_buffered;
 }
 
 double SourceBuffer::timestampOffset() const
 {
-    return m_timestampOffset;
+    return m_timestampOffset.toDouble();
 }
 
 void SourceBuffer::setTimestampOffset(double offset, ExceptionCode& ec)
 {
     // Section 3.1 timestampOffset attribute setter steps.
-    // 1. If this object has been removed from the sourceBuffers attribute of the parent media source then throw an
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#attributes-1
+    // 1. Let new timestamp offset equal the new value being assigned to this attribute.
+    // 2. If this object has been removed from the sourceBuffers attribute of the parent media source, then throw an
     //    INVALID_STATE_ERR exception and abort these steps.
-    if (isRemoved()) {
+    // 3. If the updating attribute equals true, then throw an INVALID_STATE_ERR exception and abort these steps.
+    if (isRemoved() || m_updating) {
         ec = INVALID_STATE_ERR;
         return;
     }
 
     // 4. If the readyState attribute of the parent media source is in the "ended" state then run the following steps:
-    if (isEnded()) {
-        // 4.1 Set the readyState attribute of the parent media source to "open"
-        // 4.2 Queue a task to fire a simple event named sourceopen at the parent media source.
-        m_source->setReadyState(MediaSource::openKeyword());
-    }
+    // 4.1 Set the readyState attribute of the parent media source to "open"
+    // 4.2 Queue a task to fire a simple event named sourceopen at the parent media source.
+    m_source->openIfInEndedState();
 
-    // 5. If this object is waiting for the end of a media segment to be appended, then throw an INVALID_STATE_ERR
-    // and abort these steps.
-    if (!m_private->setTimestampOffset(offset)) {
+    // 5. If the append state equals PARSING_MEDIA_SEGMENT, then throw an INVALID_STATE_ERR and abort these steps.
+    if (m_appendState == ParsingMediaSegment) {
         ec = INVALID_STATE_ERR;
         return;
     }
 
-    // 6. Update the attribute to the new value.
-    m_timestampOffset = offset;
+    // FIXME: Add step 6 text when mode attribute is implemented.
+    // 7. Update the attribute to the new value.
+    m_timestampOffset = MediaTime::createWithDouble(offset);
 }
 
-void SourceBuffer::append(PassRefPtr<Uint8Array> data, ExceptionCode& ec)
+void SourceBuffer::appendBuffer(PassRefPtr<ArrayBuffer> data, ExceptionCode& ec)
 {
-    // SourceBuffer.append() steps from October 1st version of the Media Source Extensions spec.
-    // https://dvcs.w3.org/hg/html-media/raw-file/7bab66368f2c/media-source/media-source.html#dom-append
-
-    // 2. If data is null then throw an INVALID_ACCESS_ERR exception and abort these steps.
+    // Section 3.2 appendBuffer()
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-appendBuffer-void-ArrayBufferView-data
+    // 1. If data is null then throw an INVALID_ACCESS_ERR exception and abort these steps.
     if (!data) {
         ec = INVALID_ACCESS_ERR;
         return;
     }
 
-    // 3. If this object has been removed from the sourceBuffers attribute of media source then throw
-    //    an INVALID_STATE_ERR exception and abort these steps.
-    if (isRemoved()) {
-        ec = INVALID_STATE_ERR;
-        return;
-    }
+    appendBufferInternal(static_cast<unsigned char*>(data->data()), data->byteLength(), ec);
+}
 
-    // 5. If the readyState attribute of media source is in the "ended" state then run the following steps:
-    if (isEnded()) {
-        // 5.1. Set the readyState attribute of media source to "open"
-        // 5.2. Queue a task to fire a simple event named sourceopen at media source.
-        m_source->setReadyState(MediaSource::openKeyword());
+void SourceBuffer::appendBuffer(PassRefPtr<ArrayBufferView> data, ExceptionCode& ec)
+{
+    // Section 3.2 appendBuffer()
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-appendBuffer-void-ArrayBufferView-data
+    // 1. If data is null then throw an INVALID_ACCESS_ERR exception and abort these steps.
+    if (!data) {
+        ec = INVALID_ACCESS_ERR;
+        return;
     }
 
-    // Steps 6 & beyond are handled by the private implementation.
-    m_private->append(data->data(), data->length());
+    appendBufferInternal(static_cast<unsigned char*>(data->baseAddress()), data->byteLength(), ec);
 }
 
 void SourceBuffer::abort(ExceptionCode& ec)
 {
     // Section 3.2 abort() method steps.
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-abort-void
     // 1. If this object has been removed from the sourceBuffers attribute of the parent media source
     //    then throw an INVALID_STATE_ERR exception and abort these steps.
     // 2. If the readyState attribute of the parent media source is not in the "open" state
     //    then throw an INVALID_STATE_ERR exception and abort these steps.
-    if (isRemoved() || !isOpen()) {
+    if (isRemoved() || !m_source->isOpen()) {
         ec = INVALID_STATE_ERR;
         return;
     }
 
+    // 3. If the sourceBuffer.updating attribute equals true, then run the following steps: ...
+    abortIfUpdating();
+
     // 4. Run the reset parser state algorithm.
     m_private->abort();
+
+    // FIXME(229408) Add steps 5-6 update appendWindowStart & appendWindowEnd.
+}
+
+void SourceBuffer::remove(double start, double end, ExceptionCode& ec)
+{
+    remove(MediaTime::createWithDouble(start), MediaTime::createWithDouble(end), ec);
+}
+
+void SourceBuffer::remove(const MediaTime& start, const MediaTime& end, ExceptionCode& ec)
+{
+    LOG(MediaSource, "SourceBuffer::remove(%p) - start(%lf), end(%lf)", this, start.toDouble(), end.toDouble());
+
+    // Section 3.2 remove() method steps.
+    // 1. If start is negative or greater than duration, then throw an InvalidAccessError exception and abort these steps.
+    // 2. If end is less than or equal to start, then throw an InvalidAccessError exception and abort these steps.
+    if (start < MediaTime::zeroTime() || (m_source && (!m_source->duration().isValid() || start > m_source->duration())) || end <= start) {
+        ec = INVALID_ACCESS_ERR;
+        return;
+    }
+
+    // 3. If this object has been removed from the sourceBuffers attribute of the parent media source then throw an
+    //    InvalidStateError exception and abort these steps.
+    // 4. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
+    if (isRemoved() || m_updating) {
+        ec = INVALID_STATE_ERR;
+        return;
+    }
+
+    // 5. If the readyState attribute of the parent media source is in the "ended" state then run the following steps:
+    // 5.1. Set the readyState attribute of the parent media source to "open"
+    // 5.2. Queue a task to fire a simple event named sourceopen at the parent media source .
+    m_source->openIfInEndedState();
+
+    // 6. Set the updating attribute to true.
+    m_updating = true;
+
+    // 7. Queue a task to fire a simple event named updatestart at this SourceBuffer object.
+    scheduleEvent(eventNames().updatestartEvent);
+
+    // 8. Return control to the caller and run the rest of the steps asynchronously.
+    m_pendingRemoveStart = start;
+    m_pendingRemoveEnd = end;
+    m_removeTimer.startOneShot(0);
+}
+
+void SourceBuffer::abortIfUpdating()
+{
+    // Section 3.2 abort() method step 3 substeps.
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-abort-void
+
+    if (!m_updating)
+        return;
+
+    // 3.1. Abort the buffer append and stream append loop algorithms if they are running.
+    m_appendBufferTimer.stop();
+    m_pendingAppendData.clear();
+
+    m_removeTimer.stop();
+    m_pendingRemoveStart = MediaTime::invalidTime();
+    m_pendingRemoveEnd = MediaTime::invalidTime();
+
+    // 3.2. Set the updating attribute to false.
+    m_updating = false;
+
+    // 3.3. Queue a task to fire a simple event named abort at this SourceBuffer object.
+    scheduleEvent(eventNames().abortEvent);
+
+    // 3.4. Queue a task to fire a simple event named updateend at this SourceBuffer object.
+    scheduleEvent(eventNames().updateendEvent);
 }
 
 void SourceBuffer::removedFromMediaSource()
@@ -155,8 +311,80 @@ void SourceBuffer::removedFromMediaSource()
     if (isRemoved())
         return;
 
+    abortIfUpdating();
+
+    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+        TrackBuffer& trackBuffer = it->value;
+        trackBuffer.samples.clear();
+        trackBuffer.decodeQueue.clear();
+    }
+
     m_private->removedFromMediaSource();
-    m_source.clear();
+    m_source = 0;
+}
+
+void SourceBuffer::seekToTime(const MediaTime& time)
+{
+    LOG(MediaSource, "SourceBuffer::seekToTime(%p) - time(%s)", this, toString(time).utf8().data());
+
+    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+        TrackBuffer& trackBuffer = it->value;
+        const AtomicString& trackID = it->key;
+
+        trackBuffer.needsReenqueueing = true;
+        reenqueueMediaForTime(trackBuffer, trackID, time);
+    }
+}
+
+MediaTime SourceBuffer::sourceBufferPrivateFastSeekTimeForMediaTime(SourceBufferPrivate*, const MediaTime& targetTime, const MediaTime& negativeThreshold, const MediaTime& positiveThreshold)
+{
+    MediaTime seekTime = targetTime;
+    MediaTime lowerBoundTime = targetTime - negativeThreshold;
+    MediaTime upperBoundTime = targetTime + positiveThreshold;
+
+    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+        TrackBuffer& trackBuffer = it->value;
+        // Find the sample which contains the target time time.
+        DecodeOrderSampleMap::iterator futureSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSampleAfterPresentationTime(targetTime, positiveThreshold);
+        DecodeOrderSampleMap::reverse_iterator pastSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSamplePriorToPresentationTime(targetTime, negativeThreshold);
+        DecodeOrderSampleMap::iterator upperBound = trackBuffer.samples.decodeOrder().end();
+        DecodeOrderSampleMap::reverse_iterator lowerBound = trackBuffer.samples.decodeOrder().rend();
+
+        if (futureSyncSampleIterator == upperBound && pastSyncSampleIterator == lowerBound)
+            continue;
+
+        MediaTime futureSeekTime = MediaTime::positiveInfiniteTime();
+        if (futureSyncSampleIterator != upperBound) {
+            RefPtr<MediaSample>& sample = futureSyncSampleIterator->second;
+            futureSeekTime = sample->presentationTime();
+        }
+
+        MediaTime pastSeekTime = MediaTime::negativeInfiniteTime();
+        if (pastSyncSampleIterator != lowerBound) {
+            RefPtr<MediaSample>& sample = pastSyncSampleIterator->second;
+            pastSeekTime = sample->presentationTime();
+        }
+
+        MediaTime trackSeekTime = abs(targetTime - futureSeekTime) < abs(targetTime - pastSeekTime) ? futureSeekTime : pastSeekTime;
+        if (abs(targetTime - trackSeekTime) > abs(targetTime - seekTime))
+            seekTime = trackSeekTime;
+    }
+
+    return seekTime;
+}
+
+bool SourceBuffer::hasPendingActivity() const
+{
+    return m_source || m_asyncEventQueue.hasPendingEvents();
+}
+
+void SourceBuffer::stop()
+{
+    m_appendBufferTimer.stop();
+    m_removeTimer.stop();
 }
 
 bool SourceBuffer::isRemoved() const
@@ -164,16 +392,1423 @@ bool SourceBuffer::isRemoved() const
     return !m_source;
 }
 
-bool SourceBuffer::isOpen() const
+void SourceBuffer::scheduleEvent(const AtomicString& eventName)
 {
-    ASSERT(m_source);
-    return m_source->readyState() == MediaSource::openKeyword();
+    RefPtr<Event> event = Event::create(eventName, false, false);
+    event->setTarget(this);
+
+    m_asyncEventQueue.enqueueEvent(event.release());
 }
 
-bool SourceBuffer::isEnded() const
+void SourceBuffer::appendBufferInternal(unsigned char* data, unsigned size, ExceptionCode& ec)
 {
-    ASSERT(m_source);
-    return m_source->readyState() == MediaSource::endedKeyword();
+    // Section 3.2 appendBuffer()
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-appendBuffer-void-ArrayBufferView-data
+
+    // Step 1 is enforced by the caller.
+    // 2. Run the prepare append algorithm.
+    // Section 3.5.4 Prepare AppendAlgorithm
+
+    // 1. If the SourceBuffer has been removed from the sourceBuffers attribute of the parent media source
+    // then throw an INVALID_STATE_ERR exception and abort these steps.
+    // 2. If the updating attribute equals true, then throw an INVALID_STATE_ERR exception and abort these steps.
+    if (isRemoved() || m_updating) {
+        ec = INVALID_STATE_ERR;
+        return;
+    }
+
+    // 3. If the readyState attribute of the parent media source is in the "ended" state then run the following steps:
+    // 3.1. Set the readyState attribute of the parent media source to "open"
+    // 3.2. Queue a task to fire a simple event named sourceopen at the parent media source .
+    m_source->openIfInEndedState();
+
+    // 4. Run the coded frame eviction algorithm.
+    evictCodedFrames(size);
+
+    // FIXME: enable this code when MSE libraries have been updated to support it.
+#if 0
+    // 5. If the buffer full flag equals true, then throw a QUOTA_EXCEEDED_ERR exception and abort these step.
+    if (m_bufferFull) {
+        LOG(MediaSource, "SourceBuffer::appendBufferInternal(%p) -  buffer full, failing with QUOTA_EXCEEDED_ERR error", this);
+        ec = QUOTA_EXCEEDED_ERR;
+        return;
+    }
+#endif
+
+    // NOTE: Return to 3.2 appendBuffer()
+    // 3. Add data to the end of the input buffer.
+    m_pendingAppendData.append(data, size);
+
+    // 4. Set the updating attribute to true.
+    m_updating = true;
+
+    // 5. Queue a task to fire a simple event named updatestart at this SourceBuffer object.
+    scheduleEvent(eventNames().updatestartEvent);
+
+    // 6. Asynchronously run the buffer append algorithm.
+    m_appendBufferTimer.startOneShot(0);
+
+    reportExtraMemoryCost();
+}
+
+void SourceBuffer::appendBufferTimerFired(Timer<SourceBuffer>*)
+{
+    if (isRemoved())
+        return;
+
+    ASSERT(m_updating);
+
+    // Section 3.5.5 Buffer Append Algorithm
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#sourcebuffer-buffer-append
+
+    // 1. Run the segment parser loop algorithm.
+    size_t appendSize = m_pendingAppendData.size();
+    if (!appendSize) {
+        // Resize buffer for 0 byte appends so we always have a valid pointer.
+        // We need to convey all appends, even 0 byte ones to |m_private| so
+        // that it can clear its end of stream state if necessary.
+        m_pendingAppendData.resize(1);
+    }
+
+    // Section 3.5.1 Segment Parser Loop
+    // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#sourcebuffer-segment-parser-loop
+    // When the segment parser loop algorithm is invoked, run the following steps:
+
+    // 1. Loop Top: If the input buffer is empty, then jump to the need more data step below.
+    if (!m_pendingAppendData.size()) {
+        sourceBufferPrivateAppendComplete(&m_private.get(), AppendSucceeded);
+        return;
+    }
+
+    m_private->append(m_pendingAppendData.data(), appendSize);
+    m_pendingAppendData.clear();
+}
+
+void SourceBuffer::sourceBufferPrivateAppendComplete(SourceBufferPrivate*, AppendResult result)
+{
+    if (isRemoved())
+        return;
+
+    // Section 3.5.5 Buffer Append Algorithm, ctd.
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#sourcebuffer-buffer-append
+
+    // 2. If the input buffer contains bytes that violate the SourceBuffer byte stream format specification,
+    // then run the end of stream algorithm with the error parameter set to "decode" and abort this algorithm.
+    if (result == ParsingFailed) {
+        LOG(MediaSource, "SourceBuffer::sourceBufferPrivateAppendComplete(%p) - result = ParsingFailed", this);
+        m_source->streamEndedWithError(decodeError(), IgnorableExceptionCode());
+        return;
+    }
+
+    // NOTE: Steps 3 - 6 enforced by sourceBufferPrivateDidReceiveInitializationSegment() and
+    // sourceBufferPrivateDidReceiveSample below.
+
+    // 7. Need more data: Return control to the calling algorithm.
+
+    // NOTE: return to Section 3.5.5
+    // 2.If the segment parser loop algorithm in the previous step was aborted, then abort this algorithm.
+    if (result != AppendSucceeded)
+        return;
+
+    // 3. Set the updating attribute to false.
+    m_updating = false;
+
+    // 4. Queue a task to fire a simple event named update at this SourceBuffer object.
+    scheduleEvent(eventNames().updateEvent);
+
+    // 5. Queue a task to fire a simple event named updateend at this SourceBuffer object.
+    scheduleEvent(eventNames().updateendEvent);
+
+    if (m_source)
+        m_source->monitorSourceBuffers();
+
+    MediaTime currentMediaTime = m_source->currentTime();
+    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+        TrackBuffer& trackBuffer = it->value;
+        const AtomicString& trackID = it->key;
+
+        if (trackBuffer.needsReenqueueing) {
+            LOG(MediaSource, "SourceBuffer::sourceBufferPrivateAppendComplete(%p) - reenqueuing at time (%s)", this, toString(currentMediaTime).utf8().data());
+            reenqueueMediaForTime(trackBuffer, trackID, currentMediaTime);
+        } else
+            provideMediaData(trackBuffer, trackID);
+    }
+
+    reportExtraMemoryCost();
+    if (extraMemoryCost() > this->maximumBufferSize())
+        m_bufferFull = true;
+
+    LOG(Media, "SourceBuffer::sourceBufferPrivateAppendComplete(%p) - buffered = %s", this, toString(m_buffered->ranges()).utf8().data());
+}
+
+void SourceBuffer::sourceBufferPrivateDidReceiveRenderingError(SourceBufferPrivate*, int error)
+{
+#if LOG_DISABLED
+    UNUSED_PARAM(error);
+#endif
+
+    LOG(MediaSource, "SourceBuffer::sourceBufferPrivateDidReceiveRenderingError(%p) - result = %i", this, error);
+
+    if (!isRemoved())
+        m_source->streamEndedWithError(decodeError(), IgnorableExceptionCode());
+}
+
+static bool decodeTimeComparator(const PresentationOrderSampleMap::MapType::value_type& a, const PresentationOrderSampleMap::MapType::value_type& b)
+{
+    return a.second->decodeTime() < b.second->decodeTime();
+}
+
+static PassRefPtr<TimeRanges> removeSamplesFromTrackBuffer(const DecodeOrderSampleMap::MapType& samples, SourceBuffer::TrackBuffer& trackBuffer, const SourceBuffer* buffer, const char* logPrefix)
+{
+#if !LOG_DISABLED
+    double earliestSample = std::numeric_limits<double>::infinity();
+    double latestSample = 0;
+    size_t bytesRemoved = 0;
+#else
+    UNUSED_PARAM(logPrefix);
+    UNUSED_PARAM(buffer);
+#endif
+
+    RefPtr<TimeRanges> erasedRanges = TimeRanges::create();
+    MediaTime microsecond(1, 1000000);
+    DecodeOrderSampleMap::const_iterator end = samples.end();
+    for (DecodeOrderSampleMap::const_iterator it = samples.begin(); it != end; ++it) {
+ std::pair<const DecodeOrderSampleMap::KeyType, RefPtr<MediaSample> > sampleIt = *it;
+        const DecodeOrderSampleMap::KeyType& decodeKey = sampleIt.first;
+#if !LOG_DISABLED
+        size_t startBufferSize = trackBuffer.samples.sizeInBytes();
+#endif
+
+        RefPtr<MediaSample>& sample = sampleIt.second;
+        LOG(MediaSource, "SourceBuffer::%s(%p) - removing sample(%s)", logPrefix, buffer, toString(*sampleIt.second).utf8().data());
+
+        // Remove the erased samples from the TrackBuffer sample map.
+        trackBuffer.samples.removeSample(sample.get());
+
+        // Also remove the erased samples from the TrackBuffer decodeQueue.
+        trackBuffer.decodeQueue.erase(decodeKey);
+
+        double startTime = sample->presentationTime().toDouble();
+        double endTime = startTime + (sample->duration() + microsecond).toDouble();
+        erasedRanges->add(startTime, endTime);
+
+#if !LOG_DISABLED
+        bytesRemoved += startBufferSize - trackBuffer.samples.sizeInBytes();
+        if (startTime < earliestSample)
+            earliestSample = startTime;
+        if (endTime > latestSample)
+            latestSample = endTime;
+#endif
+    }
+
+#if !LOG_DISABLED
+    if (bytesRemoved)
+        LOG(MediaSource, "SourceBuffer::%s(%p) removed %zu bytes, start(%lf), end(%lf)", logPrefix, buffer, bytesRemoved, earliestSample, latestSample);
+#endif
+
+    return erasedRanges.release();
+}
+
+void SourceBuffer::removeCodedFrames(const MediaTime& start, const MediaTime& end)
+{
+    LOG(MediaSource, "SourceBuffer::removeCodedFrames(%p) - start(%s), end(%s)", this, toString(start).utf8().data(), toString(end).utf8().data());
+
+    // 3.5.9 Coded Frame Removal Algorithm
+    // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#sourcebuffer-coded-frame-removal
+
+    // 1. Let start be the starting presentation timestamp for the removal range.
+    MediaTime durationMediaTime = m_source->duration();
+    MediaTime currentMediaTime = m_source->currentTime();
+
+    // 2. Let end be the end presentation timestamp for the removal range.
+    // 3. For each track buffer in this source buffer, run the following steps:
+    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+        TrackBuffer& trackBuffer = it->value;
+
+        // 3.1. Let remove end timestamp be the current value of duration
+        // 3.2 If this track buffer has a random access point timestamp that is greater than or equal to end, then update
+        // remove end timestamp to that random access point timestamp.
+        // NOTE: findSyncSampleAfterPresentationTime will return the next sync sample on or after the presentation time
+        // or decodeOrder().end() if no sync sample exists after that presentation time.
+        DecodeOrderSampleMap::iterator removeDecodeEnd = trackBuffer.samples.decodeOrder().findSyncSampleAfterPresentationTime(end);
+        PresentationOrderSampleMap::iterator removePresentationEnd;
+        if (removeDecodeEnd == trackBuffer.samples.decodeOrder().end())
+            removePresentationEnd = trackBuffer.samples.presentationOrder().end();
+        else
+            removePresentationEnd = trackBuffer.samples.presentationOrder().findSampleWithPresentationTime(removeDecodeEnd->second->presentationTime());
+
+        PresentationOrderSampleMap::iterator removePresentationStart = trackBuffer.samples.presentationOrder().findSampleOnOrAfterPresentationTime(start);
+        if (removePresentationStart == removePresentationEnd)
+            continue;
+
+        // 3.3 Remove all media data, from this track buffer, that contain starting timestamps greater than or equal to
+        // start and less than the remove end timestamp.
+        // NOTE: frames must be removed in decode order, so that all dependant frames between the frame to be removed
+        // and the next sync sample frame are removed. But we must start from the first sample in decode order, not
+        // presentation order.
+        PresentationOrderSampleMap::iterator minDecodeTimeIter = std::min_element(removePresentationStart, removePresentationEnd, decodeTimeComparator);
+        DecodeOrderSampleMap::KeyType decodeKey(minDecodeTimeIter->second->decodeTime(), minDecodeTimeIter->second->presentationTime());
+        DecodeOrderSampleMap::iterator removeDecodeStart = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(decodeKey);
+
+        DecodeOrderSampleMap::MapType erasedSamples(removeDecodeStart, removeDecodeEnd);
+        RefPtr<TimeRanges> erasedRanges = removeSamplesFromTrackBuffer(erasedSamples, trackBuffer, this, "removeCodedFrames");
+
+        // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
+        // not yet displayed samples.
+        if (currentMediaTime < trackBuffer.lastEnqueuedPresentationTime) {
+            PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.lastEnqueuedPresentationTime);
+            possiblyEnqueuedRanges.intersectWith(erasedRanges->ranges());
+            if (possiblyEnqueuedRanges.length())
+                trackBuffer.needsReenqueueing = true;
+        }
+
+        erasedRanges->invert();
+        m_buffered->intersectWith(*erasedRanges);
+
+        // 3.4 If this object is in activeSourceBuffers, the current playback position is greater than or equal to start
+        // and less than the remove end timestamp, and HTMLMediaElement.readyState is greater than HAVE_METADATA, then set
+        // the HTMLMediaElement.readyState attribute to HAVE_METADATA and stall playback.
+        if (m_active && currentMediaTime >= start && currentMediaTime < end && m_private->readyState() > MediaPlayer::HaveMetadata)
+            m_private->setReadyState(MediaPlayer::HaveMetadata);
+    }
+
+    // 4. If buffer full flag equals true and this object is ready to accept more bytes, then set the buffer full flag to false.
+    // No-op
+
+    LOG(Media, "SourceBuffer::removeCodedFrames(%p) - buffered = %s", this, toString(m_buffered->ranges()).utf8().data());
+}
+
+void SourceBuffer::removeTimerFired(Timer*)
+{
+    ASSERT(m_updating);
+    ASSERT(m_pendingRemoveStart.isValid());
+    ASSERT(m_pendingRemoveStart < m_pendingRemoveEnd);
+
+    // Section 3.2 remove() method steps
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-remove-void-double-start-double-end
+
+    // 9. Run the coded frame removal algorithm with start and end as the start and end of the removal range.
+    removeCodedFrames(m_pendingRemoveStart, m_pendingRemoveEnd);
+
+    // 10. Set the updating attribute to false.
+    m_updating = false;
+    m_pendingRemoveStart = MediaTime::invalidTime();
+    m_pendingRemoveEnd = MediaTime::invalidTime();
+
+    // 11. Queue a task to fire a simple event named update at this SourceBuffer object.
+    scheduleEvent(eventNames().updateEvent);
+
+    // 12. Queue a task to fire a simple event named updateend at this SourceBuffer object.
+    scheduleEvent(eventNames().updateendEvent);
+}
+
+void SourceBuffer::evictCodedFrames(size_t newDataSize)
+{
+    // 3.5.13 Coded Frame Eviction Algorithm
+    // http://www.w3.org/TR/media-source/#sourcebuffer-coded-frame-eviction
+
+    if (isRemoved())
+        return;
+
+    // This algorithm is run to free up space in this source buffer when new data is appended.
+    // 1. Let new data equal the data that is about to be appended to this SourceBuffer.
+    // 2. If the buffer full flag equals false, then abort these steps.
+    if (!m_bufferFull)
+        return;
+
+    size_t maximumBufferSize = this->maximumBufferSize();
+
+    // 3. Let removal ranges equal a list of presentation time ranges that can be evicted from
+    // the presentation to make room for the new data.
+
+    // NOTE: begin by removing data from the beginning of the buffered ranges, 30 seconds at
+    // a time, up to 30 seconds before currentTime.
+    MediaTime thirtySeconds = MediaTime(30, 1);
+    MediaTime currentTime = m_source->currentTime();
+    MediaTime maximumRangeEnd = currentTime - thirtySeconds;
+
+#if !LOG_DISABLED
+    LOG(MediaSource, "SourceBuffer::evictCodedFrames(%p) - currentTime = %lf, require %zu bytes, maximum buffer size is %zu", this, m_source->currentTime().toDouble(), extraMemoryCost() + newDataSize, maximumBufferSize);
+    size_t initialBufferedSize = extraMemoryCost();
+#endif
+
+    MediaTime rangeStart = MediaTime::zeroTime();
+    MediaTime rangeEnd = rangeStart + thirtySeconds;
+    while (rangeStart < maximumRangeEnd) {
+        // 4. For each range in removal ranges, run the coded frame removal algorithm with start and
+        // end equal to the removal range start and end timestamp respectively.
+        removeCodedFrames(rangeStart, std::min(rangeEnd, maximumRangeEnd));
+        if (extraMemoryCost() + newDataSize < maximumBufferSize) {
+            m_bufferFull = false;
+            break;
+        }
+
+        rangeStart += thirtySeconds;
+        rangeEnd += thirtySeconds;
+    }
+
+    if (!m_bufferFull) {
+        LOG(MediaSource, "SourceBuffer::evictCodedFrames(%p) - evicted %zu bytes", this, initialBufferedSize - extraMemoryCost());
+        return;
+    }
+
+    // If there still isn't enough free space and there buffers in time ranges after the current range (ie. there is a gap after
+    // the current buffered range), delete 30 seconds at a time from duration back to the current time range or 30 seconds after
+    // currenTime whichever we hit first.
+    auto buffered = m_buffered->ranges();
+    size_t currentTimeRange = buffered.find(currentTime);
+    if (currentTimeRange == notFound || currentTimeRange == buffered.length() - 1) {
+        LOG(MediaSource, "SourceBuffer::evictCodedFrames(%p) - evicted %zu bytes but FAILED to free enough", this, initialBufferedSize - extraMemoryCost());
+        return;
+    }
+
+    MediaTime minimumRangeStart = currentTime + thirtySeconds;
+
+    rangeEnd = m_source->duration();
+    rangeStart = rangeEnd - thirtySeconds;
+    while (rangeStart > minimumRangeStart) {
+
+        // Do not evict data from the time range that contains currentTime.
+        size_t startTimeRange = buffered.find(rangeStart);
+        if (startTimeRange == currentTimeRange) {
+            size_t endTimeRange = buffered.find(rangeEnd);
+            if (endTimeRange == currentTimeRange)
+                break;
+
+            rangeEnd = buffered.start(endTimeRange);
+        }
+
+        // 4. For each range in removal ranges, run the coded frame removal algorithm with start and
+        // end equal to the removal range start and end timestamp respectively.
+        removeCodedFrames(std::max(minimumRangeStart, rangeStart), rangeEnd);
+        if (extraMemoryCost() + newDataSize < maximumBufferSize) {
+            m_bufferFull = false;
+            break;
+        }
+
+        rangeStart -= thirtySeconds;
+        rangeEnd -= thirtySeconds;
+    }
+
+    LOG(MediaSource, "SourceBuffer::evictCodedFrames(%p) - evicted %zu bytes%s", this, initialBufferedSize - extraMemoryCost(), m_bufferFull ? "" : " but FAILED to free enough");
+}
+
+size_t SourceBuffer::maximumBufferSize() const
+{
+    if (isRemoved())
+        return 0;
+
+    HTMLMediaElement* element = m_source->mediaElement();
+    if (!element)
+        return 0;
+
+    return element->maximumSourceBufferSize(*this);
+}
+
+const AtomicString& SourceBuffer::decodeError()
+{
+    static NeverDestroyed<AtomicString> decode("decode", AtomicString::ConstructFromLiteral);
+    return decode;
+}
+
+const AtomicString& SourceBuffer::networkError()
+{
+    static NeverDestroyed<AtomicString> network("network", AtomicString::ConstructFromLiteral);
+    return network;
+}
+
+VideoTrackList* SourceBuffer::videoTracks()
+{
+    if (!m_source || !m_source->mediaElement())
+        return nullptr;
+
+    if (!m_videoTracks)
+        m_videoTracks = VideoTrackList::create(m_source->mediaElement(), ActiveDOMObject::scriptExecutionContext());
+
+    return m_videoTracks.get();
+}
+
+AudioTrackList* SourceBuffer::audioTracks()
+{
+    if (!m_source || !m_source->mediaElement())
+        return nullptr;
+
+    if (!m_audioTracks)
+        m_audioTracks = AudioTrackList::create(m_source->mediaElement(), ActiveDOMObject::scriptExecutionContext());
+
+    return m_audioTracks.get();
+}
+
+TextTrackList* SourceBuffer::textTracks()
+{
+    if (!m_source || !m_source->mediaElement())
+        return nullptr;
+
+    if (!m_textTracks)
+        m_textTracks = TextTrackList::create(m_source->mediaElement(), ActiveDOMObject::scriptExecutionContext());
+
+    return m_textTracks.get();
+}
+
+void SourceBuffer::setActive(bool active)
+{
+    if (m_active == active)
+        return;
+
+    m_active = active;
+    m_private->setActive(active);
+    if (!isRemoved())
+        m_source->sourceBufferDidChangeAcitveState(this, active);
+}
+
+void SourceBuffer::sourceBufferPrivateDidEndStream(SourceBufferPrivate*, const WTF::AtomicString& error)
+{
+    LOG(MediaSource, "SourceBuffer::sourceBufferPrivateDidEndStream(%p) - result = %s", this, String(error).utf8().data());
+
+    if (!isRemoved())
+        m_source->streamEndedWithError(error, IgnorableExceptionCode());
+}
+
+void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBufferPrivate*, const InitializationSegment& segment)
+{
+    if (isRemoved())
+        return;
+
+    LOG(MediaSource, "SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(%p)", this);
+
+    // 3.5.7 Initialization Segment Received
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#sourcebuffer-init-segment-received
+    // 1. Update the duration attribute if it currently equals NaN:
+    if (m_source->duration().isInvalid()) {
+        // ↳ If the initialization segment contains a duration:
+        //   Run the duration change algorithm with new duration set to the duration in the initialization segment.
+        // ↳ Otherwise:
+        //   Run the duration change algorithm with new duration set to positive Infinity.
+        MediaTime newDuration = segment.duration.isValid() ? segment.duration : MediaTime::positiveInfiniteTime();
+        m_source->setDurationInternal(newDuration);
+    }
+
+    // 2. If the initialization segment has no audio, video, or text tracks, then run the end of stream
+    // algorithm with the error parameter set to "decode" and abort these steps.
+    if (!segment.audioTracks.size() && !segment.videoTracks.size() && !segment.textTracks.size())
+        m_source->streamEndedWithError(decodeError(), IgnorableExceptionCode());
+
+
+    // 3. If the first initialization segment flag is true, then run the following steps:
+    if (m_receivedFirstInitializationSegment) {
+        if (!validateInitializationSegment(segment)) {
+            m_source->streamEndedWithError(decodeError(), IgnorableExceptionCode());
+            return;
+        }
+        // 3.2 Add the appropriate track descriptions from this initialization segment to each of the track buffers.
+        ASSERT(segment.audioTracks.size() == audioTracks()->length());
+        for (auto& audioTrackInfo : segment.audioTracks) {
+            if (audioTracks()->length() == 1) {
+                audioTracks()->item(0)->setPrivate(audioTrackInfo.track);
+                break;
+            }
+
+            auto audioTrack = audioTracks()->getTrackById(audioTrackInfo.track->id());
+            ASSERT(audioTrack);
+            audioTrack->setPrivate(audioTrackInfo.track);
+        }
+
+        ASSERT(segment.videoTracks.size() == videoTracks()->length());
+        for (auto& videoTrackInfo : segment.videoTracks) {
+            if (videoTracks()->length() == 1) {
+                videoTracks()->item(0)->setPrivate(videoTrackInfo.track);
+                break;
+            }
+
+            auto videoTrack = videoTracks()->getTrackById(videoTrackInfo.track->id());
+            ASSERT(videoTrack);
+            videoTrack->setPrivate(videoTrackInfo.track);
+        }
+
+        ASSERT(segment.textTracks.size() == textTracks()->length());
+        for (auto& textTrackInfo : segment.textTracks) {
+            if (textTracks()->length() == 1) {
+                downcast<InbandTextTrack>(*textTracks()->item(0)).setPrivate(textTrackInfo.track);
+                break;
+            }
+
+            auto textTrack = textTracks()->getTrackById(textTrackInfo.track->id());
+            ASSERT(textTrack);
+            downcast<InbandTextTrack>(*textTrack).setPrivate(textTrackInfo.track);
+        }
+
+        for (auto& trackBuffer : m_trackBufferMap.values())
+            trackBuffer.needRandomAccessFlag = true;
+    }
+
+    // 4. Let active track flag equal false.
+    bool activeTrackFlag = false;
+
+    // 5. If the first initialization segment flag is false, then run the following steps:
+    if (!m_receivedFirstInitializationSegment) {
+        // 5.1 If the initialization segment contains tracks with codecs the user agent does not support,
+        // then run the end of stream algorithm with the error parameter set to "decode" and abort these steps.
+        // NOTE: This check is the responsibility of the SourceBufferPrivate.
+
+        // 5.2 For each audio track in the initialization segment, run following steps:
+        for (auto& audioTrackInfo : segment.audioTracks) {
+            AudioTrackPrivate* audioTrackPrivate = audioTrackInfo.track.get();
+
+            // 5.2.1 Let new audio track be a new AudioTrack object.
+            // 5.2.2 Generate a unique ID and assign it to the id property on new video track.
+            RefPtr<AudioTrack> newAudioTrack = AudioTrack::create(this, audioTrackPrivate);
+            newAudioTrack->setSourceBuffer(this);
+
+            // 5.2.3 If audioTracks.length equals 0, then run the following steps:
+            if (!audioTracks()->length()) {
+                // 5.2.3.1 Set the enabled property on new audio track to true.
+                newAudioTrack->setEnabled(true);
+
+                // 5.2.3.2 Set active track flag to true.
+                activeTrackFlag = true;
+            }
+
+            // 5.2.4 Add new audio track to the audioTracks attribute on this SourceBuffer object.
+            // 5.2.5 Queue a task to fire a trusted event named addtrack, that does not bubble and is
+            // not cancelable, and that uses the TrackEvent interface, at the AudioTrackList object
+            // referenced by the audioTracks attribute on this SourceBuffer object.
+            audioTracks()->append(newAudioTrack);
+
+            // 5.2.6 Add new audio track to the audioTracks attribute on the HTMLMediaElement.
+            // 5.2.7 Queue a task to fire a trusted event named addtrack, that does not bubble and is
+            // not cancelable, and that uses the TrackEvent interface, at the AudioTrackList object
+            // referenced by the audioTracks attribute on the HTMLMediaElement.
+            m_source->mediaElement()->audioTracks()->append(newAudioTrack);
+
+            // 5.2.8 Create a new track buffer to store coded frames for this track.
+            ASSERT(!m_trackBufferMap.contains(newAudioTrack->id()));
+            TrackBuffer& trackBuffer = m_trackBufferMap.add(newAudioTrack->id(), TrackBuffer()).iterator->value;
+
+            // 5.2.9 Add the track description for this track to the track buffer.
+            trackBuffer.description = audioTrackInfo.description;
+
+            m_audioCodecs.append(trackBuffer.description->codec());
+        }
+
+        // 5.3 For each video track in the initialization segment, run following steps:
+        for (auto& videoTrackInfo : segment.videoTracks) {
+            VideoTrackPrivate* videoTrackPrivate = videoTrackInfo.track.get();
+
+            // 5.3.1 Let new video track be a new VideoTrack object.
+            // 5.3.2 Generate a unique ID and assign it to the id property on new video track.
+            RefPtr<VideoTrack> newVideoTrack = VideoTrack::create(this, videoTrackPrivate);
+            newVideoTrack->setSourceBuffer(this);
+
+            // 5.3.3 If videoTracks.length equals 0, then run the following steps:
+            if (!videoTracks()->length()) {
+                // 5.3.3.1 Set the selected property on new video track to true.
+                newVideoTrack->setSelected(true);
+
+                // 5.3.3.2 Set active track flag to true.
+                activeTrackFlag = true;
+            }
+
+            // 5.3.4 Add new video track to the videoTracks attribute on this SourceBuffer object.
+            // 5.3.5 Queue a task to fire a trusted event named addtrack, that does not bubble and is
+            // not cancelable, and that uses the TrackEvent interface, at the VideoTrackList object
+            // referenced by the videoTracks attribute on this SourceBuffer object.
+            videoTracks()->append(newVideoTrack);
+
+            // 5.3.6 Add new video track to the videoTracks attribute on the HTMLMediaElement.
+            // 5.3.7 Queue a task to fire a trusted event named addtrack, that does not bubble and is
+            // not cancelable, and that uses the TrackEvent interface, at the VideoTrackList object
+            // referenced by the videoTracks attribute on the HTMLMediaElement.
+            m_source->mediaElement()->videoTracks()->append(newVideoTrack);
+
+            // 5.3.8 Create a new track buffer to store coded frames for this track.
+            ASSERT(!m_trackBufferMap.contains(newVideoTrack->id()));
+            TrackBuffer& trackBuffer = m_trackBufferMap.add(newVideoTrack->id(), TrackBuffer()).iterator->value;
+
+            // 5.3.9 Add the track description for this track to the track buffer.
+            trackBuffer.description = videoTrackInfo.description;
+
+            m_videoCodecs.append(trackBuffer.description->codec());
+        }
+
+        // 5.4 For each text track in the initialization segment, run following steps:
+        for (auto& textTrackInfo : segment.textTracks) {
+            InbandTextTrackPrivate* textTrackPrivate = textTrackInfo.track.get();
+
+            // 5.4.1 Let new text track be a new TextTrack object with its properties populated with the
+            // appropriate information from the initialization segment.
+            RefPtr<InbandTextTrack> newTextTrack = InbandTextTrack::create(scriptExecutionContext(), this, textTrackPrivate);
+
+            // 5.4.2 If the mode property on new text track equals "showing" or "hidden", then set active
+            // track flag to true.
+            if (textTrackPrivate->mode() != InbandTextTrackPrivate::Disabled)
+                activeTrackFlag = true;
+
+            // 5.4.3 Add new text track to the textTracks attribute on this SourceBuffer object.
+            // 5.4.4 Queue a task to fire a trusted event named addtrack, that does not bubble and is
+            // not cancelable, and that uses the TrackEvent interface, at textTracks attribute on this
+            // SourceBuffer object.
+            textTracks()->append(newTextTrack);
+
+            // 5.4.5 Add new text track to the textTracks attribute on the HTMLMediaElement.
+            // 5.4.6 Queue a task to fire a trusted event named addtrack, that does not bubble and is
+            // not cancelable, and that uses the TrackEvent interface, at the TextTrackList object
+            // referenced by the textTracks attribute on the HTMLMediaElement.
+            m_source->mediaElement()->textTracks()->append(newTextTrack);
+
+            // 5.4.7 Create a new track buffer to store coded frames for this track.
+            ASSERT(!m_trackBufferMap.contains(textTrackPrivate->id()));
+            TrackBuffer& trackBuffer = m_trackBufferMap.add(textTrackPrivate->id(), TrackBuffer()).iterator->value;
+
+            // 5.4.8 Add the track description for this track to the track buffer.
+            trackBuffer.description = textTrackInfo.description;
+
+            m_textCodecs.append(trackBuffer.description->codec());
+        }
+
+        // 5.5 If active track flag equals true, then run the following steps:
+        if (activeTrackFlag) {
+            // 5.5.1 Add this SourceBuffer to activeSourceBuffers.
+            setActive(true);
+        }
+
+        // 5.6 Set first initialization segment flag to true.
+        m_receivedFirstInitializationSegment = true;
+    }
+
+    // 6. If the HTMLMediaElement.readyState attribute is HAVE_NOTHING, then run the following steps:
+    if (m_private->readyState() == MediaPlayer::HaveNothing) {
+        // 6.1 If one or more objects in sourceBuffers have first initialization segment flag set to false, then abort these steps.
+        for (auto& sourceBuffer : *m_source->sourceBuffers()) {
+            if (!sourceBuffer->m_receivedFirstInitializationSegment)
+                return;
+        }
+
+        // 6.2 Set the HTMLMediaElement.readyState attribute to HAVE_METADATA.
+        // 6.3 Queue a task to fire a simple event named loadedmetadata at the media element.
+        m_private->setReadyState(MediaPlayer::HaveMetadata);
+    }
+
+    // 7. If the active track flag equals true and the HTMLMediaElement.readyState
+    // attribute is greater than HAVE_CURRENT_DATA, then set the HTMLMediaElement.readyState
+    // attribute to HAVE_METADATA.
+    if (activeTrackFlag && m_private->readyState() > MediaPlayer::HaveCurrentData)
+        m_private->setReadyState(MediaPlayer::HaveMetadata);
+}
+
+bool SourceBuffer::validateInitializationSegment(const InitializationSegment& segment)
+{
+    // 3.5.7 Initialization Segment Received (ctd)
+    // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#sourcebuffer-init-segment-received
+
+    // 3.1. Verify the following properties. If any of the checks fail then run the end of stream
+    // algorithm with the error parameter set to "decode" and abort these steps.
+    //   * The number of audio, video, and text tracks match what was in the first initialization segment.
+    if (segment.audioTracks.size() != audioTracks()->length()
+        || segment.videoTracks.size() != videoTracks()->length()
+        || segment.textTracks.size() != textTracks()->length())
+        return false;
+
+    //   * The codecs for each track, match what was specified in the first initialization segment.
+    for (auto& audioTrackInfo : segment.audioTracks) {
+        if (!m_audioCodecs.contains(audioTrackInfo.description->codec()))
+            return false;
+    }
+
+    for (auto& videoTrackInfo : segment.videoTracks) {
+        if (!m_videoCodecs.contains(videoTrackInfo.description->codec()))
+            return false;
+    }
+
+    for (auto& textTrackInfo : segment.textTracks) {
+        if (!m_textCodecs.contains(textTrackInfo.description->codec()))
+            return false;
+    }
+
+    //   * If more than one track for a single type are present (ie 2 audio tracks), then the Track
+    //   IDs match the ones in the first initialization segment.
+    if (segment.audioTracks.size() >= 2) {
+        for (auto& audioTrackInfo : segment.audioTracks) {
+            if (!m_trackBufferMap.contains(audioTrackInfo.track->id()))
+                return false;
+        }
+    }
+
+    if (segment.videoTracks.size() >= 2) {
+        for (auto& videoTrackInfo : segment.videoTracks) {
+            if (!m_trackBufferMap.contains(videoTrackInfo.track->id()))
+                return false;
+        }
+    }
+
+    if (segment.textTracks.size() >= 2) {
+        for (auto& textTrackInfo : segment.videoTracks) {
+            if (!m_trackBufferMap.contains(textTrackInfo.track->id()))
+                return false;
+        }
+    }
+
+    return true;
+}
+
+class SampleLessThanComparator {
+public:
+    bool operator()(std::pair<MediaTime, RefPtr<MediaSample> > value1, std::pair<MediaTime, RefPtr<MediaSample> > value2)
+    {
+        return value1.first < value2.first;
+    }
+
+    bool operator()(MediaTime value1, std::pair<MediaTime, RefPtr<MediaSample> > value2)
+    {
+        return value1 < value2.first;
+    }
+
+    bool operator()(std::pair<MediaTime, RefPtr<MediaSample> > value1, MediaTime value2)
+    {
+        return value1.first < value2;
+    }
+};
+
+void SourceBuffer::sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, PassRefPtr<MediaSample> prpSample)
+{
+    if (isRemoved())
+        return;
+
+    RefPtr<MediaSample> sample = prpSample;
+
+    // 3.5.8 Coded Frame Processing
+    // When complete coded frames have been parsed by the segment parser loop then the following steps
+    // are run:
+    // 1. For each coded frame in the media segment run the following steps:
+    // 1.1. Loop Top
+    do {
+        // 1.1 (ctd) Let presentation timestamp be a double precision floating point representation of
+        // the coded frame's presentation timestamp in seconds.
+        MediaTime presentationTimestamp = sample->presentationTime();
+
+        // 1.2 Let decode timestamp be a double precision floating point representation of the coded frame's
+        // decode timestamp in seconds.
+        MediaTime decodeTimestamp = sample->decodeTime();
+
+        // 1.3 Let frame duration be a double precision floating point representation of the coded frame's
+        // duration in seconds.
+        MediaTime frameDuration = sample->duration();
+
+        // 1.4 If mode equals "sequence" and group start timestamp is set, then run the following steps:
+        // FIXME: add support for "sequence" mode
+
+        // 1.5 If timestampOffset is not 0, then run the following steps:
+        if (m_timestampOffset) {
+            // 1.5.1 Add timestampOffset to the presentation timestamp.
+            presentationTimestamp += m_timestampOffset;
+
+            // 1.5.2 Add timestampOffset to the decode timestamp.
+            decodeTimestamp += m_timestampOffset;
+
+            // 1.5.3 If the presentation timestamp or decode timestamp is less than the presentation start
+            // time, then run the end of stream algorithm with the error parameter set to "decode", and
+            // abort these steps.
+            MediaTime presentationStartTime = MediaTime::zeroTime();
+            if (presentationTimestamp < presentationStartTime || decodeTimestamp < presentationStartTime) {
+#if !LOG_DISABLED
+                LOG(MediaSource, "SourceBuffer::sourceBufferPrivateDidReceiveSample(%p) - failing because %s", this, presentationTimestamp < presentationStartTime ? "presentationTimestamp < presentationStartTime" : "decodeTimestamp < presentationStartTime");
+#endif
+                m_source->streamEndedWithError(decodeError(), IgnorableExceptionCode());
+                return;
+            }
+        }
+
+        // 1.6 Let track buffer equal the track buffer that the coded frame will be added to.
+        AtomicString trackID = sample->trackID();
+        auto it = m_trackBufferMap.find(trackID);
+        if (it == m_trackBufferMap.end())
+            it = m_trackBufferMap.add(trackID, TrackBuffer()).iterator;
+        TrackBuffer& trackBuffer = it->value;
+
+        // 1.7 If last decode timestamp for track buffer is set and decode timestamp is less than last
+        // decode timestamp:
+        // OR
+        // If last decode timestamp for track buffer is set and the difference between decode timestamp and
+        // last decode timestamp is greater than 2 times last frame duration:
+        if (trackBuffer.lastDecodeTimestamp.isValid() && (decodeTimestamp < trackBuffer.lastDecodeTimestamp
+            || abs(decodeTimestamp - trackBuffer.lastDecodeTimestamp) > (trackBuffer.lastFrameDuration * 2))) {
+            // 1.7.1 If mode equals "segments":
+            // Set highest presentation end timestamp to presentation timestamp.
+            m_highestPresentationEndTimestamp = presentationTimestamp;
+
+            // If mode equals "sequence":
+            // Set group start timestamp equal to the highest presentation end timestamp.
+            // FIXME: Add support for "sequence" mode.
+
+            HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
+            for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+                TrackBuffer& trackBuffer = it->value;
+                // 1.7.2 Unset the last decode timestamp on all track buffers.
+                trackBuffer.lastDecodeTimestamp = MediaTime::invalidTime();
+                // 1.7.3 Unset the last frame duration on all track buffers.
+                trackBuffer.lastFrameDuration = MediaTime::invalidTime();
+                // 1.7.4 Unset the highest presentation timestamp on all track buffers.
+                trackBuffer.highestPresentationTimestamp = MediaTime::invalidTime();
+                // 1.7.5 Set the need random access point flag on all track buffers to true.
+                trackBuffer.needRandomAccessFlag = true;
+            }
+
+            // 1.7.6 Jump to the Loop Top step above to restart processing of the current coded frame.
+            continue;
+        }
+
+        // 1.8 Let frame end timestamp equal the sum of presentation timestamp and frame duration.
+        MediaTime frameEndTimestamp = presentationTimestamp + frameDuration;
+
+        // 1.9 If presentation timestamp is less than appendWindowStart, then set the need random access
+        // point flag to true, drop the coded frame, and jump to the top of the loop to start processing
+        // the next coded frame.
+        // 1.10 If frame end timestamp is greater than appendWindowEnd, then set the need random access
+        // point flag to true, drop the coded frame, and jump to the top of the loop to start processing
+        // the next coded frame.
+        // FIXME: implement append windows
+
+        // 1.11 If the need random access point flag on track buffer equals true, then run the following steps:
+        if (trackBuffer.needRandomAccessFlag) {
+            // 1.11.1 If the coded frame is not a random access point, then drop the coded frame and jump
+            // to the top of the loop to start processing the next coded frame.
+            if (!sample->isSync()) {
+                didDropSample();
+                return;
+            }
+
+            // 1.11.2 Set the need random access point flag on track buffer to false.
+            trackBuffer.needRandomAccessFlag = false;
+        }
+
+        // 1.12 Let spliced audio frame be an unset variable for holding audio splice information
+        // 1.13 Let spliced timed text frame be an unset variable for holding timed text splice information
+        // FIXME: Add support for sample splicing.
+
+        SampleMap erasedSamples;
+        MediaTime microsecond(1, 1000000);
+
+        // 1.14 If last decode timestamp for track buffer is unset and presentation timestamp falls
+        // falls within the presentation interval of a coded frame in track buffer, then run the
+        // following steps:
+        if (trackBuffer.lastDecodeTimestamp.isInvalid()) {
+            auto iter = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(presentationTimestamp);
+            if (iter != trackBuffer.samples.presentationOrder().end()) {
+                // 1.14.1 Let overlapped frame be the coded frame in track buffer that matches the condition above.
+                RefPtr<MediaSample> overlappedFrame = iter->second;
+
+                // 1.14.2 If track buffer contains audio coded frames:
+                // Run the audio splice frame algorithm and if a splice frame is returned, assign it to
+                // spliced audio frame.
+                // FIXME: Add support for sample splicing.
+
+                // If track buffer contains video coded frames:
+                if (trackBuffer.description->isVideo()) {
+                    // 1.14.2.1 Let overlapped frame presentation timestamp equal the presentation timestamp
+                    // of overlapped frame.
+                    MediaTime overlappedFramePresentationTimestamp = overlappedFrame->presentationTime();
+
+                    // 1.14.2.2 Let remove window timestamp equal overlapped frame presentation timestamp
+                    // plus 1 microsecond.
+                    MediaTime removeWindowTimestamp = overlappedFramePresentationTimestamp + microsecond;
+
+                    // 1.14.2.3 If the presentation timestamp is less than the remove window timestamp,
+                    // then remove overlapped frame and any coded frames that depend on it from track buffer.
+                    if (presentationTimestamp < removeWindowTimestamp)
+                        erasedSamples.addSample(iter->second);
+                }
+
+                // If track buffer contains timed text coded frames:
+                // Run the text splice frame algorithm and if a splice frame is returned, assign it to spliced timed text frame.
+                // FIXME: Add support for sample splicing.
+            }
+        }
+
+        // 1.15 Remove existing coded frames in track buffer:
+        // If highest presentation timestamp for track buffer is not set:
+        if (trackBuffer.highestPresentationTimestamp.isInvalid()) {
+            // Remove all coded frames from track buffer that have a presentation timestamp greater than or
+            // equal to presentation timestamp and less than frame end timestamp.
+            auto iter_pair = trackBuffer.samples.presentationOrder().findSamplesBetweenPresentationTimes(presentationTimestamp, frameEndTimestamp);
+            if (iter_pair.first != trackBuffer.samples.presentationOrder().end())
+                erasedSamples.addRange(iter_pair.first, iter_pair.second);
+        }
+
+        // If highest presentation timestamp for track buffer is set and less than presentation timestamp
+        if (trackBuffer.highestPresentationTimestamp.isValid() && trackBuffer.highestPresentationTimestamp <= presentationTimestamp) {
+            // Remove all coded frames from track buffer that have a presentation timestamp greater than highest
+            // presentation timestamp and less than or equal to frame end timestamp.
+            do {
+                // NOTE: Searching from the end of the trackBuffer will be vastly more efficient if the search range is
+                // near the end of the buffered range. Use a linear-backwards search if the search range is within one
+                // frame duration of the end:
+                if (!m_buffered)
+                    break;
+
+                unsigned bufferedLength = m_buffered->ranges().length();
+                if (!bufferedLength)
+                    break;
+
+                bool ignoreValid;
+                MediaTime highestBufferedTime = m_buffered->ranges().end(bufferedLength - 1, ignoreValid);
+
+                PresentationOrderSampleMap::iterator_range range;
+                if (highestBufferedTime - trackBuffer.highestPresentationTimestamp < trackBuffer.lastFrameDuration)
+                    range = trackBuffer.samples.presentationOrder().findSamplesWithinPresentationRangeFromEnd(trackBuffer.highestPresentationTimestamp, frameEndTimestamp);
+                else
+                    range = trackBuffer.samples.presentationOrder().findSamplesWithinPresentationRange(trackBuffer.highestPresentationTimestamp, frameEndTimestamp);
+
+                if (range.first != trackBuffer.samples.presentationOrder().end())
+                    erasedSamples.addRange(range.first, range.second);
+            } while(false);
+        }
+
+        // 1.16 Remove decoding dependencies of the coded frames removed in the previous step:
+        DecodeOrderSampleMap::MapType dependentSamples;
+        if (!erasedSamples.empty()) {
+            // If detailed information about decoding dependencies is available:
+            // FIXME: Add support for detailed dependency information
+
+            // Otherwise: Remove all coded frames between the coded frames removed in the previous step
+            // and the next random access point after those removed frames.
+            auto firstDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().begin()->first);
+            auto lastDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().rbegin()->first);
+            auto nextSyncIter = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(lastDecodeIter);
+            dependentSamples.insert(firstDecodeIter, nextSyncIter);
+
+            RefPtr<TimeRanges> erasedRanges = removeSamplesFromTrackBuffer(dependentSamples, trackBuffer, this, "sourceBufferPrivateDidReceiveSample");
+
+            // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
+            // not yet displayed samples.
+            MediaTime currentMediaTime = m_source->currentTime();
+            if (currentMediaTime < trackBuffer.lastEnqueuedPresentationTime) {
+                PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.lastEnqueuedPresentationTime);
+                possiblyEnqueuedRanges.intersectWith(erasedRanges->ranges());
+                if (possiblyEnqueuedRanges.length())
+                    trackBuffer.needsReenqueueing = true;
+            }
+
+            erasedRanges->invert();
+            m_buffered->intersectWith(*erasedRanges);
+        }
+
+        // 1.17 If spliced audio frame is set:
+        // Add spliced audio frame to the track buffer.
+        // If spliced timed text frame is set:
+        // Add spliced timed text frame to the track buffer.
+        // FIXME: Add support for sample splicing.
+
+        // Otherwise:
+        // Add the coded frame with the presentation timestamp, decode timestamp, and frame duration to the track buffer.
+        trackBuffer.samples.addSample(sample);
+
+        if (trackBuffer.lastEnqueuedDecodeEndTime.isInvalid() || decodeTimestamp >= trackBuffer.lastEnqueuedDecodeEndTime) {
+            DecodeOrderSampleMap::KeyType decodeKey(decodeTimestamp, presentationTimestamp);
+            trackBuffer.decodeQueue.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, sample));
+        }
+
+        // 1.18 Set last decode timestamp for track buffer to decode timestamp.
+        trackBuffer.lastDecodeTimestamp = decodeTimestamp;
+
+        // 1.19 Set last frame duration for track buffer to frame duration.
+        trackBuffer.lastFrameDuration = frameDuration;
+
+        // 1.20 If highest presentation timestamp for track buffer is unset or frame end timestamp is greater
+        // than highest presentation timestamp, then set highest presentation timestamp for track buffer
+        // to frame end timestamp.
+        if (trackBuffer.highestPresentationTimestamp.isInvalid() || frameEndTimestamp > trackBuffer.highestPresentationTimestamp)
+            trackBuffer.highestPresentationTimestamp = frameEndTimestamp;
+
+        // 1.21 If highest presentation end timestamp is unset or frame end timestamp is greater than highest
+        // presentation end timestamp, then set highest presentation end timestamp equal to frame end timestamp.
+        if (m_highestPresentationEndTimestamp.isInvalid() || frameEndTimestamp > m_highestPresentationEndTimestamp)
+            m_highestPresentationEndTimestamp = frameEndTimestamp;
+
+        m_buffered->add(presentationTimestamp.toDouble(), (presentationTimestamp + frameDuration + microsecond).toDouble());
+        m_bufferedSinceLastMonitor += frameDuration.toDouble();
+
+        break;
+    } while (1);
+
+    // Steps 2-4 will be handled by MediaSource::monitorSourceBuffers()
+
+    // 5. If the media segment contains data beyond the current duration, then run the duration change algorithm with new
+    // duration set to the maximum of the current duration and the highest end timestamp reported by HTMLMediaElement.buffered.
+    if (highestPresentationEndTimestamp() > m_source->duration())
+        m_source->setDurationInternal(highestPresentationEndTimestamp());
+}
+
+bool SourceBuffer::hasAudio() const
+{
+    return m_audioTracks && m_audioTracks->length();
+}
+
+bool SourceBuffer::hasVideo() const
+{
+    return m_videoTracks && m_videoTracks->length();
+}
+
+bool SourceBuffer::sourceBufferPrivateHasAudio(const SourceBufferPrivate*) const
+{
+    return hasAudio();
+}
+
+bool SourceBuffer::sourceBufferPrivateHasVideo(const SourceBufferPrivate*) const
+{
+    return hasVideo();
+}
+
+void SourceBuffer::videoTrackSelectedChanged(VideoTrack* track)
+{
+    // 2.4.5 Changes to selected/enabled track state
+    // If the selected video track changes, then run the following steps:
+    // 1. If the SourceBuffer associated with the previously selected video track is not associated with
+    // any other enabled tracks, run the following steps:
+    if (track->selected()
+        && (!m_videoTracks || !m_videoTracks->isAnyTrackEnabled())
+        && (!m_audioTracks || !m_audioTracks->isAnyTrackEnabled())
+        && (!m_textTracks || !m_textTracks->isAnyTrackEnabled())) {
+        // 1.1 Remove the SourceBuffer from activeSourceBuffers.
+        // 1.2 Queue a task to fire a simple event named removesourcebuffer at activeSourceBuffers
+        setActive(false);
+    } else if (!track->selected()) {
+        // 2. If the SourceBuffer associated with the newly selected video track is not already in activeSourceBuffers,
+        // run the following steps:
+        // 2.1 Add the SourceBuffer to activeSourceBuffers.
+        // 2.2 Queue a task to fire a simple event named addsourcebuffer at activeSourceBuffers
+        setActive(true);
+    }
+
+    if (!isRemoved())
+        m_source->mediaElement()->videoTrackSelectedChanged(track);
+}
+
+void SourceBuffer::audioTrackEnabledChanged(AudioTrack* track)
+{
+    // 2.4.5 Changes to selected/enabled track state
+    // If an audio track becomes disabled and the SourceBuffer associated with this track is not
+    // associated with any other enabled or selected track, then run the following steps:
+    if (track->enabled()
+        && (!m_videoTracks || !m_videoTracks->isAnyTrackEnabled())
+        && (!m_audioTracks || !m_audioTracks->isAnyTrackEnabled())
+        && (!m_textTracks || !m_textTracks->isAnyTrackEnabled())) {
+        // 1. Remove the SourceBuffer associated with the audio track from activeSourceBuffers
+        // 2. Queue a task to fire a simple event named removesourcebuffer at activeSourceBuffers
+        setActive(false);
+    } else if (!track->enabled()) {
+        // If an audio track becomes enabled and the SourceBuffer associated with this track is
+        // not already in activeSourceBuffers, then run the following steps:
+        // 1. Add the SourceBuffer associated with the audio track to activeSourceBuffers
+        // 2. Queue a task to fire a simple event named addsourcebuffer at activeSourceBuffers
+        setActive(true);
+    }
+
+    if (!isRemoved())
+        m_source->mediaElement()->audioTrackEnabledChanged(track);
+}
+
+void SourceBuffer::textTrackModeChanged(TextTrack* track)
+{
+    // 2.4.5 Changes to selected/enabled track state
+    // If a text track mode becomes "disabled" and the SourceBuffer associated with this track is not
+    // associated with any other enabled or selected track, then run the following steps:
+    if (track->mode() == TextTrack::disabledKeyword()
+        && (!m_videoTracks || !m_videoTracks->isAnyTrackEnabled())
+        && (!m_audioTracks || !m_audioTracks->isAnyTrackEnabled())
+        && (!m_textTracks || !m_textTracks->isAnyTrackEnabled())) {
+        // 1. Remove the SourceBuffer associated with the audio track from activeSourceBuffers
+        // 2. Queue a task to fire a simple event named removesourcebuffer at activeSourceBuffers
+        setActive(false);
+    } else {
+        // If a text track mode becomes "showing" or "hidden" and the SourceBuffer associated with this
+        // track is not already in activeSourceBuffers, then run the following steps:
+        // 1. Add the SourceBuffer associated with the text track to activeSourceBuffers
+        // 2. Queue a task to fire a simple event named addsourcebuffer at activeSourceBuffers
+        setActive(true);
+    }
+
+    if (!isRemoved())
+        m_source->mediaElement()->textTrackModeChanged(track);
+}
+
+void SourceBuffer::textTrackAddCue(TextTrack* track, WTF::PassRefPtr<TextTrackCue> cue)
+{
+    if (!isRemoved())
+        m_source->mediaElement()->textTrackAddCue(track, cue);
+}
+
+void SourceBuffer::textTrackAddCues(TextTrack* track, TextTrackCueList const* cueList)
+{
+    if (!isRemoved())
+        m_source->mediaElement()->textTrackAddCues(track, cueList);
+}
+
+void SourceBuffer::textTrackRemoveCue(TextTrack* track, WTF::PassRefPtr<TextTrackCue> cue)
+{
+    if (!isRemoved())
+        m_source->mediaElement()->textTrackRemoveCue(track, cue);
+}
+
+void SourceBuffer::textTrackRemoveCues(TextTrack* track, TextTrackCueList const* cueList)
+{
+    if (!isRemoved())
+        m_source->mediaElement()->textTrackRemoveCues(track, cueList);
+}
+
+void SourceBuffer::textTrackKindChanged(TextTrack* track)
+{
+    if (!isRemoved())
+        m_source->mediaElement()->textTrackKindChanged(track);
+}
+
+void SourceBuffer::sourceBufferPrivateDidBecomeReadyForMoreSamples(SourceBufferPrivate*, AtomicString trackID)
+{
+    LOG(MediaSource, "SourceBuffer::sourceBufferPrivateDidBecomeReadyForMoreSamples(%p)", this);
+    auto it = m_trackBufferMap.find(trackID);
+    if (it == m_trackBufferMap.end())
+        return;
+
+    TrackBuffer& trackBuffer = it->value;
+    if (!trackBuffer.needsReenqueueing && !m_source->isSeeking())
+        provideMediaData(trackBuffer, trackID);
+}
+
+void SourceBuffer::provideMediaData(TrackBuffer& trackBuffer, AtomicString trackID)
+{
+#if !LOG_DISABLED
+    unsigned enqueuedSamples = 0;
+#endif
+
+    DecodeOrderSampleMap::iterator sampleIt = trackBuffer.decodeQueue.begin();
+    for (auto sampleEnd = trackBuffer.decodeQueue.end(); sampleIt != sampleEnd; ++sampleIt) {
+        if (!m_private->isReadyForMoreSamples(trackID)) {
+            m_private->notifyClientWhenReadyForMoreSamples(trackID);
+            break;
+        }
+
+        RefPtr<MediaSample> sample = sampleIt->second;
+        // Do not enqueue samples spanning a significant unbuffered gap.
+        // NOTE: one second is somewhat arbitrary. MediaSource::monitorSourceBuffers() is run
+        // on the playbackTimer, which is effectively every 350ms. Allowing > 350ms gap between
+        // enqueued samples allows for situations where we overrun the end of a buffered range
+        // but don't notice for 350s of playback time, and the client can enqueue data for the
+        // new current time without triggering this early return.
+        // FIXME(135867): Make this gap detection logic less arbitrary.
+        MediaTime oneSecond(1, 1);
+        if (trackBuffer.lastEnqueuedDecodeEndTime.isValid() && sample->decodeTime() - trackBuffer.lastEnqueuedDecodeEndTime > oneSecond)
+            break;
+
+        trackBuffer.lastEnqueuedPresentationTime = sample->presentationTime();
+        trackBuffer.lastEnqueuedDecodeEndTime = sample->decodeTime() + sample->duration();
+        m_private->enqueueSample(sample.release(), trackID);
+#if !LOG_DISABLED
+        ++enqueuedSamples;
+#endif
+
+    }
+    trackBuffer.decodeQueue.erase(trackBuffer.decodeQueue.begin(), sampleIt);
+
+    LOG(MediaSource, "SourceBuffer::provideMediaData(%p) - Enqueued %u samples", this, enqueuedSamples);
+}
+
+void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, AtomicString trackID, const MediaTime& time)
+{
+    // Find the sample which contains the current presentation time.
+    auto currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
+
+    if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end()) {
+        trackBuffer.decodeQueue.clear();
+        m_private->flushAndEnqueueNonDisplayingSamples(Vector<RefPtr<MediaSample> >(), trackID);
+        return;
+    }
+
+    // Seach backward for the previous sync sample.
+    DecodeOrderSampleMap::KeyType decodeKey(currentSamplePTSIterator->second->decodeTime(), currentSamplePTSIterator->second->presentationTime());
+    auto currentSampleDTSIterator = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(decodeKey);
+    ASSERT(currentSampleDTSIterator != trackBuffer.samples.decodeOrder().end());
+
+    auto reverseCurrentSampleIter = --DecodeOrderSampleMap::reverse_iterator(currentSampleDTSIterator);
+    auto reverseLastSyncSampleIter = trackBuffer.samples.decodeOrder().findSyncSamplePriorToDecodeIterator(reverseCurrentSampleIter);
+    if (reverseLastSyncSampleIter == trackBuffer.samples.decodeOrder().rend()) {
+        trackBuffer.decodeQueue.clear();
+        m_private->flushAndEnqueueNonDisplayingSamples(Vector<RefPtr<MediaSample> >(), trackID);
+        return;
+    }
+
+    Vector<RefPtr<MediaSample> > nonDisplayingSamples;
+    for (auto iter = reverseLastSyncSampleIter; iter != reverseCurrentSampleIter; --iter)
+        nonDisplayingSamples.append(iter->second);
+
+    m_private->flushAndEnqueueNonDisplayingSamples(nonDisplayingSamples, trackID);
+
+    if (!nonDisplayingSamples.isEmpty()) {
+        trackBuffer.lastEnqueuedPresentationTime = nonDisplayingSamples.last()->presentationTime();
+        trackBuffer.lastEnqueuedDecodeEndTime = nonDisplayingSamples.last()->decodeTime();
+    } else {
+        trackBuffer.lastEnqueuedPresentationTime = MediaTime::invalidTime();
+        trackBuffer.lastEnqueuedDecodeEndTime = MediaTime::invalidTime();
+    }
+
+    // Fill the decode queue with the remaining samples.
+    trackBuffer.decodeQueue.clear();
+    for (auto iter = currentSampleDTSIterator; iter != trackBuffer.samples.decodeOrder().end(); ++iter)
+        trackBuffer.decodeQueue.insert(*iter);
+    provideMediaData(trackBuffer, trackID);
+
+    trackBuffer.needsReenqueueing = false;
+}
+
+
+void SourceBuffer::didDropSample()
+{
+    if (!isRemoved())
+        m_source->mediaElement()->incrementDroppedFrameCount();
+}
+
+void SourceBuffer::monitorBufferingRate()
+{
+    if (!m_bufferedSinceLastMonitor)
+        return;
+
+    double now = monotonicallyIncreasingTime();
+    double interval = now - m_timeOfBufferingMonitor;
+    double rateSinceLastMonitor = m_bufferedSinceLastMonitor / interval;
+
+    m_timeOfBufferingMonitor = now;
+    m_bufferedSinceLastMonitor = 0;
+
+    m_averageBufferRate = m_averageBufferRate * (1 - ExponentialMovingAverageCoefficient) + rateSinceLastMonitor * ExponentialMovingAverageCoefficient;
+
+    LOG(MediaSource, "SourceBuffer::monitorBufferingRate(%p) - m_avegareBufferRate: %lf", this, m_averageBufferRate);
+}
+
+std::unique_ptr<PlatformTimeRanges> SourceBuffer::bufferedAccountingForEndOfStream() const
+{
+    // FIXME: Revisit this method once the spec bug <https://www.w3.org/Bugs/Public/show_bug.cgi?id=26436> is resolved.
+    std::unique_ptr<PlatformTimeRanges> virtualRanges = PlatformTimeRanges::create(m_buffered->ranges());
+    if (m_source->isEnded()) {
+        MediaTime start = virtualRanges->maximumBufferedTime();
+        MediaTime end = m_source->duration();
+        if (start <= end)
+            virtualRanges->add(start, end);
+    }
+    return virtualRanges;
+}
+
+bool SourceBuffer::hasCurrentTime() const
+{
+    if (isRemoved() || !m_buffered->length())
+        return false;
+
+    MediaTime currentTime = m_source->currentTime();
+    MediaTime duration = m_source->duration();
+    if (currentTime >= duration)
+        return true;
+
+    std::unique_ptr<PlatformTimeRanges> ranges = bufferedAccountingForEndOfStream();
+    return abs(ranges->nearest(currentTime) - currentTime) <= currentTimeFudgeFactor();
+}
+
+bool SourceBuffer::hasFutureTime() const
+{
+    if (isRemoved())
+        return false;
+
+    std::unique_ptr<PlatformTimeRanges> ranges = bufferedAccountingForEndOfStream();
+    if (!ranges->length())
+        return false;
+
+    MediaTime currentTime = m_source->currentTime();
+    MediaTime duration = m_source->duration();
+    if (currentTime >= duration)
+        return true;
+
+    MediaTime nearest = ranges->nearest(currentTime);
+    if (abs(nearest - currentTime) > currentTimeFudgeFactor())
+        return false;
+
+    size_t found = ranges->find(nearest);
+    if (found == notFound)
+        return false;
+
+    MediaTime localEnd = ranges->end(found);
+    if (localEnd == duration)
+        return true;
+
+    return localEnd - currentTime > currentTimeFudgeFactor();
+}
+
+bool SourceBuffer::canPlayThrough()
+{
+    if (isRemoved())
+        return false;
+
+    monitorBufferingRate();
+
+    // Assuming no fluctuations in the buffering rate, loading 1 second per second or greater
+    // means indefinite playback. This could be improved by taking jitter into account.
+    if (m_averageBufferRate > 1)
+        return true;
+
+    // Add up all the time yet to be buffered.
+    MediaTime currentTime = m_source->currentTime();
+    MediaTime duration = m_source->duration();
+
+    std::unique_ptr<PlatformTimeRanges> unbufferedRanges = bufferedAccountingForEndOfStream();
+    unbufferedRanges->invert();
+    unbufferedRanges->intersectWith(PlatformTimeRanges(currentTime, std::max(currentTime, duration)));
+    MediaTime unbufferedTime = unbufferedRanges->totalDuration();
+    if (!unbufferedTime.isValid())
+        return true;
+
+    MediaTime timeRemaining = duration - currentTime;
+    return unbufferedTime.toDouble() / m_averageBufferRate < timeRemaining.toDouble();
+}
+
+size_t SourceBuffer::extraMemoryCost() const
+{
+    size_t extraMemoryCost = m_pendingAppendData.capacity();
+    for (auto& trackBuffer : m_trackBufferMap.values())
+        extraMemoryCost += trackBuffer.samples.sizeInBytes();
+
+    return extraMemoryCost;
+}
+
+void SourceBuffer::reportExtraMemoryCost()
+{
+    size_t extraMemoryCost = this->extraMemoryCost();
+    if (extraMemoryCost < m_reportedExtraMemoryCost)
+        return;
+
+    size_t extraMemoryCostDelta = extraMemoryCost - m_reportedExtraMemoryCost;
+    m_reportedExtraMemoryCost = extraMemoryCost;
+
+    JSC::JSLockHolder lock(scriptExecutionContext()->vm());
+    if (extraMemoryCostDelta > 0)
+        scriptExecutionContext()->vm().heap.reportExtraMemoryCost(extraMemoryCostDelta);
+}
+
+Vector<String> SourceBuffer::bufferedSamplesForTrackID(const AtomicString& trackID)
+{
+    HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.find(trackID);
+    if (it == m_trackBufferMap.end())
+        return Vector<String>();
+
+    TrackBuffer& trackBuffer = it->value;
+    Vector<String> sampleDescriptions;
+    DecodeOrderSampleMap::iterator end = trackBuffer.samples.decodeOrder().end();
+    for (DecodeOrderSampleMap::iterator it = trackBuffer.samples.decodeOrder().begin(); it != end; ++it) {
+        sampleDescriptions.append(toString(*it.second));
+    }
+
+    return sampleDescriptions;
+}
+
+Document& SourceBuffer::document() const
+{
+    ASSERT(scriptExecutionContext());
+    return downcast<Document>(*scriptExecutionContext());
 }
 
 } // namespace WebCore
diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.h b/Source/WebCore/Modules/mediasource/SourceBuffer.h
index a35e325..feb7c87 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.h
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.h
@@ -1,5 +1,6 @@
 /*
- * Copyright (C) 2012 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ * Copyright (C) 2013-2014 Apple Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -33,45 +34,192 @@
 
 #if ENABLE(MEDIA_SOURCE)
 
+#include "ActiveDOMObject.h"
+#include "AudioTrack.h"
+#include "EventTarget.h"
 #include "ExceptionCode.h"
+#include "GenericEventQueue.h"
+#include "ScriptWrappable.h"
+#include "SourceBufferPrivateClient.h"
+#include "TextTrack.h"
+#include "Timer.h"
+#include "VideoTrack.h"
+#include <wtf/ArrayBufferView.h>
+#include <wtf/PassOwnPtr.h>
 #include <wtf/PassRefPtr.h>
 #include <wtf/RefCounted.h>
 #include <wtf/text/WTFString.h>
 
 namespace WebCore {
+
+class AudioTrackList;
 class MediaSource;
+class PlatformTimeRanges;
 class SourceBufferPrivate;
+class TextTrackList;
 class TimeRanges;
+class VideoTrackList;
 
-class SourceBuffer : public RefCounted<SourceBuffer> {
+class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, public EventTarget, public ScriptWrappable, public SourceBufferPrivateClient, public AudioTrackClient, public VideoTrackClient, public TextTrackClient {
 public:
     static PassRefPtr<SourceBuffer> create(PassOwnPtr<SourceBufferPrivate>, PassRefPtr<MediaSource>);
 
     virtual ~SourceBuffer();
 
     // SourceBuffer.idl methods
+    bool updating() const { return m_updating; }
     PassRefPtr<TimeRanges> buffered(ExceptionCode&) const;
+    const RefPtr<TimeRanges>& buffered() const;
     double timestampOffset() const;
     void setTimestampOffset(double, ExceptionCode&);
-    void append(PassRefPtr<Uint8Array> data, ExceptionCode&);
+    void appendBuffer(PassRefPtr<ArrayBuffer> data, ExceptionCode&);
+    void appendBuffer(PassRefPtr<ArrayBufferView> data, ExceptionCode&);
     void abort(ExceptionCode&);
+    void remove(double start, double end, ExceptionCode&);
+    void remove(const MediaTime&, const MediaTime&, ExceptionCode&);
 
+    void abortIfUpdating();
     void removedFromMediaSource();
+    const MediaTime& highestPresentationEndTimestamp() const { return m_highestPresentationEndTimestamp; }
+    void seekToTime(const MediaTime&);
+
+#if ENABLE(VIDEO_TRACK)
+    VideoTrackList* videoTracks();
+    AudioTrackList* audioTracks();
+    TextTrackList* textTracks();
+#endif
+
+    bool hasCurrentTime() const;
+    bool hasFutureTime() const;
+    bool canPlayThrough();
+
+    bool hasVideo() const;
+    bool hasAudio() const;
+
+    bool active() const { return m_active; }
+
+    // ActiveDOMObject interface
+    virtual bool hasPendingActivity();
+    virtual void stop();
+
+    // EventTarget interface
+    virtual ScriptExecutionContext* scriptExecutionContext() { return ActiveDOMObject::scriptExecutionContext(); }
+
+    using RefCounted<SourceBuffer>::ref;
+    using RefCounted<SourceBuffer>::deref;
+
+    struct TrackBuffer;
+
+    Document& document() const;
+
+protected:
+    // EventTarget interface
+    virtual void refEventTarget() { ref(); }
+    virtual void derefEventTarget() { deref(); }
 
 private:
     SourceBuffer(PassOwnPtr<SourceBufferPrivate>, PassRefPtr<MediaSource>);
 
+    // SourceBufferPrivateClient
+    virtual void sourceBufferPrivateDidEndStream(SourceBufferPrivate*, const WTF::AtomicString&);
+    virtual void sourceBufferPrivateDidReceiveInitializationSegment(SourceBufferPrivate*, const InitializationSegment&);
+    virtual void sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, PassRefPtr<MediaSample>);
+    virtual bool sourceBufferPrivateHasAudio(const SourceBufferPrivate*);
+    virtual bool sourceBufferPrivateHasVideo(const SourceBufferPrivate*);
+    virtual void sourceBufferPrivateDidBecomeReadyForMoreSamples(SourceBufferPrivate*, AtomicString trackID);
+    virtual MediaTime sourceBufferPrivateFastSeekTimeForMediaTime(SourceBufferPrivate*, const MediaTime&, const MediaTime& negativeThreshold, const MediaTime& positiveThreshold);
+    virtual void sourceBufferPrivateAppendComplete(SourceBufferPrivate*, AppendResult);
+    virtual void sourceBufferPrivateDidReceiveRenderingError(SourceBufferPrivate*, int errorCode);
+
+    // AudioTrackClient
+    virtual void audioTrackEnabledChanged(AudioTrack*);
+
+    // VideoTrackClient
+    virtual void videoTrackSelectedChanged(VideoTrack*);
+
+    // TextTrackClient
+    virtual void textTrackKindChanged(TextTrack*);
+    virtual void textTrackModeChanged(TextTrack*);
+    virtual void textTrackAddCues(TextTrack*, const TextTrackCueList*);
+    virtual void textTrackRemoveCues(TextTrack*, const TextTrackCueList*);
+    virtual void textTrackAddCue(TextTrack*, PassRefPtr<TextTrackCue>);
+    virtual void textTrackRemoveCue(TextTrack*, PassRefPtr<TextTrackCue>);
+
+    static const WTF::AtomicString& decodeError();
+    static const WTF::AtomicString& networkError();
+
     bool isRemoved() const;
-    bool isOpen() const;
-    bool isEnded() const;
+    void scheduleEvent(const AtomicString& eventName);
+
+    void appendBufferInternal(unsigned char*, unsigned, ExceptionCode&);
+    void appendBufferTimerFired(Timer<SourceBuffer>*);
+
+    void setActive(bool);
+
+    bool validateInitializationSegment(const InitializationSegment&);
+
+    void reenqueueMediaForTime(TrackBuffer&, AtomicString trackID, const MediaTime&);
+    void provideMediaData(TrackBuffer&, AtomicString trackID);
+    void didDropSample();
+    void evictCodedFrames(size_t newDataSize);
+    size_t maximumBufferSize() const;
+
+    void monitorBufferingRate();
+
+    void removeTimerFired(Timer<SourceBuffer>*);
+    void removeCodedFrames(const MediaTime& start, const MediaTime& end);
+
+    size_t extraMemoryCost() const;
+    void reportExtraMemoryCost();
+
+    PassOwnPtr<PlatformTimeRanges> bufferedAccountingForEndOfStream() const;
+
+    // Internals
+    friend class Internals;
+    Vector<String> bufferedSamplesForTrackID(const AtomicString&);
 
     OwnPtr<SourceBufferPrivate> m_private;
-    RefPtr<MediaSource> m_source;
+    MediaSource* m_source;
+    GenericEventQueue m_asyncEventQueue;
+
+    Vector<unsigned char> m_pendingAppendData;
+    Timer<SourceBuffer> m_appendBufferTimer;
 
-    double m_timestampOffset;
+    RefPtr<VideoTrackList> m_videoTracks;
+    RefPtr<AudioTrackList> m_audioTracks;
+    RefPtr<TextTrackList> m_textTracks;
+
+    Vector<AtomicString> m_videoCodecs;
+    Vector<AtomicString> m_audioCodecs;
+    Vector<AtomicString> m_textCodecs;
+
+    MediaTime m_timestampOffset;
+    MediaTime m_highestPresentationEndTimestamp;
+
+    HashMap<AtomicString, TrackBuffer> m_trackBufferMap;
+    RefPtr<TimeRanges> m_buffered;
+
+    enum AppendStateType { WaitingForSegment, ParsingInitSegment, ParsingMediaSegment };
+    AppendStateType m_appendState;
+
+    double m_timeOfBufferingMonitor;
+    double m_bufferedSinceLastMonitor;
+    double m_averageBufferRate;
+
+    size_t m_reportedExtraMemoryCost;
+
+    MediaTime m_pendingRemoveStart;
+    MediaTime m_pendingRemoveEnd;
+    Timer<SourceBuffer> m_removeTimer;
+
+    bool m_updating;
+    bool m_receivedFirstInitializationSegment;
+    bool m_active;
+    bool m_bufferFull;
 };
 
 } // namespace WebCore
 
 #endif
+
 #endif
diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.idl b/Source/WebCore/Modules/mediasource/SourceBuffer.idl
index 71f2b6b..45a465b 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.idl
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.idl
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2012 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -30,9 +30,15 @@
  
 [
     Conditional=MEDIA_SOURCE,
-    InterfaceName=WebKitSourceBuffer
-] interface SourceBuffer {
+    NoInterfaceObject,
+    ActiveDOMObject,
+    EventTarget,
+    JSGenerateToJSObject,
+    JSGenerateToNativeObject,
+] interface SourceBuffer : EventTarget {
 
+    readonly attribute boolean updating;
+  
     // Returns the time ranges buffered.
     [GetterRaisesException] readonly attribute TimeRanges buffered;
 
@@ -40,9 +46,16 @@
     [SetterRaisesException] attribute double timestampOffset;
 
     // Append segment data.
-    [RaisesException] void append(Uint8Array data);
+    [RaisesException] void appendBuffer(ArrayBuffer data);
+    [RaisesException] void appendBuffer(ArrayBufferView data);
 
     // Abort the current segment append sequence.
     [RaisesException] void abort();
+    [RaisesException] void remove(double start, double end);
+    
+    // Track support
+    [Conditional=VIDEO_TRACK] readonly attribute AudioTrackList audioTracks;
+    [Conditional=VIDEO_TRACK] readonly attribute VideoTrackList videoTracks;
+    [Conditional=VIDEO_TRACK] readonly attribute TextTrackList textTracks;
 };
 
diff --git a/Source/WebCore/Modules/mediasource/SourceBufferList.cpp b/Source/WebCore/Modules/mediasource/SourceBufferList.cpp
index 11dd91c..94be379 100644
--- a/Source/WebCore/Modules/mediasource/SourceBufferList.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBufferList.cpp
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2012 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -34,85 +34,68 @@
 #if ENABLE(MEDIA_SOURCE)
 
 #include "Event.h"
-#include "GenericEventQueue.h"
 #include "SourceBuffer.h"
 
 namespace WebCore {
 
-SourceBufferList::SourceBufferList(ScriptExecutionContext* context,
-                                   GenericEventQueue* asyncEventQueue)
+SourceBufferList::SourceBufferList(ScriptExecutionContext* context)
     : m_scriptExecutionContext(context)
-    , m_asyncEventQueue(asyncEventQueue)
+    , m_asyncEventQueue(GenericEventQueue::create(this))
 {
 }
 
-unsigned long SourceBufferList::length() const
+SourceBufferList::~SourceBufferList()
 {
-    return m_list.size();
-}
-
-SourceBuffer* SourceBufferList::item(unsigned index) const
-{
-    if (index >= m_list.size())
-        return 0;
-    return m_list[index].get();
+    ASSERT(m_list.isEmpty());
 }
 
 void SourceBufferList::add(PassRefPtr<SourceBuffer> buffer)
 {
     m_list.append(buffer);
-    createAndFireEvent(eventNames().webkitaddsourcebufferEvent);
+    scheduleEvent(eventNames().addsourcebufferEvent);
 }
 
-bool SourceBufferList::remove(SourceBuffer* buffer)
+void SourceBufferList::remove(SourceBuffer* buffer)
 {
     size_t index = m_list.find(buffer);
     if (index == notFound)
-        return false;
-
-    buffer->removedFromMediaSource();
+        return;
     m_list.remove(index);
-    createAndFireEvent(eventNames().webkitremovesourcebufferEvent);
-    return true;
+    scheduleEvent(eventNames().removesourcebufferEvent);
 }
 
 void SourceBufferList::clear()
 {
-    for (size_t i = 0; i < m_list.size(); ++i)
-        m_list[i]->removedFromMediaSource();
     m_list.clear();
-    createAndFireEvent(eventNames().webkitremovesourcebufferEvent);
+    scheduleEvent(eventNames().removesourcebufferEvent);
 }
 
-void SourceBufferList::createAndFireEvent(const AtomicString& eventName)
+void SourceBufferList::swap(Vector<RefPtr <SourceBuffer> >& other)
 {
-    ASSERT(m_asyncEventQueue);
+    int changeInSize = other.size() - m_list.size();
+    int addedEntries = 0;
+    for (size_t i = 0; i < other.size(); ++i) {
+        if (!m_list.contains(other[i].get()))
+            ++addedEntries;
+    }
+    int removedEntries = addedEntries - changeInSize;
+
+    m_list.swap(other);
+
+    if (addedEntries)
+        scheduleEvent(eventNames().addsourcebufferEvent);
+    if (removedEntries)
+        scheduleEvent(eventNames().removesourcebufferEvent);
+}
 
+void SourceBufferList::scheduleEvent(const AtomicString& eventName)
+{
     RefPtr<Event> event = Event::create(eventName, false, false);
     event->setTarget(this);
 
     m_asyncEventQueue->enqueueEvent(event.release());
 }
 
-const AtomicString& SourceBufferList::interfaceName() const
-{
-    return eventNames().interfaceForSourceBufferList;
-}
-
-ScriptExecutionContext* SourceBufferList::scriptExecutionContext() const
-{
-    return m_scriptExecutionContext;
-}
-
-EventTargetData* SourceBufferList::eventTargetData()
-{
-    return &m_eventTargetData;
-}
-
-EventTargetData* SourceBufferList::ensureEventTargetData()
-{
-    return &m_eventTargetData;
-}
 
 } // namespace WebCore
 
diff --git a/Source/WebCore/Modules/mediasource/SourceBufferList.h b/Source/WebCore/Modules/mediasource/SourceBufferList.h
index 0d4764e..27a418e 100644
--- a/Source/WebCore/Modules/mediasource/SourceBufferList.h
+++ b/Source/WebCore/Modules/mediasource/SourceBufferList.h
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2012 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -34,56 +34,62 @@
 #if ENABLE(MEDIA_SOURCE)
 
 #include "EventTarget.h"
+#include "GenericEventQueue.h"
+#include "ScriptWrappable.h"
 #include <wtf/RefCounted.h>
 #include <wtf/Vector.h>
 
 namespace WebCore {
 
 class SourceBuffer;
-class GenericEventQueue;
 
-class SourceBufferList : public RefCounted<SourceBufferList>, public EventTarget {
+class SourceBufferList : public RefCounted<SourceBufferList>, public ScriptWrappable, public EventTarget {
 public:
-    static PassRefPtr<SourceBufferList> create(ScriptExecutionContext* context, GenericEventQueue* asyncEventQueue)
+    static PassRefPtr<SourceBufferList> create(ScriptExecutionContext* context)
     {
-        return adoptRef(new SourceBufferList(context, asyncEventQueue));
+        return adoptRef(new SourceBufferList(context));
     }
-    virtual ~SourceBufferList() { }
+    virtual ~SourceBufferList();
 
-    unsigned long length() const;
-    SourceBuffer* item(unsigned index) const;
+    unsigned long length() const { return m_list.size(); }
+    SourceBuffer* item(unsigned long index) const { return (index < m_list.size()) ? m_list[index].get() : 0; }
 
     void add(PassRefPtr<SourceBuffer>);
-    bool remove(SourceBuffer*);
+    void remove(SourceBuffer*);
+    bool contains(SourceBuffer* buffer) { return m_list.find(buffer) != notFound; }
     void clear();
+    void swap(Vector<RefPtr <SourceBuffer> >&);
+
+    Vector<RefPtr <SourceBuffer> >::iterator begin() { return m_list.begin(); }
+    Vector<RefPtr <SourceBuffer> >::iterator end() { return m_list.end(); }
 
     // EventTarget interface
-    virtual const AtomicString& interfaceName() const OVERRIDE;
-    virtual ScriptExecutionContext* scriptExecutionContext() const OVERRIDE;
+    virtual const AtomicString& interfaceName() const; 
+    virtual ScriptExecutionContext* scriptExecutionContext() const { return m_scriptExecutionContext; }
+    virtual EventTargetData* eventTargetData() { return &m_eventTargetData; }
+    virtual EventTargetData* ensureEventTargetData() { return &m_eventTargetData; }
 
     using RefCounted<SourceBufferList>::ref;
     using RefCounted<SourceBufferList>::deref;
 
-protected:
-    virtual EventTargetData* eventTargetData() OVERRIDE;
-    virtual EventTargetData* ensureEventTargetData() OVERRIDE;
-
 private:
-    SourceBufferList(ScriptExecutionContext*, GenericEventQueue*);
+    explicit SourceBufferList(ScriptExecutionContext*);
 
-    void createAndFireEvent(const AtomicString&);
+    void scheduleEvent(const AtomicString&);
 
-    virtual void refEventTarget() OVERRIDE { ref(); }
-    virtual void derefEventTarget() OVERRIDE { deref(); }
+    virtual void refEventTarget() { ref(); }
+    virtual void derefEventTarget() { deref(); }
 
-    EventTargetData m_eventTargetData;
     ScriptExecutionContext* m_scriptExecutionContext;
-    GenericEventQueue* m_asyncEventQueue;
+    OwnPtr<GenericEventQueue> m_asyncEventQueue;
 
-    Vector<RefPtr<SourceBuffer> > m_list;
+    EventTargetData m_eventTargetData;
+
+    Vector<RefPtr <SourceBuffer> > m_list;
 };
 
 } // namespace WebCore
 
 #endif
+
 #endif
diff --git a/Source/WebCore/Modules/mediasource/SourceBufferList.idl b/Source/WebCore/Modules/mediasource/SourceBufferList.idl
index 5b14ad8..d3b36df 100644
--- a/Source/WebCore/Modules/mediasource/SourceBufferList.idl
+++ b/Source/WebCore/Modules/mediasource/SourceBufferList.idl
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2012 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Google Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -30,19 +30,14 @@
  
 [
     Conditional=MEDIA_SOURCE,
+    NoInterfaceObject,
     EventTarget,
-    InterfaceName=WebKitSourceBufferList
-] interface SourceBufferList {
+    JSGenerateToJSObject,
+    JSGenerateToNativeObject,
+    GenerateIsReachable=Impl,
+    CallWith=ScriptExecutionContext,
+] interface SourceBufferList : EventTarget {
     readonly attribute unsigned long length;
     getter SourceBuffer item(unsigned long index);
-
-    // EventTarget interface
-    void addEventListener(DOMString type,
-                          EventListener listener,
-                          optional boolean useCapture);
-    void removeEventListener(DOMString type,
-                             EventListener listener,
-                             optional boolean useCapture);
-    [RaisesException] boolean dispatchEvent(Event event);
 };
 
diff --git a/Source/WebCore/Modules/mediasource/TextTrackMediaSource.h b/Source/WebCore/Modules/mediasource/TextTrackMediaSource.h
new file mode 100644
index 0000000..f0595e5
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/TextTrackMediaSource.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+#ifndef TextTrackMediaSource_h
+#define TextTrackMediaSource_h
+
+#if ENABLE(MEDIA_SOURCE) && ENABLE(VIDEO_TRACK)
+
+#include "TextTrack.h"
+
+namespace WebCore {
+
+class SourceBuffer;
+
+class TextTrackMediaSource {
+public:
+    static SourceBuffer* sourceBuffer(TextTrack* track) { return track->sourceBuffer(); }
+};
+
+}
+
+#endif
+
+#endif
diff --git a/Source/WebCore/Modules/mediasource/TextTrackMediaSource.idl b/Source/WebCore/Modules/mediasource/TextTrackMediaSource.idl
new file mode 100644
index 0000000..88ed22f
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/TextTrackMediaSource.idl
@@ -0,0 +1,31 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+[
+    Conditional=MEDIA_SOURCE&VIDEO_TRACK,
+]
+partial interface TextTrack {
+    readonly attribute SourceBuffer sourceBuffer;
+};
diff --git a/Source/WebCore/Modules/mediasource/VideoPlaybackQuality.cpp b/Source/WebCore/Modules/mediasource/VideoPlaybackQuality.cpp
new file mode 100644
index 0000000..f7a5cf8
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/VideoPlaybackQuality.cpp
@@ -0,0 +1,45 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS''
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
+ * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "config.h"
+#include "VideoPlaybackQuality.h"
+
+namespace WebCore {
+
+RefPtr<VideoPlaybackQuality> VideoPlaybackQuality::create(double creationTime, unsigned long totalVideoFrames, unsigned long droppedVideoFrames, unsigned long corruptedVideoFrames, double totalFrameDelay)
+{
+    return adoptRef(new VideoPlaybackQuality(creationTime, totalVideoFrames, droppedVideoFrames, corruptedVideoFrames, totalFrameDelay));
+}
+
+VideoPlaybackQuality::VideoPlaybackQuality(double creationTime, unsigned long totalVideoFrames, unsigned long droppedVideoFrames, unsigned long corruptedVideoFrames, double totalFrameDelay)
+    : m_creationTime(creationTime)
+    , m_totalVideoFrames(totalVideoFrames)
+    , m_droppedVideoFrames(droppedVideoFrames)
+    , m_corruptedVideoFrames(corruptedVideoFrames)
+    , m_totalFrameDelay(totalFrameDelay)
+{
+}
+
+}
diff --git a/Source/WebCore/Modules/mediasource/VideoPlaybackQuality.h b/Source/WebCore/Modules/mediasource/VideoPlaybackQuality.h
new file mode 100644
index 0000000..5b89377
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/VideoPlaybackQuality.h
@@ -0,0 +1,57 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS''
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
+ * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef VideoPlaybackQuality_h
+#define VideoPlaybackQuality_h
+
+#include <wtf/RefCounted.h>
+#include <wtf/RefPtr.h>
+
+namespace WebCore {
+
+class VideoPlaybackQuality : public RefCounted<VideoPlaybackQuality> {
+    WTF_MAKE_NONCOPYABLE(VideoPlaybackQuality)
+public:
+    static RefPtr<VideoPlaybackQuality> create(double creationTime, unsigned long totalVideoFrames, unsigned long droppedVideoFrames, unsigned long corruptedVideoFrames, double totalFrameDelay);
+
+    double creationTime() const { return m_creationTime; }
+    unsigned long totalVideoFrames() const { return m_totalVideoFrames; }
+    unsigned long droppedVideoFrames() const { return m_droppedVideoFrames; }
+    unsigned long corruptedVideoFrames() const { return m_corruptedVideoFrames; }
+    double totalFrameDelay() const { return m_totalFrameDelay; }
+
+protected:
+    VideoPlaybackQuality(double creationTime, unsigned long totalVideoFrames, unsigned long droppedVideoFrames, unsigned long corruptedVideoFrames, double totalFrameDelay);
+
+    double m_creationTime;
+    unsigned long m_totalVideoFrames;
+    unsigned long m_droppedVideoFrames;
+    unsigned long m_corruptedVideoFrames;
+    double m_totalFrameDelay;
+};
+
+}
+
+#endif // VideoPlaybackQuality_h
diff --git a/Source/WebCore/Modules/mediasource/VideoPlaybackQuality.idl b/Source/WebCore/Modules/mediasource/VideoPlaybackQuality.idl
new file mode 100644
index 0000000..65c6193
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/VideoPlaybackQuality.idl
@@ -0,0 +1,39 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS''
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
+ * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+[
+    Conditional=MEDIA_SOURCE,
+    NoInterfaceObject,
+    ImplementationLacksVTable,
+] interface VideoPlaybackQuality {
+    readonly attribute double creationTime;
+    readonly attribute unsigned long totalVideoFrames;
+    readonly attribute unsigned long droppedVideoFrames;
+    readonly attribute unsigned long corruptedVideoFrames;
+    readonly attribute double totalFrameDelay;
+};
+
+
+
diff --git a/Source/WebCore/Modules/mediasource/VideoTrackMediaSource.h b/Source/WebCore/Modules/mediasource/VideoTrackMediaSource.h
new file mode 100644
index 0000000..f7f5f64
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/VideoTrackMediaSource.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+#ifndef VideoTrackMediaSource_h
+#define VideoTrackMediaSource_h
+
+#if ENABLE(MEDIA_SOURCE) && ENABLE(VIDEO_TRACK)
+
+#include "VideoTrack.h"
+
+namespace WebCore {
+
+class SourceBuffer;
+
+class VideoTrackMediaSource {
+public:
+    static SourceBuffer* sourceBuffer(VideoTrack* track) { return track->sourceBuffer(); }
+};
+
+}
+
+#endif
+
+#endif
diff --git a/Source/WebCore/Modules/mediasource/VideoTrackMediaSource.idl b/Source/WebCore/Modules/mediasource/VideoTrackMediaSource.idl
new file mode 100644
index 0000000..0f7c65b
--- /dev/null
+++ b/Source/WebCore/Modules/mediasource/VideoTrackMediaSource.idl
@@ -0,0 +1,30 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+[
+    Conditional=MEDIA_SOURCE&VIDEO_TRACK,
+]
+partial interface VideoTrack {
+    readonly attribute SourceBuffer sourceBuffer;
+};
diff --git a/Source/WebCore/dom/EventNames.h b/Source/WebCore/dom/EventNames.h
index 0b96a2a..b79b996 100644
--- a/Source/WebCore/dom/EventNames.h
+++ b/Source/WebCore/dom/EventNames.h
@@ -171,6 +171,14 @@ namespace WebCore {
     macro(webkitbeginfullscreen) \
     macro(webkitendfullscreen) \
     \
+    macro(addsourcebuffer) \
+    macro(removesourcebuffer) \
+    macro(sourceopen) \
+    macro(sourceended) \
+    macro(sourceclose) \
+    macro(update) \
+    macro(updateend) \
+    macro(updatestart) \
     macro(webkitaddsourcebuffer) \
     macro(webkitremovesourcebuffer) \
     macro(webkitsourceopen) \
diff --git a/Source/WebCore/html/URLRegistry.h b/Source/WebCore/html/URLRegistry.h
new file mode 100644
index 0000000..72c7d69
--- /dev/null
+++ b/Source/WebCore/html/URLRegistry.h
@@ -0,0 +1,61 @@
+/*
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef URLRegistry_h
+#define URLRegistry_h
+
+#include <wtf/text/WTFString.h>
+
+namespace WebCore {
+
+class URL;
+class SecurityOrigin;
+class URLRegistry;
+
+class URLRegistrable {
+public:
+    virtual ~URLRegistrable() { }
+    virtual URLRegistry& registry() const = 0;
+};
+
+class URLRegistry {
+    WTF_MAKE_FAST_ALLOCATED;
+public:
+    virtual ~URLRegistry() { }
+    virtual void registerURL(SecurityOrigin*, const URL&, URLRegistrable*) = 0;
+    virtual void unregisterURL(const URL&) = 0;
+
+    // This is an optional API
+    virtual URLRegistrable* lookup(const String&) const { ASSERT_NOT_REACHED(); return 0; }
+};
+
+} // namespace WebCore
+
+#endif // URLRegistry_h
diff --git a/Source/WebCore/platform/MediaDescription.h b/Source/WebCore/platform/MediaDescription.h
new file mode 100644
index 0000000..7b6ffcd
--- /dev/null
+++ b/Source/WebCore/platform/MediaDescription.h
@@ -0,0 +1,45 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+#ifndef MediaDescription_h
+#define MediaDescription_h
+
+#include <wtf/RefCounted.h>
+
+namespace WebCore {
+
+class MediaDescription : public RefCounted<MediaDescription> {
+public:
+    virtual ~MediaDescription() { }
+
+    virtual AtomicString codec() const = 0;
+    virtual bool isVideo() const = 0;
+    virtual bool isAudio() const = 0;
+    virtual bool isText() const = 0;
+};
+
+}
+
+#endif
diff --git a/Source/WebCore/platform/MediaSample.h b/Source/WebCore/platform/MediaSample.h
new file mode 100644
index 0000000..99e5721
--- /dev/null
+++ b/Source/WebCore/platform/MediaSample.h
@@ -0,0 +1,78 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+#ifndef MediaSample_h
+#define MediaSample_h
+
+#include "FloatSize.h"
+#include <wtf/MediaTime.h>
+#include <wtf/RefCounted.h>
+#include <wtf/text/AtomicString.h>
+
+namespace WebCore {
+
+class MockSampleBox;
+typedef struct opaqueCMSampleBuffer *CMSampleBufferRef;
+
+struct PlatformSample {
+    enum {
+        None,
+        MockSampleBoxType,
+        CMSampleBufferType,
+    } type;
+    union {
+        MockSampleBox* mockSampleBox;
+        CMSampleBufferRef cmSampleBuffer;
+    } sample;
+};
+
+class MediaSample : public RefCounted<MediaSample> {
+public:
+    virtual ~MediaSample() { }
+
+    virtual MediaTime presentationTime() const = 0;
+    virtual MediaTime decodeTime() const = 0;
+    virtual MediaTime duration() const = 0;
+    virtual AtomicString trackID() const = 0;
+    virtual size_t sizeInBytes() const = 0;
+    virtual FloatSize presentationSize() const = 0;
+
+    enum SampleFlags {
+        None = 0,
+        IsSync = 1 << 0,
+        NonDisplaying = 1 << 1,
+    };
+    virtual SampleFlags flags() const = 0;
+    virtual PlatformSample platformSample() = 0;
+
+    bool isSync() const { return flags() & IsSync; }
+    bool isNonDisplaying() const { return flags() & NonDisplaying; }
+
+    virtual void dump(PrintStream&) const = 0;
+};
+
+}
+
+#endif
diff --git a/Source/WebCore/platform/graphics/MediaSourcePrivate.h b/Source/WebCore/platform/graphics/MediaSourcePrivate.h
index 2b1074f..7186589 100644
--- a/Source/WebCore/platform/graphics/MediaSourcePrivate.h
+++ b/Source/WebCore/platform/graphics/MediaSourcePrivate.h
@@ -32,25 +32,35 @@
 
 #if ENABLE(MEDIA_SOURCE)
 
+#include "MediaPlayer.h"
 #include <wtf/Forward.h>
+#include <wtf/RefCounted.h>
+#include <wtf/Vector.h>
 
 namespace WebCore {
 
+class ContentType;
 class SourceBufferPrivate;
 
-class MediaSourcePrivate {
+class MediaSourcePrivate : public RefCounted<MediaSourcePrivate> {
 public:
-    typedef Vector<String, 0> CodecsArray;
+    typedef Vector<String> CodecsArray;
 
     MediaSourcePrivate() { }
     virtual ~MediaSourcePrivate() { }
 
     enum AddStatus { Ok, NotSupported, ReachedIdLimit };
-    virtual AddStatus addSourceBuffer(const String& type, const CodecsArray&, OwnPtr<SourceBufferPrivate>*) = 0;
-    virtual double duration() = 0;
-    virtual void setDuration(double) = 0;
+    virtual AddStatus addSourceBuffer(const ContentType&, RefPtr<SourceBufferPrivate>&) = 0;
+    virtual void durationChanged() = 0;
     enum EndOfStreamStatus { EosNoError, EosNetworkError, EosDecodeError };
-    virtual void endOfStream(EndOfStreamStatus) = 0;
+    virtual void markEndOfStream(EndOfStreamStatus) = 0;
+    virtual void unmarkEndOfStream() = 0;
+
+    virtual MediaPlayer::ReadyState readyState() const = 0;
+    virtual void setReadyState(MediaPlayer::ReadyState) = 0;
+
+    virtual void waitForSeekCompleted() = 0;
+    virtual void seekCompleted() = 0;
 };
 
 }
diff --git a/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h b/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h
new file mode 100644
index 0000000..5827763
--- /dev/null
+++ b/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h
@@ -0,0 +1,54 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+#ifndef MediaSourcePrivateClient_h
+#define MediaSourcePrivateClient_h
+
+#if ENABLE(MEDIA_SOURCE)
+
+#include "PlatformTimeRanges.h"
+#include <wtf/RefCounted.h>
+#include <wtf/PassRefPtr.h>
+#include <wtf/PassOwnPtr.h>
+
+namespace WebCore {
+
+class MediaSourcePrivate;
+
+class MediaSourcePrivateClient : public RefCounted<MediaSourcePrivateClient> {
+public:
+    virtual ~MediaSourcePrivateClient() { }
+
+    virtual void setPrivateAndOpen(PassOwnPtr<MediaSourcePrivate>) = 0;
+    virtual MediaTime duration() const = 0;
+    virtual PassOwnPtr<PlatformTimeRanges> buffered() const = 0;
+    virtual void seekToTime(const MediaTime&) = 0;
+};
+
+}
+
+#endif // ENABLE(MEDIA_SOURCE)
+
+#endif
diff --git a/Source/WebCore/platform/graphics/PlatformTimeRanges.cpp b/Source/WebCore/platform/graphics/PlatformTimeRanges.cpp
new file mode 100644
index 0000000..2f319ac
--- /dev/null
+++ b/Source/WebCore/platform/graphics/PlatformTimeRanges.cpp
@@ -0,0 +1,271 @@
+/*
+ * Copyright (C) 2014 Apple Inc.  All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+#include "config.h"
+#include "PlatformTimeRanges.h"
+
+#include <math.h>
+#include <wtf/PrintStream.h>
+
+namespace WebCore {
+
+PassOwnPtr<PlatformTimeRanges> PlatformTimeRanges::create()
+{
+    return adoptPtr(new PlatformTimeRanges());
+}
+
+PassOwnPtr<PlatformTimeRanges> PlatformTimeRanges::create(const MediaTime& start, const MediaTime& end)
+{
+    return adoptPtr(new PlatformTimeRanges(start, end));
+}
+
+PassOwnPtr<PlatformTimeRanges> PlatformTimeRanges::create(const PlatformTimeRanges& other)
+{
+    return adoptPtr(new PlatformTimeRanges(other));
+}
+    
+PlatformTimeRanges::PlatformTimeRanges(const MediaTime& start, const MediaTime& end)
+{
+    add(start, end);
+}
+
+PlatformTimeRanges::PlatformTimeRanges(const PlatformTimeRanges& other)
+{
+    copy(other);
+}
+
+PlatformTimeRanges& PlatformTimeRanges::operator=(const PlatformTimeRanges& other)
+{
+    return copy(other);
+}
+
+PlatformTimeRanges& PlatformTimeRanges::copy(const PlatformTimeRanges& other)
+{
+    unsigned size = other.m_ranges.size();
+    for (unsigned i = 0; i < size; i++)
+        add(other.m_ranges[i].m_start, other.m_ranges[i].m_end);
+    
+    return *this;
+}
+
+void PlatformTimeRanges::invert()
+{
+    PlatformTimeRanges inverted;
+    MediaTime posInf = MediaTime::positiveInfiniteTime();
+    MediaTime negInf = MediaTime::negativeInfiniteTime();
+
+    if (!m_ranges.size())
+        inverted.add(negInf, posInf);
+    else {
+        MediaTime start = m_ranges.first().m_start;
+        if (start != negInf)
+            inverted.add(negInf, start);
+
+        for (size_t index = 0; index + 1 < m_ranges.size(); ++index)
+            inverted.add(m_ranges[index].m_end, m_ranges[index + 1].m_start);
+
+        MediaTime end = m_ranges.last().m_end;
+        if (end != posInf)
+            inverted.add(end, posInf);
+    }
+
+    m_ranges.swap(inverted.m_ranges);
+}
+
+void PlatformTimeRanges::intersectWith(const PlatformTimeRanges& other)
+{
+    PlatformTimeRanges invertedOther(other);
+
+    invertedOther.invert();
+    invert();
+    unionWith(invertedOther);
+    invert();
+}
+
+void PlatformTimeRanges::unionWith(const PlatformTimeRanges& other)
+{
+    PlatformTimeRanges unioned(*this);
+
+    for (size_t index = 0; index < other.m_ranges.size(); ++index) {
+        const Range& range = other.m_ranges[index];
+        unioned.add(range.m_start, range.m_end);
+    }
+
+    m_ranges.swap(unioned.m_ranges);
+}
+
+MediaTime PlatformTimeRanges::start(unsigned index) const
+{
+    bool ignoredValid;
+    return start(index, ignoredValid);
+}
+
+MediaTime PlatformTimeRanges::start(unsigned index, bool& valid) const
+{ 
+    if (index >= length()) {
+        valid = false;
+        return MediaTime::zeroTime();
+    }
+    
+    valid = true;
+    return m_ranges[index].m_start;
+}
+
+MediaTime PlatformTimeRanges::end(unsigned index) const
+{
+    bool ignoredValid;
+    return end(index, ignoredValid);
+}
+
+MediaTime PlatformTimeRanges::end(unsigned index, bool& valid) const
+{ 
+    if (index >= length()) {
+        valid = false;
+        return MediaTime::zeroTime();
+    }
+
+    valid = true;
+    return m_ranges[index].m_end;
+}
+
+MediaTime PlatformTimeRanges::duration(unsigned index) const
+{
+    if (index >= length())
+        return MediaTime::invalidTime();
+
+    return m_ranges[index].m_end - m_ranges[index].m_start;
+}
+
+MediaTime PlatformTimeRanges::maximumBufferedTime() const
+{
+    if (!length())
+        return MediaTime::invalidTime();
+
+    return m_ranges[length() - 1].m_end;
+}
+
+void PlatformTimeRanges::add(const MediaTime& start, const MediaTime& end)
+{
+    ASSERT(start <= end);
+    unsigned overlappingArcIndex;
+    Range addedRange(start, end);
+
+    // For each present range check if we need to:
+    // - merge with the added range, in case we are overlapping or contiguous
+    // - Need to insert in place, we we are completely, not overlapping and not contiguous
+    // in between two ranges.
+    //
+    // TODO: Given that we assume that ranges are correctly ordered, this could be optimized.
+
+    for (overlappingArcIndex = 0; overlappingArcIndex < m_ranges.size(); overlappingArcIndex++) {
+        if (addedRange.isOverlappingRange(m_ranges[overlappingArcIndex]) || addedRange.isContiguousWithRange(m_ranges[overlappingArcIndex])) {
+            // We need to merge the addedRange and that range.
+            addedRange = addedRange.unionWithOverlappingOrContiguousRange(m_ranges[overlappingArcIndex]);
+            m_ranges.remove(overlappingArcIndex);
+            overlappingArcIndex--;
+        } else {
+            // Check the case for which there is no more to do
+            if (!overlappingArcIndex) {
+                if (addedRange.isBeforeRange(m_ranges[0])) {
+                    // First index, and we are completely before that range (and not contiguous, nor overlapping).
+                    // We just need to be inserted here.
+                    break;
+                }
+            } else {
+                if (m_ranges[overlappingArcIndex - 1].isBeforeRange(addedRange) && addedRange.isBeforeRange(m_ranges[overlappingArcIndex])) {
+                    // We are exactly after the current previous range, and before the current range, while
+                    // not overlapping with none of them. Insert here.
+                    break;
+                }
+            }
+        }
+    }
+
+    // Now that we are sure we don't overlap with any range, just add it.
+    m_ranges.insert(overlappingArcIndex, addedRange);
+}
+
+bool PlatformTimeRanges::contain(const MediaTime& time) const
+{
+    return find(time) != notFound;
+}
+
+size_t PlatformTimeRanges::find(const MediaTime& time) const
+{
+    bool ignoreInvalid;
+    for (unsigned n = 0; n < length(); n++) {
+        if (time >= start(n, ignoreInvalid) && time <= end(n, ignoreInvalid))
+            return n;
+    }
+    return notFound;
+}
+
+MediaTime PlatformTimeRanges::nearest(const MediaTime& time) const
+{
+    MediaTime closestDelta = MediaTime::positiveInfiniteTime();
+    MediaTime closestTime = MediaTime::zeroTime();
+    unsigned count = length();
+    bool ignoreInvalid;
+
+    for (unsigned ndx = 0; ndx < count; ndx++) {
+        MediaTime startTime = start(ndx, ignoreInvalid);
+        MediaTime endTime = end(ndx, ignoreInvalid);
+        if (time >= startTime && time <= endTime)
+            return time;
+
+        MediaTime startTimeDelta = abs(startTime - time);
+        if (startTimeDelta < closestDelta) {
+            closestTime = startTime;
+            closestDelta = startTimeDelta;
+        }
+
+        MediaTime endTimeDelta = abs(endTime - time);
+        if (endTimeDelta < closestDelta) {
+            closestTime = endTime;
+            closestDelta = endTimeDelta;
+        }
+    }
+    return closestTime;
+}
+
+MediaTime PlatformTimeRanges::totalDuration() const
+{
+    MediaTime total = MediaTime::zeroTime();
+
+    for (unsigned n = 0; n < length(); n++)
+        total += abs(end(n) - start(n));
+    return total;
+}
+
+void PlatformTimeRanges::dump(PrintStream& out) const
+{
+    if (!length())
+        return;
+
+    for (size_t i = 0; i < length(); ++i)
+        out.print("[", start(i), "..", end(i), "] ");
+}
+
+}
diff --git a/Source/WebCore/platform/graphics/PlatformTimeRanges.h b/Source/WebCore/platform/graphics/PlatformTimeRanges.h
new file mode 100644
index 0000000..9423ee5
--- /dev/null
+++ b/Source/WebCore/platform/graphics/PlatformTimeRanges.h
@@ -0,0 +1,130 @@
+/*
+ * Copyright (C) 2014 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+#ifndef PlatformTimeRanges_h
+#define PlatformTimeRanges_h
+
+#include <algorithm>
+#include <wtf/MediaTime.h>
+#include <wtf/PassOwnPtr.h>
+#include <wtf/PassRefPtr.h>
+#include <wtf/RefCounted.h>
+#include <wtf/Vector.h>
+
+namespace WTF {
+class PrintStream;
+}
+
+namespace WebCore {
+
+class PlatformTimeRanges {
+public:
+    static PassOwnPtr<PlatformTimeRanges> create();
+    static PassOwnPtr<PlatformTimeRanges> create(const MediaTime& start, const MediaTime& end);
+    static PassOwnPtr<PlatformTimeRanges> create(const PlatformTimeRanges&);
+
+    explicit PlatformTimeRanges() { }
+    PlatformTimeRanges(const MediaTime& start, const MediaTime& end);
+    PlatformTimeRanges(const PlatformTimeRanges&);
+
+    PlatformTimeRanges& operator=(const PlatformTimeRanges&);
+
+    MediaTime start(unsigned index) const;
+    MediaTime start(unsigned index, bool& valid) const;
+    MediaTime end(unsigned index) const;
+    MediaTime end(unsigned index, bool& valid) const;
+    MediaTime duration(unsigned index) const;
+    MediaTime maximumBufferedTime() const;
+
+    void invert();
+    void intersectWith(const PlatformTimeRanges&);
+    void unionWith(const PlatformTimeRanges&);
+
+    unsigned length() const { return m_ranges.size(); }
+
+    void add(const MediaTime& start, const MediaTime& end);
+    
+    bool contain(const MediaTime&) const;
+
+    size_t find(const MediaTime&) const;
+    
+    MediaTime nearest(const MediaTime&) const;
+
+    MediaTime totalDuration() const;
+
+    void dump(WTF::PrintStream&) const;
+
+private:
+    PlatformTimeRanges& copy(const PlatformTimeRanges&);
+
+    // We consider all the Ranges to be semi-bounded as follow: [start, end[
+    struct Range {
+        Range() { }
+        Range(const MediaTime& start, const MediaTime& end)
+            : m_start(start)
+            , m_end(end)
+        {
+        }
+
+        MediaTime m_start;
+        MediaTime m_end;
+
+        inline bool isPointInRange(const MediaTime& point) const
+        {
+            return m_start <= point && point < m_end;
+        }
+        
+        inline bool isOverlappingRange(const Range& range) const
+        {
+            return isPointInRange(range.m_start) || isPointInRange(range.m_end) || range.isPointInRange(m_start);
+        }
+
+        inline bool isContiguousWithRange(const Range& range) const
+        {
+            return range.m_start == m_end || range.m_end == m_start;
+        }
+        
+        inline Range unionWithOverlappingOrContiguousRange(const Range& range) const
+        {
+            Range ret;
+
+            ret.m_start = std::min(m_start, range.m_start);
+            ret.m_end = std::max(m_end, range.m_end);
+
+            return ret;
+        }
+
+        inline bool isBeforeRange(const Range& range) const
+        {
+            return range.m_start >= m_end;
+        }
+    };
+    
+    Vector<Range> m_ranges;
+};
+
+} // namespace WebCore
+
+#endif
diff --git a/Source/WebCore/platform/graphics/SourceBufferPrivateClient.h b/Source/WebCore/platform/graphics/SourceBufferPrivateClient.h
new file mode 100644
index 0000000..c32307d
--- /dev/null
+++ b/Source/WebCore/platform/graphics/SourceBufferPrivateClient.h
@@ -0,0 +1,94 @@
+/*
+ * Copyright (C) 2013 Apple Inc. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
+ * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. 
+ */
+
+#ifndef SourceBufferPrivateClient_h
+#define SourceBufferPrivateClient_h
+
+#if ENABLE(MEDIA_SOURCE)
+
+#include <wtf/MediaTime.h>
+#include <wtf/PassRefPtr.h>
+#include <wtf/Vector.h>
+
+namespace WebCore {
+
+class SourceBufferPrivate;
+class AudioTrackPrivate;
+class VideoTrackPrivate;
+class InbandTextTrackPrivate;
+class MediaSample;
+class MediaDescription;
+
+class SourceBufferPrivateClient {
+public:
+    virtual ~SourceBufferPrivateClient() { }
+
+    virtual void sourceBufferPrivateDidEndStream(SourceBufferPrivate*, const WTF::AtomicString&) = 0;
+
+    struct InitializationSegment {
+        MediaTime duration;
+
+        struct AudioTrackInformation {
+            RefPtr<MediaDescription> description;
+            RefPtr<AudioTrackPrivate> track;
+        };
+        Vector<AudioTrackInformation> audioTracks;
+
+        struct VideoTrackInformation {
+            RefPtr<MediaDescription> description;
+            RefPtr<VideoTrackPrivate> track;
+        };
+        Vector<VideoTrackInformation> videoTracks;
+
+        struct TextTrackInformation {
+            RefPtr<MediaDescription> description;
+            RefPtr<InbandTextTrackPrivate> track;
+        };
+        Vector<TextTrackInformation> textTracks;
+    };
+    virtual void sourceBufferPrivateDidReceiveInitializationSegment(SourceBufferPrivate*, const InitializationSegment&) = 0;
+    virtual void sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, PassRefPtr<MediaSample>) = 0;
+    virtual bool sourceBufferPrivateHasAudio(const SourceBufferPrivate*) const = 0;
+    virtual bool sourceBufferPrivateHasVideo(const SourceBufferPrivate*) const = 0;
+
+    virtual void sourceBufferPrivateDidBecomeReadyForMoreSamples(SourceBufferPrivate*, AtomicString trackID) = 0;
+
+    virtual MediaTime sourceBufferPrivateFastSeekTimeForMediaTime(SourceBufferPrivate*, const MediaTime& time, const MediaTime&, const MediaTime&) { return time; }
+    virtual void sourceBufferPrivateSeekToTime(SourceBufferPrivate*, const MediaTime&) { };
+
+    enum AppendResult {
+        AppendSucceeded,
+        ReadStreamFailed,
+        ParsingFailed,
+    };
+    virtual void sourceBufferPrivateAppendComplete(SourceBufferPrivate*, AppendResult) = 0;
+    virtual void sourceBufferPrivateDidReceiveRenderingError(SourceBufferPrivate*, int errocCode) = 0;
+};
+
+}
+
+#endif // ENABLE(MEDIA_SOURCE)
+
+#endif

From d4310870f41b79b28e91a8f4945ace8221094b51 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Thu, 13 Nov 2014 15:35:04 +0100
Subject: [PATCH 06/68] Refactoring

Remove more auto keywords
Remove all unique_ptr keywords
---
 .../WebCore/Modules/mediasource/SourceBuffer.cpp   | 84 ++++++++++++----------
 1 file changed, 48 insertions(+), 36 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index 9b69c66..2328a29 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -574,14 +574,13 @@ static PassRefPtr<TimeRanges> removeSamplesFromTrackBuffer(const DecodeOrderSamp
     MediaTime microsecond(1, 1000000);
     DecodeOrderSampleMap::const_iterator end = samples.end();
     for (DecodeOrderSampleMap::const_iterator it = samples.begin(); it != end; ++it) {
- std::pair<const DecodeOrderSampleMap::KeyType, RefPtr<MediaSample> > sampleIt = *it;
-        const DecodeOrderSampleMap::KeyType& decodeKey = sampleIt.first;
+        const DecodeOrderSampleMap::KeyType& decodeKey = it->first;
 #if !LOG_DISABLED
         size_t startBufferSize = trackBuffer.samples.sizeInBytes();
 #endif
 
-        RefPtr<MediaSample>& sample = sampleIt.second;
-        LOG(MediaSource, "SourceBuffer::%s(%p) - removing sample(%s)", logPrefix, buffer, toString(*sampleIt.second).utf8().data());
+        RefPtr<MediaSample>& sample = it->second;
+        LOG(MediaSource, "SourceBuffer::%s(%p) - removing sample(%s)", logPrefix, buffer, toString(*it->second).utf8().data());
 
         // Remove the erased samples from the TrackBuffer sample map.
         trackBuffer.samples.removeSample(sample.get());
@@ -795,7 +794,7 @@ void SourceBuffer::evictCodedFrames(size_t newDataSize)
     LOG(MediaSource, "SourceBuffer::evictCodedFrames(%p) - evicted %zu bytes%s", this, initialBufferedSize - extraMemoryCost(), m_bufferFull ? "" : " but FAILED to free enough");
 }
 
-size_t SourceBuffer::maximumBufferSize() const
+size_t SourceBuffer::maximumBufferSize()
 {
     if (isRemoved())
         return 0;
@@ -930,13 +929,13 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         ASSERT(segment.textTracks.size() == textTracks()->length());
         for (auto& textTrackInfo : segment.textTracks) {
             if (textTracks()->length() == 1) {
-                downcast<InbandTextTrack>(*textTracks()->item(0)).setPrivate(textTrackInfo.track);
+                static_cast<InbandTextTrack>(*textTracks()->item(0)).setPrivate(textTrackInfo.track);
                 break;
             }
 
             auto textTrack = textTracks()->getTrackById(textTrackInfo.track->id());
             ASSERT(textTrack);
-            downcast<InbandTextTrack>(*textTrack).setPrivate(textTrackInfo.track);
+            static_cast<InbandTextTrack>(*textTrack).setPrivate(textTrackInfo.track);
         }
 
         for (auto& trackBuffer : m_trackBufferMap.values())
@@ -1111,17 +1110,23 @@ bool SourceBuffer::validateInitializationSegment(const InitializationSegment& se
         return false;
 
     //   * The codecs for each track, match what was specified in the first initialization segment.
-    for (auto& audioTrackInfo : segment.audioTracks) {
+    Vector<InitializationSegment::AudioTrackInformation>::const_iterator aend = segment.audioTracks.end();
+    for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != aend; ++it) {
+        const InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
         if (!m_audioCodecs.contains(audioTrackInfo.description->codec()))
             return false;
     }
 
-    for (auto& videoTrackInfo : segment.videoTracks) {
+    Vector<InitializationSegment::VideoTrackInformation>::const_iterator vend = segment.videoTracks.end();
+    for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+        const InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
         if (!m_videoCodecs.contains(videoTrackInfo.description->codec()))
             return false;
     }
 
-    for (auto& textTrackInfo : segment.textTracks) {
+    Vector<InitializationSegment::TextTrackInformation>::const_iterator tend = segment.textTracks.end();
+    for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != tend; ++it) {
+        const InitializationSegment::TextTrackInformation & textTrackInfo = *it;
         if (!m_textCodecs.contains(textTrackInfo.description->codec()))
             return false;
     }
@@ -1129,22 +1134,26 @@ bool SourceBuffer::validateInitializationSegment(const InitializationSegment& se
     //   * If more than one track for a single type are present (ie 2 audio tracks), then the Track
     //   IDs match the ones in the first initialization segment.
     if (segment.audioTracks.size() >= 2) {
-        for (auto& audioTrackInfo : segment.audioTracks) {
+        for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != aend; ++it) {
+            const InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
             if (!m_trackBufferMap.contains(audioTrackInfo.track->id()))
                 return false;
         }
     }
 
     if (segment.videoTracks.size() >= 2) {
-        for (auto& videoTrackInfo : segment.videoTracks) {
+        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+            const InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
             if (!m_trackBufferMap.contains(videoTrackInfo.track->id()))
                 return false;
         }
     }
 
     if (segment.textTracks.size() >= 2) {
-        for (auto& textTrackInfo : segment.videoTracks) {
-            if (!m_trackBufferMap.contains(textTrackInfo.track->id()))
+        // Don't know why they use the video tracks here
+        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+            const InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
+            if (!m_trackBufferMap.contains(videoTrackInfo.track->id()))
                 return false;
         }
     }
@@ -1221,7 +1230,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, Pas
 
         // 1.6 Let track buffer equal the track buffer that the coded frame will be added to.
         AtomicString trackID = sample->trackID();
-        auto it = m_trackBufferMap.find(trackID);
+        HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.find(trackID);
         if (it == m_trackBufferMap.end())
             it = m_trackBufferMap.add(trackID, TrackBuffer()).iterator;
         TrackBuffer& trackBuffer = it->value;
@@ -1293,7 +1302,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, Pas
         // falls within the presentation interval of a coded frame in track buffer, then run the
         // following steps:
         if (trackBuffer.lastDecodeTimestamp.isInvalid()) {
-            auto iter = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(presentationTimestamp);
+            PresentationOrderSampleMap::iterator iter = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(presentationTimestamp);
             if (iter != trackBuffer.samples.presentationOrder().end()) {
                 // 1.14.1 Let overlapped frame be the coded frame in track buffer that matches the condition above.
                 RefPtr<MediaSample> overlappedFrame = iter->second;
@@ -1330,7 +1339,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, Pas
         if (trackBuffer.highestPresentationTimestamp.isInvalid()) {
             // Remove all coded frames from track buffer that have a presentation timestamp greater than or
             // equal to presentation timestamp and less than frame end timestamp.
-            auto iter_pair = trackBuffer.samples.presentationOrder().findSamplesBetweenPresentationTimes(presentationTimestamp, frameEndTimestamp);
+            PresentationOrderSampleMap::iterator_range iter_pair = trackBuffer.samples.presentationOrder().findSamplesBetweenPresentationTimes(presentationTimestamp, frameEndTimestamp);
             if (iter_pair.first != trackBuffer.samples.presentationOrder().end())
                 erasedSamples.addRange(iter_pair.first, iter_pair.second);
         }
@@ -1372,9 +1381,9 @@ void SourceBuffer::sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, Pas
 
             // Otherwise: Remove all coded frames between the coded frames removed in the previous step
             // and the next random access point after those removed frames.
-            auto firstDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().begin()->first);
-            auto lastDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().rbegin()->first);
-            auto nextSyncIter = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(lastDecodeIter);
+            DecodeOrderSampleMap::iterator firstDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().begin()->first);
+            DecodeOrderSampleMap::iterator lastDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().rbegin()->first);
+            DecodeOrderSampleMap::iterator nextSyncIter = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(lastDecodeIter);
             dependentSamples.insert(firstDecodeIter, nextSyncIter);
 
             RefPtr<TimeRanges> erasedRanges = removeSamplesFromTrackBuffer(dependentSamples, trackBuffer, this, "sourceBufferPrivateDidReceiveSample");
@@ -1565,7 +1574,7 @@ void SourceBuffer::textTrackKindChanged(TextTrack* track)
 void SourceBuffer::sourceBufferPrivateDidBecomeReadyForMoreSamples(SourceBufferPrivate*, AtomicString trackID)
 {
     LOG(MediaSource, "SourceBuffer::sourceBufferPrivateDidBecomeReadyForMoreSamples(%p)", this);
-    auto it = m_trackBufferMap.find(trackID);
+    HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.find(trackID);
     if (it == m_trackBufferMap.end())
         return;
 
@@ -1581,7 +1590,7 @@ void SourceBuffer::provideMediaData(TrackBuffer& trackBuffer, AtomicString track
 #endif
 
     DecodeOrderSampleMap::iterator sampleIt = trackBuffer.decodeQueue.begin();
-    for (auto sampleEnd = trackBuffer.decodeQueue.end(); sampleIt != sampleEnd; ++sampleIt) {
+    for (DecodeOrderSampleMap::iterator sampleEnd = trackBuffer.decodeQueue.end(); sampleIt != sampleEnd; ++sampleIt) {
         if (!m_private->isReadyForMoreSamples(trackID)) {
             m_private->notifyClientWhenReadyForMoreSamples(trackID);
             break;
@@ -1615,7 +1624,7 @@ void SourceBuffer::provideMediaData(TrackBuffer& trackBuffer, AtomicString track
 void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, AtomicString trackID, const MediaTime& time)
 {
     // Find the sample which contains the current presentation time.
-    auto currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
+    PresentationOrderSampleMap::iterator currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
 
     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end()) {
         trackBuffer.decodeQueue.clear();
@@ -1625,11 +1634,11 @@ void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, AtomicString
 
     // Seach backward for the previous sync sample.
     DecodeOrderSampleMap::KeyType decodeKey(currentSamplePTSIterator->second->decodeTime(), currentSamplePTSIterator->second->presentationTime());
-    auto currentSampleDTSIterator = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(decodeKey);
+    DecodeOrderSampleMap::iterator currentSampleDTSIterator = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(decodeKey);
     ASSERT(currentSampleDTSIterator != trackBuffer.samples.decodeOrder().end());
 
-    auto reverseCurrentSampleIter = --DecodeOrderSampleMap::reverse_iterator(currentSampleDTSIterator);
-    auto reverseLastSyncSampleIter = trackBuffer.samples.decodeOrder().findSyncSamplePriorToDecodeIterator(reverseCurrentSampleIter);
+    DecodeOrderSampleMap::reverse_iterator reverseCurrentSampleIter = --DecodeOrderSampleMap::reverse_iterator(currentSampleDTSIterator);
+    DecodeOrderSampleMap::reverse_iterator reverseLastSyncSampleIter = trackBuffer.samples.decodeOrder().findSyncSamplePriorToDecodeIterator(reverseCurrentSampleIter);
     if (reverseLastSyncSampleIter == trackBuffer.samples.decodeOrder().rend()) {
         trackBuffer.decodeQueue.clear();
         m_private->flushAndEnqueueNonDisplayingSamples(Vector<RefPtr<MediaSample> >(), trackID);
@@ -1637,7 +1646,7 @@ void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, AtomicString
     }
 
     Vector<RefPtr<MediaSample> > nonDisplayingSamples;
-    for (auto iter = reverseLastSyncSampleIter; iter != reverseCurrentSampleIter; --iter)
+    for (DecodeOrderSampleMap::reverse_iterator iter = reverseLastSyncSampleIter; iter != reverseCurrentSampleIter; --iter)
         nonDisplayingSamples.append(iter->second);
 
     m_private->flushAndEnqueueNonDisplayingSamples(nonDisplayingSamples, trackID);
@@ -1652,7 +1661,7 @@ void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, AtomicString
 
     // Fill the decode queue with the remaining samples.
     trackBuffer.decodeQueue.clear();
-    for (auto iter = currentSampleDTSIterator; iter != trackBuffer.samples.decodeOrder().end(); ++iter)
+    for (DecodeOrderSampleMap::iterator iter = currentSampleDTSIterator; iter != trackBuffer.samples.decodeOrder().end(); ++iter)
         trackBuffer.decodeQueue.insert(*iter);
     provideMediaData(trackBuffer, trackID);
 
@@ -1683,10 +1692,10 @@ void SourceBuffer::monitorBufferingRate()
     LOG(MediaSource, "SourceBuffer::monitorBufferingRate(%p) - m_avegareBufferRate: %lf", this, m_averageBufferRate);
 }
 
-std::unique_ptr<PlatformTimeRanges> SourceBuffer::bufferedAccountingForEndOfStream() const
+PassOwnPtr<PlatformTimeRanges> SourceBuffer::bufferedAccountingForEndOfStream() const
 {
     // FIXME: Revisit this method once the spec bug <https://www.w3.org/Bugs/Public/show_bug.cgi?id=26436> is resolved.
-    std::unique_ptr<PlatformTimeRanges> virtualRanges = PlatformTimeRanges::create(m_buffered->ranges());
+    PassOwnPtr<PlatformTimeRanges> virtualRanges = PlatformTimeRanges::create(m_buffered->ranges());
     if (m_source->isEnded()) {
         MediaTime start = virtualRanges->maximumBufferedTime();
         MediaTime end = m_source->duration();
@@ -1706,7 +1715,7 @@ bool SourceBuffer::hasCurrentTime() const
     if (currentTime >= duration)
         return true;
 
-    std::unique_ptr<PlatformTimeRanges> ranges = bufferedAccountingForEndOfStream();
+    PassOwnPtr<PlatformTimeRanges> ranges = bufferedAccountingForEndOfStream();
     return abs(ranges->nearest(currentTime) - currentTime) <= currentTimeFudgeFactor();
 }
 
@@ -1715,7 +1724,7 @@ bool SourceBuffer::hasFutureTime() const
     if (isRemoved())
         return false;
 
-    std::unique_ptr<PlatformTimeRanges> ranges = bufferedAccountingForEndOfStream();
+    PassOwnPtr<PlatformTimeRanges> ranges = bufferedAccountingForEndOfStream();
     if (!ranges->length())
         return false;
 
@@ -1755,7 +1764,7 @@ bool SourceBuffer::canPlayThrough()
     MediaTime currentTime = m_source->currentTime();
     MediaTime duration = m_source->duration();
 
-    std::unique_ptr<PlatformTimeRanges> unbufferedRanges = bufferedAccountingForEndOfStream();
+    PassOwnPtr<PlatformTimeRanges> unbufferedRanges = bufferedAccountingForEndOfStream();
     unbufferedRanges->invert();
     unbufferedRanges->intersectWith(PlatformTimeRanges(currentTime, std::max(currentTime, duration)));
     MediaTime unbufferedTime = unbufferedRanges->totalDuration();
@@ -1769,8 +1778,11 @@ bool SourceBuffer::canPlayThrough()
 size_t SourceBuffer::extraMemoryCost() const
 {
     size_t extraMemoryCost = m_pendingAppendData.capacity();
-    for (auto& trackBuffer : m_trackBufferMap.values())
+    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+        TrackBuffer& trackBuffer = it->value;
         extraMemoryCost += trackBuffer.samples.sizeInBytes();
+    }
 
     return extraMemoryCost;
 }
@@ -1799,7 +1811,7 @@ Vector<String> SourceBuffer::bufferedSamplesForTrackID(const AtomicString& track
     Vector<String> sampleDescriptions;
     DecodeOrderSampleMap::iterator end = trackBuffer.samples.decodeOrder().end();
     for (DecodeOrderSampleMap::iterator it = trackBuffer.samples.decodeOrder().begin(); it != end; ++it) {
-        sampleDescriptions.append(toString(*it.second));
+        sampleDescriptions.append(toString(*it->second));
     }
 
     return sampleDescriptions;
@@ -1808,7 +1820,7 @@ Vector<String> SourceBuffer::bufferedSamplesForTrackID(const AtomicString& track
 Document& SourceBuffer::document() const
 {
     ASSERT(scriptExecutionContext());
-    return downcast<Document>(*scriptExecutionContext());
+    return static_cast<Document>(*scriptExecutionContext());
 }
 
 } // namespace WebCore

From 9c583e20f805fe359a9e585cdcdc3971a10f95c0 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Thu, 13 Nov 2014 16:36:13 +0100
Subject: [PATCH 07/68] Remove every occurence of auto

---
 .../WebCore/Modules/mediasource/SourceBuffer.cpp   | 42 +++++++++++++++-------
 1 file changed, 30 insertions(+), 12 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index 2328a29..b6ca75b 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -756,7 +756,7 @@ void SourceBuffer::evictCodedFrames(size_t newDataSize)
     // If there still isn't enough free space and there buffers in time ranges after the current range (ie. there is a gap after
     // the current buffered range), delete 30 seconds at a time from duration back to the current time range or 30 seconds after
     // currenTime whichever we hit first.
-    auto buffered = m_buffered->ranges();
+    PlatformTimeRanges& buffered = m_buffered->ranges();
     size_t currentTimeRange = buffered.find(currentTime);
     if (currentTimeRange == notFound || currentTimeRange == buffered.length() - 1) {
         LOG(MediaSource, "SourceBuffer::evictCodedFrames(%p) - evicted %zu bytes but FAILED to free enough", this, initialBufferedSize - extraMemoryCost());
@@ -903,43 +903,53 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         }
         // 3.2 Add the appropriate track descriptions from this initialization segment to each of the track buffers.
         ASSERT(segment.audioTracks.size() == audioTracks()->length());
-        for (auto& audioTrackInfo : segment.audioTracks) {
+        Vector<InitializationSegment::AudioTrackInformation>::const_iterator aend = segment.audioTracks.end();
+        for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != aend; ++it) {
+            InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
+
             if (audioTracks()->length() == 1) {
                 audioTracks()->item(0)->setPrivate(audioTrackInfo.track);
                 break;
             }
 
-            auto audioTrack = audioTracks()->getTrackById(audioTrackInfo.track->id());
+            AudioTrack audioTrack = audioTracks()->getTrackById(audioTrackInfo.track->id());
             ASSERT(audioTrack);
             audioTrack->setPrivate(audioTrackInfo.track);
         }
 
+
         ASSERT(segment.videoTracks.size() == videoTracks()->length());
-        for (auto& videoTrackInfo : segment.videoTracks) {
+        Vector<InitializationSegment::VideoTrackInformation>::const_iterator vend = segment.videoTracks.end();
+        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+            InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
             if (videoTracks()->length() == 1) {
                 videoTracks()->item(0)->setPrivate(videoTrackInfo.track);
                 break;
             }
 
-            auto videoTrack = videoTracks()->getTrackById(videoTrackInfo.track->id());
+            VideoTrack videoTrack = videoTracks()->getTrackById(videoTrackInfo.track->id());
             ASSERT(videoTrack);
             videoTrack->setPrivate(videoTrackInfo.track);
         }
 
         ASSERT(segment.textTracks.size() == textTracks()->length());
-        for (auto& textTrackInfo : segment.textTracks) {
+        Vector<InitializationSegment::TextTrackInformation>::const_iterator tend = segment.textTracks.end();
+        for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != tend; ++it) {
             if (textTracks()->length() == 1) {
                 static_cast<InbandTextTrack>(*textTracks()->item(0)).setPrivate(textTrackInfo.track);
                 break;
             }
 
-            auto textTrack = textTracks()->getTrackById(textTrackInfo.track->id());
+            TextTrack textTrack = textTracks()->getTrackById(textTrackInfo.track->id());
             ASSERT(textTrack);
             static_cast<InbandTextTrack>(*textTrack).setPrivate(textTrackInfo.track);
         }
 
-        for (auto& trackBuffer : m_trackBufferMap.values())
+        HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
+        for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+            TrackBuffer& trackBuffer = it->value;
             trackBuffer.needRandomAccessFlag = true;
+        }
     }
 
     // 4. Let active track flag equal false.
@@ -952,7 +962,9 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         // NOTE: This check is the responsibility of the SourceBufferPrivate.
 
         // 5.2 For each audio track in the initialization segment, run following steps:
-        for (auto& audioTrackInfo : segment.audioTracks) {
+        Vector<InitializationSegment::AudioTrackInformation>::iterator aend = segment.audioTracks.end();
+        for (Vector<InitializationSegment::AudioTrackInformation>::iterator it = segment.audioTracks.begin(); it != aend; ++it) {
+            InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
             AudioTrackPrivate* audioTrackPrivate = audioTrackInfo.track.get();
 
             // 5.2.1 Let new audio track be a new AudioTrack object.
@@ -992,7 +1004,9 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         }
 
         // 5.3 For each video track in the initialization segment, run following steps:
-        for (auto& videoTrackInfo : segment.videoTracks) {
+        Vector<InitializationSegment::VideoTrackInformation>::iterator vend = segment.videoTracks.end();
+        for (Vector<InitializationSegment::VideoTrackInformation>::iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+            InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
             VideoTrackPrivate* videoTrackPrivate = videoTrackInfo.track.get();
 
             // 5.3.1 Let new video track be a new VideoTrack object.
@@ -1032,7 +1046,9 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         }
 
         // 5.4 For each text track in the initialization segment, run following steps:
-        for (auto& textTrackInfo : segment.textTracks) {
+        Vector<InitializationSegment::TextTrackInformation>::iterator tend = segment.textTracks.end();
+        for (Vector<InitializationSegment::TextTrackInformation>::iterator it = segment.textTracks.begin(); it != tend; ++it) {
+            InitializationSegment::TextTrackInformation & textTrackInfo = *it;
             InbandTextTrackPrivate* textTrackPrivate = textTrackInfo.track.get();
 
             // 5.4.1 Let new text track be a new TextTrack object with its properties populated with the
@@ -1079,7 +1095,9 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
     // 6. If the HTMLMediaElement.readyState attribute is HAVE_NOTHING, then run the following steps:
     if (m_private->readyState() == MediaPlayer::HaveNothing) {
         // 6.1 If one or more objects in sourceBuffers have first initialization segment flag set to false, then abort these steps.
-        for (auto& sourceBuffer : *m_source->sourceBuffers()) {
+        Vector<RefPtr <SourceBuffer> >::iterator end = m_source->sourceBuffers()->end();
+        for (Vector<RefPtr <SourceBuffer> >::iterator it = m_source->sourceBuffers()->begin(); it != end; ++it) {
+            SourceBuffer *sourceBuffer = it->value;
             if (!sourceBuffer->m_receivedFirstInitializationSegment)
                 return;
         }

From f1a07fa5e3bf8e7786f0ee4443c1bcb6b53c8c1b Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:41:06 +0100
Subject: [PATCH 08/68] All tracks now have a MediaSource member with
 associated functions.

---
 Source/WebCore/html/track/TrackBase.cpp |  7 +++++--
 Source/WebCore/html/track/TrackBase.h   | 14 ++++++++++++--
 2 files changed, 17 insertions(+), 4 deletions(-)

diff --git a/Source/WebCore/html/track/TrackBase.cpp b/Source/WebCore/html/track/TrackBase.cpp
index b928a73..9327d5a 100644
--- a/Source/WebCore/html/track/TrackBase.cpp
+++ b/Source/WebCore/html/track/TrackBase.cpp
@@ -10,10 +10,10 @@
  *    notice, this list of conditions and the following disclaimer in the
  *    documentation and/or other materials provided with the distribution.
  *
- * THIS SOFTWARE IS PROVIDED BY APPLE COMPUTER, INC. ``AS IS'' AND ANY
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE COMPUTER, INC. OR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
@@ -34,6 +34,9 @@ namespace WebCore {
 
 TrackBase::TrackBase(Type type, const AtomicString& label, const AtomicString& language)
     : m_mediaElement(0)
+#if ENABLE(MEDIA_SOURCE)
+    , m_sourceBuffer(0)
+#endif
     , m_label(label)
     , m_language(language)
 {
diff --git a/Source/WebCore/html/track/TrackBase.h b/Source/WebCore/html/track/TrackBase.h
index a81ce31..17a0e05 100644
--- a/Source/WebCore/html/track/TrackBase.h
+++ b/Source/WebCore/html/track/TrackBase.h
@@ -10,10 +10,10 @@
  *    notice, this list of conditions and the following disclaimer in the
  *    documentation and/or other materials provided with the distribution.
  *
- * THIS SOFTWARE IS PROVIDED BY APPLE COMPUTER, INC. ``AS IS'' AND ANY
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE COMPUTER, INC. OR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
@@ -35,6 +35,7 @@ namespace WebCore {
 
 class Element;
 class HTMLMediaElement;
+class SourceBuffer;
 
 class TrackBase : public RefCounted<TrackBase> {
 public:
@@ -58,6 +59,11 @@ class TrackBase : public RefCounted<TrackBase> {
 
     virtual void clearClient() = 0;
 
+#if ENABLE(MEDIA_SOURCE)
+    SourceBuffer* sourceBuffer() const { return m_sourceBuffer; }
+    void setSourceBuffer(SourceBuffer* buffer) { m_sourceBuffer = buffer; }
+#endif
+
 protected:
     TrackBase(Type, const AtomicString& label, const AtomicString& language);
 
@@ -66,6 +72,10 @@ class TrackBase : public RefCounted<TrackBase> {
 
     HTMLMediaElement* m_mediaElement;
 
+#if ENABLE(MEDIA_SOURCE)
+    SourceBuffer* m_sourceBuffer;
+#endif
+
 private:
     Type m_type;
     AtomicString m_kind;

From 622546f3a234dae61583795082e9d07cfefbdb8a Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:41:29 +0100
Subject: [PATCH 09/68] TextTrackList provides a lastItem function.

---
 Source/WebCore/html/track/TextTrackList.h | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/Source/WebCore/html/track/TextTrackList.h b/Source/WebCore/html/track/TextTrackList.h
index 3c01d26..bf1ba75 100644
--- a/Source/WebCore/html/track/TextTrackList.h
+++ b/Source/WebCore/html/track/TextTrackList.h
@@ -10,10 +10,10 @@
  *    notice, this list of conditions and the following disclaimer in the
  *    documentation and/or other materials provided with the distribution.
  *
- * THIS SOFTWARE IS PROVIDED BY APPLE COMPUTER, INC. ``AS IS'' AND ANY
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE COMPUTER, INC. OR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
@@ -47,7 +47,8 @@ class TextTrackList : public TrackListBase {
     int getTrackIndexRelativeToRenderedTracks(TextTrack*);
     virtual bool contains(TrackBase*) const OVERRIDE;
 
-    TextTrack* item(unsigned index);
+    TextTrack* item(unsigned index) const;
+    TextTrack* lastItem() const { return item(length() - 1); }
     void append(PassRefPtr<TextTrack>);
     virtual void remove(TrackBase*) OVERRIDE;
 

From f0cf199d784d4bcc99bc28c812776198b98a415b Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:42:03 +0100
Subject: [PATCH 10/68] Keep using KURL for now.

---
 Source/WebCore/html/URLRegistry.h | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/Source/WebCore/html/URLRegistry.h b/Source/WebCore/html/URLRegistry.h
index 72c7d69..992f36c 100644
--- a/Source/WebCore/html/URLRegistry.h
+++ b/Source/WebCore/html/URLRegistry.h
@@ -35,7 +35,7 @@
 
 namespace WebCore {
 
-class URL;
+class KURL;
 class SecurityOrigin;
 class URLRegistry;
 
@@ -49,8 +49,8 @@ class URLRegistry {
     WTF_MAKE_FAST_ALLOCATED;
 public:
     virtual ~URLRegistry() { }
-    virtual void registerURL(SecurityOrigin*, const URL&, URLRegistrable*) = 0;
-    virtual void unregisterURL(const URL&) = 0;
+    virtual void registerURL(SecurityOrigin*, const KURL&, URLRegistrable*) = 0;
+    virtual void unregisterURL(const KURL&) = 0;
 
     // This is an optional API
     virtual URLRegistrable* lookup(const String&) const { ASSERT_NOT_REACHED(); return 0; }

From f76e7d2349aa41742ba16f6834d917121f1f3fb1 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:45:12 +0100
Subject: [PATCH 11/68] Slight changes in the API, inherit from URLRegistry.

---
 .../Modules/mediasource/MediaSourceRegistry.cpp    | 24 +++++++++++++---------
 .../Modules/mediasource/MediaSourceRegistry.h      | 15 ++++++++------
 2 files changed, 23 insertions(+), 16 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/MediaSourceRegistry.cpp b/Source/WebCore/Modules/mediasource/MediaSourceRegistry.cpp
index 45459df..d065960 100644
--- a/Source/WebCore/Modules/mediasource/MediaSourceRegistry.cpp
+++ b/Source/WebCore/Modules/mediasource/MediaSourceRegistry.cpp
@@ -42,39 +42,43 @@ namespace WebCore {
 MediaSourceRegistry& MediaSourceRegistry::registry()
 {
     ASSERT(isMainThread());
-    DEFINE_STATIC_LOCAL(MediaSourceRegistry, instance, ());
+    static NeverDestroyed<MediaSourceRegistry> instance;
     return instance;
 }
 
-void MediaSourceRegistry::registerMediaSourceURL(const KURL& url, PassRefPtr<MediaSource> source)
+void MediaSourceRegistry::registerURL(SecurityOrigin*, const KURL& url, URLRegistrable* registrable)
 {
+    ASSERT(&registrable->registry() == this);
     ASSERT(isMainThread());
 
-    source->setPendingActivity(source.get());
-
+    MediaSource* source = static_cast<MediaSource*>(registrable);
+    source->addedToRegistry();
     m_mediaSources.set(url.string(), source);
 }
 
-void MediaSourceRegistry::unregisterMediaSourceURL(const KURL& url)
+void MediaSourceRegistry::unregisterURL(const KURL& url)
 {
     ASSERT(isMainThread());
-    HashMap<String, RefPtr<MediaSource> >::iterator iter = m_mediaSources.find(url.string());
+    HashMap<String, RefPtr <MediaSource> >::iterator iter = m_mediaSources.find(url.string());
     if (iter == m_mediaSources.end())
         return;
 
     RefPtr<MediaSource> source = iter->value;
     m_mediaSources.remove(iter);
-
-    // Remove the pending activity added in registerMediaSourceURL().
-    source->unsetPendingActivity(source.get());
+    source->removedFromRegistry();
 }
 
-MediaSource* MediaSourceRegistry::lookupMediaSource(const String& url)
+URLRegistrable* MediaSourceRegistry::lookup(const String& url) const
 {
     ASSERT(isMainThread());
     return m_mediaSources.get(url);
 }
 
+MediaSourceRegistry::MediaSourceRegistry()
+{
+    MediaSource::setRegistry(this);
+}
+
 } // namespace WebCore
 
 #endif
diff --git a/Source/WebCore/Modules/mediasource/MediaSourceRegistry.h b/Source/WebCore/Modules/mediasource/MediaSourceRegistry.h
index 96da6b3..a2706a0 100644
--- a/Source/WebCore/Modules/mediasource/MediaSourceRegistry.h
+++ b/Source/WebCore/Modules/mediasource/MediaSourceRegistry.h
@@ -33,7 +33,9 @@
 
 #if ENABLE(MEDIA_SOURCE)
 
+#include "URLRegistry.h"
 #include <wtf/HashMap.h>
+#include <wtf/NeverDestroyed.h>
 #include <wtf/PassRefPtr.h>
 #include <wtf/text/StringHash.h>
 
@@ -42,19 +44,20 @@ namespace WebCore {
 class KURL;
 class MediaSource;
 
-class MediaSourceRegistry {
+class MediaSourceRegistry : public URLRegistry {
+    friend class NeverDestroyed<MediaSourceRegistry>;
 public:
     // Returns a single instance of MediaSourceRegistry.
     static MediaSourceRegistry& registry();
 
     // Registers a blob URL referring to the specified media source.
-    void registerMediaSourceURL(const KURL&, PassRefPtr<MediaSource>);
-    void unregisterMediaSourceURL(const KURL&);
-
-    MediaSource* lookupMediaSource(const String& url);
+    virtual void registerURL(SecurityOrigin*, const KURL&, URLRegistrable*) OVERRIDE;
+    virtual void unregisterURL(const KURL&) OVERRIDE;
+    virtual URLRegistrable* lookup(const String&) const OVERRIDE;
 
 private:
-    HashMap<String, RefPtr<MediaSource> > m_mediaSources;
+    MediaSourceRegistry();
+    HashMap<String, RefPtr <MediaSource> > m_mediaSources;
 };
 
 } // namespace WebCore

From a73cb136af7e54f31c79f9820f8fe3f09e66ec2b Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:47:38 +0100
Subject: [PATCH 12/68] Expose some new public APIs.

---
 Source/WebCore/html/HTMLMediaElement.h | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/Source/WebCore/html/HTMLMediaElement.h b/Source/WebCore/html/HTMLMediaElement.h
index 66bd638..6278369 100644
--- a/Source/WebCore/html/HTMLMediaElement.h
+++ b/Source/WebCore/html/HTMLMediaElement.h
@@ -377,6 +377,9 @@ class HTMLMediaElement : public HTMLElement, private MediaPlayerClient, public M
     virtual bool dispatchEvent(PassRefPtr<Event>) OVERRIDE;
 
     virtual bool willRespondToMouseClickEvents() OVERRIDE;
+    
+    void mediaLoadingFailed(MediaPlayer::NetworkState);
+    void mediaEngineError(PassRefPtr<MediaError> err);
 
 protected:
     HTMLMediaElement(const QualifiedName&, Document*, bool);
@@ -538,15 +541,12 @@ class HTMLMediaElement : public HTMLElement, private MediaPlayerClient, public M
     void clearMediaPlayer(int flags);
     bool havePotentialSourceChild();
     void noneSupported();
-    void mediaEngineError(PassRefPtr<MediaError> err);
     void cancelPendingEventsAndCallbacks();
     void waitForSourceChange();
     void prepareToPlay();
 
     KURL selectNextSourceChild(ContentType*, String* keySystem, InvalidURLAction);
 
-    void mediaLoadingFailed(MediaPlayer::NetworkState);
-
 #if ENABLE(VIDEO_TRACK)
     void updateActiveTextTrackCues(double);
     HTMLTrackElement* showingTrackWithSameKind(HTMLTrackElement*) const;

From 321d68d61c8c3cb1883f2b7813086d21676f9cb8 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:47:59 +0100
Subject: [PATCH 13/68] Use new API from MediaSourceRegistry.

---
 Source/WebCore/html/DOMURL.cpp         | 4 ++--
 Source/WebCore/html/PublicURLManager.h | 4 ++--
 2 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/Source/WebCore/html/DOMURL.cpp b/Source/WebCore/html/DOMURL.cpp
index 36e559e..432c5e9 100644
--- a/Source/WebCore/html/DOMURL.cpp
+++ b/Source/WebCore/html/DOMURL.cpp
@@ -67,7 +67,7 @@ String DOMURL::createObjectURL(ScriptExecutionContext* scriptExecutionContext, M
     if (publicURL.isEmpty())
         return String();
 
-    MediaSourceRegistry::registry().registerMediaSourceURL(publicURL, source);
+    MediaSourceRegistry::registry().registerURL(scriptExecutionContext->securityOrigin(), publicURL, source);
     scriptExecutionContext->publicURLManager().sourceURLs().add(publicURL.string());
 
     return publicURL.string();
@@ -130,7 +130,7 @@ void DOMURL::revokeObjectURL(ScriptExecutionContext* scriptExecutionContext, con
 #if ENABLE(MEDIA_SOURCE)
     HashSet<String>& sourceURLs = scriptExecutionContext->publicURLManager().sourceURLs();
     if (sourceURLs.contains(url.string())) {
-        MediaSourceRegistry::registry().unregisterMediaSourceURL(url);
+        MediaSourceRegistry::registry().unregisterURL(url);
         sourceURLs.remove(url.string());
     }
 #endif
diff --git a/Source/WebCore/html/PublicURLManager.h b/Source/WebCore/html/PublicURLManager.h
index e17e46a..4d94c56 100644
--- a/Source/WebCore/html/PublicURLManager.h
+++ b/Source/WebCore/html/PublicURLManager.h
@@ -59,12 +59,12 @@ class PublicURLManager {
 #if ENABLE(MEDIA_STREAM)
         HashSet<String>::iterator streamURLsEnd = m_streamURLs.end();
         for (HashSet<String>::iterator iter = m_streamURLs.begin(); iter != streamURLsEnd; ++iter)
-            MediaStreamRegistry::registry().unregisterMediaStreamURL(KURL(ParsedURLString, *iter));
+            MediaStreamRegistry::registry().unregisterURL(KURL(ParsedURLString, *iter));
 #endif
 #if ENABLE(MEDIA_SOURCE)
         HashSet<String>::iterator sourceURLsEnd = m_sourceURLs.end();
         for (HashSet<String>::iterator iter = m_sourceURLs.begin(); iter != sourceURLsEnd; ++iter)
-            MediaSourceRegistry::registry().unregisterMediaSourceURL(KURL(ParsedURLString, *iter));
+            MediaSourceRegistry::registry().unregisterURL(KURL(ParsedURLString, *iter));
 #endif
     }
 

From ff2e6061bb63520600f27913fc96badc9ee9a999 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:48:27 +0100
Subject: [PATCH 14/68] Backport from trunk.

---
 .../platform/graphics/SourceBufferPrivate.h        | 25 ++++++++++++++++++----
 1 file changed, 21 insertions(+), 4 deletions(-)

diff --git a/Source/WebCore/platform/graphics/SourceBufferPrivate.h b/Source/WebCore/platform/graphics/SourceBufferPrivate.h
index 009badf..087b158 100644
--- a/Source/WebCore/platform/graphics/SourceBufferPrivate.h
+++ b/Source/WebCore/platform/graphics/SourceBufferPrivate.h
@@ -1,5 +1,6 @@
 /*
  * Copyright (C) 2013 Google Inc. All rights reserved.
+ * Copyright (C) 2013-2014 Apple Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are
@@ -32,20 +33,36 @@
 
 #if ENABLE(MEDIA_SOURCE)
 
+#include "MediaPlayer.h"
 #include "TimeRanges.h"
+#include <wtf/RefCounted.h>
+#include <wtf/Vector.h>
 
 namespace WebCore {
 
-class SourceBufferPrivate {
+class MediaSample;
+class SourceBufferPrivateClient;
+class TimeRanges;
+
+class SourceBufferPrivate : public RefCounted<SourceBufferPrivate> {
 public:
-    SourceBufferPrivate() { }
     virtual ~SourceBufferPrivate() { }
 
-    virtual PassRefPtr<TimeRanges> buffered() = 0;
+    virtual void setClient(SourceBufferPrivateClient*) = 0;
+
     virtual void append(const unsigned char* data, unsigned length) = 0;
     virtual void abort() = 0;
-    virtual bool setTimestampOffset(double) = 0;
     virtual void removedFromMediaSource() = 0;
+
+    virtual MediaPlayer::ReadyState readyState() const = 0;
+    virtual void setReadyState(MediaPlayer::ReadyState) = 0;
+
+    virtual void flushAndEnqueueNonDisplayingSamples(Vector< RefPtr<MediaSample> >, AtomicString) { }
+    virtual void enqueueSample(PassRefPtr<MediaSample>, AtomicString) { }
+    virtual bool isReadyForMoreSamples(AtomicString) { return false; }
+    virtual void setActive(bool) { }
+    virtual void stopAskingForMoreSamples(AtomicString) { }
+    virtual void notifyClientWhenReadyForMoreSamples(AtomicString) { }
 };
 
 }

From a93f489cf4470d0c037f6b0024a4e97db5cd2ad5 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:49:21 +0100
Subject: [PATCH 15/68] Backport from trunk. This new version uses a layered
 implementation with platform specifics.

---
 Source/WebCore/html/TimeRanges.cpp | 192 +++++++++++++------------------------
 Source/WebCore/html/TimeRanges.h   |  75 ++++-----------
 2 files changed, 84 insertions(+), 183 deletions(-)

diff --git a/Source/WebCore/html/TimeRanges.cpp b/Source/WebCore/html/TimeRanges.cpp
index cf8e20f..3bb1367 100644
--- a/Source/WebCore/html/TimeRanges.cpp
+++ b/Source/WebCore/html/TimeRanges.cpp
@@ -10,10 +10,10 @@
  *    notice, this list of conditions and the following disclaimer in the
  *    documentation and/or other materials provided with the distribution.
  *
- * THIS SOFTWARE IS PROVIDED BY APPLE COMPUTER, INC. ``AS IS'' AND ANY
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE COMPUTER, INC. OR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
@@ -29,168 +29,110 @@
 
 #include "ExceptionCode.h"
 #include "ExceptionCodePlaceholder.h"
-#include <math.h>
 
-using namespace WebCore;
-using namespace std;
+namespace WebCore {
 
-TimeRanges::TimeRanges(double start, double end)
+PassRefPtr<TimeRanges> TimeRanges::create()
 {
-    add(start, end);
+    return adoptRef(new TimeRanges);
 }
 
-PassRefPtr<TimeRanges> TimeRanges::copy() const
+PassRefPtr<TimeRanges> TimeRanges::create(double start, double end)
 {
-    RefPtr<TimeRanges> newSession = TimeRanges::create();
-    
-    unsigned size = m_ranges.size();
-    for (unsigned i = 0; i < size; i++)
-        newSession->add(m_ranges[i].m_start, m_ranges[i].m_end);
-    
-    return newSession.release();
+    return adoptRef(new TimeRanges(start, end));
 }
 
-void TimeRanges::invert()
+PassRefPtr<TimeRanges> TimeRanges::create(const PlatformTimeRanges& other)
 {
-    RefPtr<TimeRanges> inverted = TimeRanges::create();
-    double posInf = std::numeric_limits<double>::infinity();
-    double negInf = -std::numeric_limits<double>::infinity();
-
-    if (!m_ranges.size())
-        inverted->add(negInf, posInf);
-    else {
-        if (double start = m_ranges.first().m_start != negInf)
-            inverted->add(negInf, start);
-
-        for (size_t index = 0; index + 1 < m_ranges.size(); ++index)
-            inverted->add(m_ranges[index].m_end, m_ranges[index + 1].m_start);
-
-        if (double end = m_ranges.last().m_end != posInf)
-            inverted->add(end, posInf);
-    }
-
-    m_ranges.swap(inverted->m_ranges);
+    return adoptRef(new TimeRanges(other));
 }
 
-void TimeRanges::intersectWith(const TimeRanges* other)
+TimeRanges::TimeRanges()
 {
-    ASSERT(other);
-    RefPtr<TimeRanges> inverted = copy();
-    RefPtr<TimeRanges> invertedOther = other->copy();
-    inverted->unionWith(invertedOther.get());
-    inverted->invert();
-
-    m_ranges.swap(inverted->m_ranges);
 }
 
-void TimeRanges::unionWith(const TimeRanges* other)
+TimeRanges::TimeRanges(double start, double end)
+    : m_ranges(PlatformTimeRanges(MediaTime::createWithDouble(start), MediaTime::createWithDouble(end)))
 {
-    ASSERT(other);
-    RefPtr<TimeRanges> unioned = copy();
-    for (size_t index = 0; index < other->m_ranges.size(); ++index) {
-        const Range& range = other->m_ranges[index];
-        unioned->add(range.m_start, range.m_end);
-    }
+}
 
-    m_ranges.swap(unioned->m_ranges);
+TimeRanges::TimeRanges(const PlatformTimeRanges& other)
+    : m_ranges(other)
+{
 }
 
-double TimeRanges::start(unsigned index, ExceptionCode& ec) const 
-{ 
-    if (index >= length()) {
+double TimeRanges::start(unsigned index, ExceptionCode& ec) const
+{
+    bool valid;
+    MediaTime result = m_ranges.start(index, valid);
+
+    if (!valid) {
         ec = INDEX_SIZE_ERR;
         return 0;
     }
-    return m_ranges[index].m_start;
+    return result.toDouble();
 }
 
 double TimeRanges::end(unsigned index, ExceptionCode& ec) const 
 { 
-    if (index >= length()) {
+    bool valid;
+    MediaTime result = m_ranges.end(index, valid);
+
+    if (!valid) {
         ec = INDEX_SIZE_ERR;
         return 0;
     }
-    return m_ranges[index].m_end;
-}
-
-void TimeRanges::add(double start, double end) 
-{
-    ASSERT(start <= end);
-    unsigned int overlappingArcIndex;
-    Range addedRange(start, end);
-
-    // For each present range check if we need to:
-    // - merge with the added range, in case we are overlapping or contiguous
-    // - Need to insert in place, we we are completely, not overlapping and not contiguous
-    // in between two ranges.
-    //
-    // TODO: Given that we assume that ranges are correctly ordered, this could be optimized.
-
-    for (overlappingArcIndex = 0; overlappingArcIndex < m_ranges.size(); overlappingArcIndex++) {
-        if (addedRange.isOverlappingRange(m_ranges[overlappingArcIndex])
-         || addedRange.isContiguousWithRange(m_ranges[overlappingArcIndex])) {
-            // We need to merge the addedRange and that range.
-            addedRange = addedRange.unionWithOverlappingOrContiguousRange(m_ranges[overlappingArcIndex]);
-            m_ranges.remove(overlappingArcIndex);
-            overlappingArcIndex--;
-        } else {
-            // Check the case for which there is no more to do
-            if (!overlappingArcIndex) {
-                if (addedRange.isBeforeRange(m_ranges[0])) {
-                    // First index, and we are completely before that range (and not contiguous, nor overlapping).
-                    // We just need to be inserted here.
-                    break;
-                }
-            } else {
-                if (m_ranges[overlappingArcIndex - 1].isBeforeRange(addedRange)
-                 && addedRange.isBeforeRange(m_ranges[overlappingArcIndex])) {
-                    // We are exactly after the current previous range, and before the current range, while
-                    // not overlapping with none of them. Insert here.
-                    break;
-                }
-            }
-        }
-    }
+    return result.toDouble();
+}
+
+void TimeRanges::invert()
+{
+    m_ranges.invert();
+}
+
+PassRefPtr<TimeRanges> TimeRanges::copy() const
+{
+    return TimeRanges::create(m_ranges);
+}
+
+void TimeRanges::intersectWith(const TimeRanges* other)
+{
+    m_ranges.intersectWith(other->ranges());
+}
+
+void TimeRanges::unionWith(const TimeRanges* other)
+{
+    m_ranges.unionWith(other->ranges());
+}
+
+unsigned TimeRanges::length() const
+{
+    return m_ranges.length();
+}
 
-    // Now that we are sure we don't overlap with any range, just add it.
-    m_ranges.insert(overlappingArcIndex, addedRange);
+void TimeRanges::add(double start, double end)
+{
+    m_ranges.add(MediaTime::createWithDouble(start), MediaTime::createWithDouble(end));
 }
 
 bool TimeRanges::contain(double time) const
 {
-    for (unsigned n = 0; n < length(); n++) {
-        if (time >= start(n, IGNORE_EXCEPTION) && time <= end(n, IGNORE_EXCEPTION))
-            return true;
-    }
-    return false;
+    return m_ranges.contain(MediaTime::createWithDouble(time));
+}
+
+size_t TimeRanges::find(double time) const
+{
+    return m_ranges.find(MediaTime::createWithDouble(time));
 }
 
 double TimeRanges::nearest(double time) const
 {
-    double closestDelta = std::numeric_limits<double>::infinity();
-    double closestTime = 0;
-    unsigned count = length();
-    for (unsigned ndx = 0; ndx < count; ndx++) {
-        double startTime = start(ndx, IGNORE_EXCEPTION);
-        double endTime = end(ndx, IGNORE_EXCEPTION);
-        if (time >= startTime && time <= endTime)
-            return time;
-        if (fabs(startTime - time) < closestDelta) {
-            closestTime = startTime;
-            closestDelta = fabsf(startTime - time);
-        }
-        if (fabs(endTime - time) < closestDelta) {
-            closestTime = endTime;
-            closestDelta = fabsf(endTime - time);
-        }
-    }
-    return closestTime;
+    return m_ranges.nearest(MediaTime::createWithDouble(time)).toDouble();
 }
 
 double TimeRanges::totalDuration() const
 {
-    double total = 0;
-    for (unsigned n = 0; n < length(); n++)
-        total += fabs(end(n, IGNORE_EXCEPTION) - start(n, IGNORE_EXCEPTION));
-    return total;
+    return m_ranges.totalDuration().toDouble();
+}
+
 }
diff --git a/Source/WebCore/html/TimeRanges.h b/Source/WebCore/html/TimeRanges.h
index 97f4eb7..9cc01b8 100644
--- a/Source/WebCore/html/TimeRanges.h
+++ b/Source/WebCore/html/TimeRanges.h
@@ -10,10 +10,10 @@
  *    notice, this list of conditions and the following disclaimer in the
  *    documentation and/or other materials provided with the distribution.
  *
- * THIS SOFTWARE IS PROVIDED BY APPLE COMPUTER, INC. ``AS IS'' AND ANY
+ * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS'' AND ANY
  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
- * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE COMPUTER, INC. OR
+ * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
@@ -26,6 +26,7 @@
 #ifndef TimeRanges_h
 #define TimeRanges_h
 
+#include "PlatformTimeRanges.h"
 #include <algorithm>
 #include <wtf/PassRefPtr.h>
 #include <wtf/RefCounted.h>
@@ -37,80 +38,38 @@ typedef int ExceptionCode;
 
 class TimeRanges : public RefCounted<TimeRanges> {
 public:
-    static PassRefPtr<TimeRanges> create() 
-    {
-        return adoptRef(new TimeRanges);
-    }
-    static PassRefPtr<TimeRanges> create(double start, double end)
-    {
-        return adoptRef(new TimeRanges(start, end));
-    }
+    static PassRefPtr<TimeRanges> create() ;
+    static PassRefPtr<TimeRanges> create(double start, double end);
+    static PassRefPtr<TimeRanges> create(const PlatformTimeRanges&);
+
+    double start(unsigned index, ExceptionCode&) const;
+    double end(unsigned index, ExceptionCode&) const;
 
     PassRefPtr<TimeRanges> copy() const;
     void invert();
     void intersectWith(const TimeRanges*);
     void unionWith(const TimeRanges*);
 
-    unsigned length() const { return m_ranges.size(); }
-    double start(unsigned index, ExceptionCode&) const;
-    double end(unsigned index, ExceptionCode&) const;
+    unsigned length() const;
     
     void add(double start, double end);
-    
     bool contain(double time) const;
     
+    size_t find(double time) const;
     double nearest(double time) const;
 
     double totalDuration() const;
 
+    const PlatformTimeRanges& ranges() const { return m_ranges; }
+    PlatformTimeRanges& ranges() { return m_ranges; }
+
 private:
-    TimeRanges() { }
+    TimeRanges();
     TimeRanges(double start, double end);
-    TimeRanges(const TimeRanges&);
-
-    // We consider all the Ranges to be semi-bounded as follow: [start, end[
-    struct Range {
-        Range() { }
-        Range(double start, double end)
-        {
-            m_start = start;
-            m_end = end;
-        }
-        double m_start;
-        double m_end;
-
-        inline bool isPointInRange(double point) const
-        {
-            return m_start <= point && point < m_end;
-        }
-        
-        inline bool isOverlappingRange(const Range& range) const
-        {
-            return isPointInRange(range.m_start) || isPointInRange(range.m_end) || range.isPointInRange(m_start);
-        }
+    TimeRanges(const PlatformTimeRanges&);
 
-        inline bool isContiguousWithRange(const Range& range) const
-        {
-            return range.m_start == m_end || range.m_end == m_start;
-        }
-        
-        inline Range unionWithOverlappingOrContiguousRange(const Range& range) const
-        {
-            Range ret;
 
-            ret.m_start = std::min(m_start, range.m_start);
-            ret.m_end = std::max(m_end, range.m_end);
-
-            return ret;
-        }
-
-        inline bool isBeforeRange(const Range& range) const
-        {
-            return range.m_start >= m_end;
-        }
-    };
-    
-    Vector<Range> m_ranges;
+    PlatformTimeRanges m_ranges;
 };
 
 } // namespace WebCore

From 97687f9a5411cc4f2eb6f1733b6ed331d9806930 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:49:52 +0100
Subject: [PATCH 16/68] Try to provide the usual API to work with iterators.

---
 Source/WebCore/Modules/mediasource/SourceBufferList.h | 6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBufferList.h b/Source/WebCore/Modules/mediasource/SourceBufferList.h
index 27a418e..4ebe9fd 100644
--- a/Source/WebCore/Modules/mediasource/SourceBufferList.h
+++ b/Source/WebCore/Modules/mediasource/SourceBufferList.h
@@ -60,8 +60,10 @@ class SourceBufferList : public RefCounted<SourceBufferList>, public ScriptWrapp
     void clear();
     void swap(Vector<RefPtr <SourceBuffer> >&);
 
-    Vector<RefPtr <SourceBuffer> >::iterator begin() { return m_list.begin(); }
-    Vector<RefPtr <SourceBuffer> >::iterator end() { return m_list.end(); }
+    typedef RefPtr <SourceBuffer> * iterator;
+    typedef const RefPtr <SourceBuffer> * const_iterator;
+    iterator begin() { return m_list.begin(); }
+    iterator end() { return m_list.end(); }
 
     // EventTarget interface
     virtual const AtomicString& interfaceName() const; 

From daef97b87d0c413ffb9e8414f15e3f51660b4f9c Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:51:58 +0100
Subject: [PATCH 17/68] Backport trunk code trying to use our "old" API.

---
 Source/WebCore/Modules/mediasource/MediaSource.cpp | 139 ++++++++++++---------
 Source/WebCore/Modules/mediasource/MediaSource.h   |   5 +-
 Source/WebCore/Modules/mediasource/MediaSource.idl |  16 ++-
 3 files changed, 96 insertions(+), 64 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/MediaSource.cpp b/Source/WebCore/Modules/mediasource/MediaSource.cpp
index 2b27a49..6938b77 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.cpp
+++ b/Source/WebCore/Modules/mediasource/MediaSource.cpp
@@ -114,7 +114,7 @@ void MediaSource::setPrivateAndOpen(PassOwnPtr<MediaSourcePrivate> mediaSourcePr
 {
     ASSERT(!m_private);
     ASSERT(m_mediaElement);
-    m_private = WTF::move(mediaSourcePrivate);
+    m_private = mediaSourcePrivate.get ();
     setReadyState(openKeyword());
 }
 
@@ -135,7 +135,7 @@ MediaTime MediaSource::duration() const
 
 MediaTime MediaSource::currentTime() const
 {
-    return m_mediaElement ? m_mediaElement->currentMediaTime() : MediaTime::zeroTime();
+    return /*FIXME m_mediaElement ? m_mediaElement->currentMediaTime() : */MediaTime::zeroTime();
 }
 
 PassOwnPtr<PlatformTimeRanges> MediaSource::buffered() const
@@ -151,14 +151,14 @@ PassOwnPtr<PlatformTimeRanges> MediaSource::buffered() const
     // 2. Let active ranges be the ranges returned by buffered for each SourceBuffer object in activeSourceBuffers.
     // 3. Let highest end time be the largest range end time in the active ranges.
     MediaTime highestEndTime = MediaTime::zeroTime();
-    for (auto& ranges : activeRanges) {
-        unsigned length = ranges.length();
+    for (Vector<PlatformTimeRanges>::const_iterator ranges = activeRanges.begin(); ranges != activeRanges.end(); ++ranges) {
+        unsigned length = ranges->length();
         if (length)
-            highestEndTime = std::max(highestEndTime, ranges.end(length - 1));
+            highestEndTime = std::max(highestEndTime, ranges->end(length - 1));
     }
 
     // Return an empty range if all ranges are empty.
-    if (!highestEndTime)
+    if (highestEndTime == MediaTime::zeroTime())
         return PlatformTimeRanges::create();
 
     // 4. Let intersection ranges equal a TimeRange object containing a single range from 0 to highest end time.
@@ -166,15 +166,15 @@ PassOwnPtr<PlatformTimeRanges> MediaSource::buffered() const
 
     // 5. For each SourceBuffer object in activeSourceBuffers run the following steps:
     bool ended = readyState() == endedKeyword();
-    for (auto& sourceRanges : activeRanges) {
+    for (Vector<PlatformTimeRanges>::iterator sourceRanges = activeRanges.begin(); sourceRanges != activeRanges.end(); ++sourceRanges) {
         // 5.1 Let source ranges equal the ranges returned by the buffered attribute on the current SourceBuffer.
         // 5.2 If readyState is "ended", then set the end time on the last range in source ranges to highest end time.
-        if (ended && sourceRanges.length())
-            sourceRanges.add(sourceRanges.start(sourceRanges.length() - 1), highestEndTime);
+        if (ended && sourceRanges->length())
+            sourceRanges->add(sourceRanges->start(sourceRanges->length() - 1), highestEndTime);
 
         // 5.3 Let new intersection ranges equal the the intersection between the intersection ranges and the source ranges.
         // 5.4 Replace the ranges in intersection ranges with the new intersection ranges.
-        intersectionRanges.intersectWith(sourceRanges);
+        intersectionRanges.intersectWith(*sourceRanges);
     }
 
     return PlatformTimeRanges::create(intersectionRanges);
@@ -192,7 +192,8 @@ void MediaSource::seekToTime(const MediaTime& time)
     // to play back that position" step of the seek algorithm:
     // 1. The media element looks for media segments containing the new playback position in each SourceBuffer
     // object in activeSourceBuffers.
-    for (auto& sourceBuffer : *m_activeSourceBuffers) {
+    for (SourceBufferList::const_iterator it = m_activeSourceBuffers->begin(); it != m_activeSourceBuffers->end(); ++it) {
+        RefPtr<SourceBuffer> sourceBuffer = *it;
         // ↳ If one or more of the objects in activeSourceBuffers is missing media segments for the new
         // playback position
         if (!sourceBuffer->buffered()->ranges().contain(time)) {
@@ -224,8 +225,10 @@ void MediaSource::completeSeek()
     // initialization segment.
     // 3. The media element feeds coded frames from the active track buffers into the decoders starting
     // with the closest random access point before the new playback position.
-    for (auto& sourceBuffer : *m_activeSourceBuffers)
+    for (SourceBufferList::const_iterator it = m_activeSourceBuffers->begin(); it != m_activeSourceBuffers->end(); ++it) {
+        RefPtr<SourceBuffer> sourceBuffer = *it;
         sourceBuffer->seekToTime(m_pendingSeekTime);
+    }
 
     // 4. Resume the seek algorithm at the "Await a stable state" step.
     m_private->seekCompleted();
@@ -247,11 +250,15 @@ void MediaSource::monitorSourceBuffers()
 
     // ↳ If buffered for all objects in activeSourceBuffers do not contain TimeRanges for the current
     // playback position:
-    auto begin = m_activeSourceBuffers->begin();
-    auto end = m_activeSourceBuffers->end();
-    if (std::all_of(begin, end, [](RefPtr<SourceBuffer>& sourceBuffer) {
-        return !sourceBuffer->hasCurrentTime();
-    })) {
+    bool noneHasCurrentTime = true;
+    for (SourceBufferList::const_iterator it = m_activeSourceBuffers->begin(); it != m_activeSourceBuffers->end(); ++it) {
+        RefPtr<SourceBuffer> sourceBuffer = *it;
+        if (sourceBuffer->hasCurrentTime ()) {
+          noneHasCurrentTime = false;
+          break;
+        }
+    }
+    if (noneHasCurrentTime) {
         // 1. Set the HTMLMediaElement.readyState attribute to HAVE_METADATA.
         // 2. If this is the first transition to HAVE_METADATA, then queue a task to fire a simple event
         // named loadedmetadata at the media element.
@@ -263,9 +270,15 @@ void MediaSource::monitorSourceBuffers()
 
     // ↳ If buffered for all objects in activeSourceBuffers contain TimeRanges that include the current
     // playback position and enough data to ensure uninterrupted playback:
-    if (std::all_of(begin, end, [](RefPtr<SourceBuffer>& sourceBuffer) {
-        return sourceBuffer->hasFutureTime() && sourceBuffer->canPlayThrough();
-    })) {
+    bool allCanPlayThrough = true;
+    for (SourceBufferList::const_iterator it = m_activeSourceBuffers->begin(); it != m_activeSourceBuffers->end(); ++it) {
+        RefPtr<SourceBuffer> sourceBuffer = *it;
+        if (!sourceBuffer->hasFutureTime() || !sourceBuffer->canPlayThrough()) {
+          allCanPlayThrough = false;
+          break;
+        }
+    }
+    if (allCanPlayThrough) {
         // 1. Set the HTMLMediaElement.readyState attribute to HAVE_ENOUGH_DATA.
         // 2. Queue a task to fire a simple event named canplaythrough at the media element.
         // 3. Playback may resume at this point if it was previously suspended by a transition to HAVE_CURRENT_DATA.
@@ -280,9 +293,15 @@ void MediaSource::monitorSourceBuffers()
 
     // ↳ If buffered for all objects in activeSourceBuffers contain a TimeRange that includes
     // the current playback position and some time beyond the current playback position, then run the following steps:
-    if (std::all_of(begin, end, [](RefPtr<SourceBuffer>& sourceBuffer) {
-        return sourceBuffer->hasFutureTime();
-    })) {
+    bool allHaveFutureTime = true;
+    for (SourceBufferList::const_iterator it = m_activeSourceBuffers->begin(); it != m_activeSourceBuffers->end(); ++it) {
+        RefPtr<SourceBuffer> sourceBuffer = *it;
+        if (!sourceBuffer->hasFutureTime()) {
+          allHaveFutureTime = false;
+          break;
+        }
+    }
+    if (allHaveFutureTime) {
         // 1. Set the HTMLMediaElement.readyState attribute to HAVE_FUTURE_DATA.
         // 2. If the previous value of HTMLMediaElement.readyState was less than HAVE_FUTURE_DATA, then queue a task to fire a simple event named canplay at the media element.
         // 3. Playback may resume at this point if it was previously suspended by a transition to HAVE_CURRENT_DATA.
@@ -333,7 +352,8 @@ void MediaSource::setDuration(double duration, ExceptionCode& ec)
 
     // 3. If the updating attribute equals true on any SourceBuffer in sourceBuffers, then throw an INVALID_STATE_ERR
     // exception and abort these steps.
-    for (auto& sourceBuffer : *m_sourceBuffers) {
+    for (SourceBufferList::const_iterator it = m_sourceBuffers->begin(); it != m_sourceBuffers->end(); ++it) {
+        RefPtr<SourceBuffer> sourceBuffer = *it;
         if (sourceBuffer->updating()) {
             ec = INVALID_STATE_ERR;
             return;
@@ -362,8 +382,10 @@ void MediaSource::setDurationInternal(const MediaTime& duration)
     // 4. If the new duration is less than old duration, then call remove(new duration, old duration)
     // on all objects in sourceBuffers.
     if (oldDuration.isValid() && duration < oldDuration) {
-        for (auto& sourceBuffer : *m_sourceBuffers)
+        for (SourceBufferList::const_iterator it = m_sourceBuffers->begin(); it != m_sourceBuffers->end(); ++it) {
+            RefPtr<SourceBuffer> sourceBuffer = *it;
             sourceBuffer->remove(duration, oldDuration, IGNORE_EXCEPTION);
+        }
     }
 
     // 5. If a user agent is unable to partially render audio frames or text cues that start before and end after the
@@ -399,11 +421,6 @@ void MediaSource::setReadyState(const AtomicString& state)
     onReadyStateChange(oldState, state);
 }
 
-static bool SourceBufferIsUpdating(RefPtr<SourceBuffer>& sourceBuffer)
-{
-    return sourceBuffer->updating();
-}
-
 void MediaSource::endOfStream(ExceptionCode& ec)
 {
     endOfStream(emptyAtom, ec);
@@ -421,7 +438,15 @@ void MediaSource::endOfStream(const AtomicString& error, ExceptionCode& ec)
 
     // 2. If the updating attribute equals true on any SourceBuffer in sourceBuffers, then throw an
     // INVALID_STATE_ERR exception and abort these steps.
-    if (std::any_of(m_sourceBuffers->begin(), m_sourceBuffers->end(), SourceBufferIsUpdating)) {
+    bool anyUpdating = false;
+    for (SourceBufferList::const_iterator it = m_sourceBuffers->begin(); it != m_sourceBuffers->end(); ++it) {
+        RefPtr<SourceBuffer> sourceBuffer = *it;
+        if (sourceBuffer->updating()) {
+          anyUpdating = true;
+          break;
+        }
+    }
+    if (anyUpdating) {
         ec = INVALID_STATE_ERR;
         return;
     }
@@ -445,8 +470,9 @@ void MediaSource::streamEndedWithError(const AtomicString& error, ExceptionCode&
         // 1. Run the duration change algorithm with new duration set to the highest end time reported by
         // the buffered attribute across all SourceBuffer objects in sourceBuffers.
         MediaTime maxEndTime;
-        for (auto& sourceBuffer : *m_sourceBuffers) {
-            if (auto length = sourceBuffer->buffered()->length())
+        for (SourceBufferList::const_iterator it = m_sourceBuffers->begin(); it != m_sourceBuffers->end(); ++it) {
+            RefPtr<SourceBuffer> sourceBuffer = *it;
+            if (unsigned length = sourceBuffer->buffered()->length())
                 maxEndTime = std::max(sourceBuffer->buffered()->ranges().end(length - 1), maxEndTime);
         }
         setDurationInternal(maxEndTime);
@@ -476,7 +502,7 @@ void MediaSource::streamEndedWithError(const AtomicString& error, ExceptionCode&
             //    Run the "If the connection is interrupted after some media data has been received, causing the
             //    user agent to give up trying to fetch the resource" steps of the resource fetch algorithm.
             //    NOTE: This step is handled by HTMLMediaElement::mediaLoadingFailedFatally().
-            m_mediaElement->mediaLoadingFailedFatally(MediaPlayer::NetworkError);
+            m_mediaElement->mediaEngineError(MediaError::create(MediaError::MEDIA_ERR_NETWORK));
         }
     } else if (error == decode) {
         // ↳ If error is set to "decode"
@@ -491,7 +517,7 @@ void MediaSource::streamEndedWithError(const AtomicString& error, ExceptionCode&
             //  ↳ If the HTMLMediaElement.readyState attribute is greater than HAVE_NOTHING
             //    Run the media data is corrupted steps of the resource fetch algorithm.
             //    NOTE: This step is handled by HTMLMediaElement::mediaLoadingFailedFatally().
-            m_mediaElement->mediaLoadingFailedFatally(MediaPlayer::DecodeError);
+            m_mediaElement->mediaEngineError(MediaError::create(MediaError::MEDIA_ERR_DECODE));
         }
     } else if (!error.isEmpty()) {
         // ↳ Otherwise
@@ -509,21 +535,21 @@ SourceBuffer* MediaSource::addSourceBuffer(const String& type, ExceptionCode& ec
     // abort these steps.
     if (type.isNull() || type.isEmpty()) {
         ec = INVALID_ACCESS_ERR;
-        return nullptr;
+        return 0;
     }
 
     // 2. If type contains a MIME type that is not supported ..., then throw a
     // NOT_SUPPORTED_ERR exception and abort these steps.
     if (!isTypeSupported(type)) {
         ec = NOT_SUPPORTED_ERR;
-        return nullptr;
+        return 0;
     }
 
     // 4. If the readyState attribute is not in the "open" state then throw an
     // INVALID_STATE_ERR exception and abort these steps.
     if (!isOpen()) {
         ec = INVALID_STATE_ERR;
-        return nullptr;
+        return 0;
     }
 
     // 5. Create a new SourceBuffer object and associated resources.
@@ -534,10 +560,10 @@ SourceBuffer* MediaSource::addSourceBuffer(const String& type, ExceptionCode& ec
         ASSERT(ec == NOT_SUPPORTED_ERR || ec == QUOTA_EXCEEDED_ERR);
         // 2. If type contains a MIME type that is not supported ..., then throw a NOT_SUPPORTED_ERR exception and abort these steps.
         // 3. If the user agent can't handle any more SourceBuffer objects then throw a QUOTA_EXCEEDED_ERR exception and abort these steps
-        return nullptr;
+        return 0;
     }
 
-    RefPtr<SourceBuffer> buffer = SourceBuffer::create(sourceBufferPrivate.releaseNonNull(), this);
+    RefPtr<SourceBuffer> buffer = SourceBuffer::create(sourceBufferPrivate.release(), this);
     // 6. Add the new object to sourceBuffers and fire a addsourcebuffer on that object.
     m_sourceBuffers->add(buffer);
     regenerateActiveSourceBuffers();
@@ -722,11 +748,7 @@ bool MediaSource::isTypeSupported(const String& type)
     // 4. If type contains at a codec that the MediaSource does not support, then return false.
     // 5. If the MediaSource does not support the specified combination of media type, media subtype, and codecs then return false.
     // 6. Return true.
-    MediaEngineSupportParameters parameters;
-    parameters.type = contentType.type();
-    parameters.codecs = codecs;
-    parameters.isMediaSource = true;
-    return MediaPlayer::supportsType(parameters, 0) != MediaPlayer::IsNotSupported;
+    return MIMETypeRegistry::isSupportedMediaSourceMIMEType(contentType.type(), codecs);
 }
 
 bool MediaSource::isOpen() const
@@ -749,7 +771,7 @@ void MediaSource::close()
     setReadyState(closedKeyword());
 }
 
-void MediaSource::sourceBufferDidChangeAcitveState(SourceBuffer*, bool)
+void MediaSource::sourceBufferDidChangeActiveState(SourceBuffer*, bool)
 {
     regenerateActiveSourceBuffers();
 }
@@ -776,13 +798,13 @@ void MediaSource::openIfInEndedState()
 
 bool MediaSource::hasPendingActivity() const
 {
-    return m_private || m_asyncEventQueue.hasPendingEvents()
+    return m_private || m_asyncEventQueue->hasPendingEvents()
         || ActiveDOMObject::hasPendingActivity();
 }
 
 void MediaSource::stop()
 {
-    m_asyncEventQueue.close();
+    m_asyncEventQueue->close();
     if (!isClosed())
         setReadyState(closedKeyword());
     m_private.clear();
@@ -815,8 +837,10 @@ void MediaSource::onReadyStateChange(const AtomicString& oldState, const AtomicS
 Vector<PlatformTimeRanges> MediaSource::activeRanges() const
 {
     Vector<PlatformTimeRanges> activeRanges;
-    for (auto& sourceBuffer : *m_activeSourceBuffers)
+    for (SourceBufferList::const_iterator it = m_activeSourceBuffers->begin(); it != m_activeSourceBuffers->end(); ++it) {
+        RefPtr<SourceBuffer> sourceBuffer = *it;
         activeRanges.append(sourceBuffer->buffered()->ranges());
+    }
     return activeRanges;
 }
 
@@ -833,17 +857,17 @@ RefPtr<SourceBufferPrivate> MediaSource::createSourceBufferPrivate(const Content
         // specified for the other SourceBuffer objects in sourceBuffers, then throw
         // a NOT_SUPPORTED_ERR exception and abort these steps.
         ec = NOT_SUPPORTED_ERR;
-        return nullptr;
+        return 0;
     case MediaSourcePrivate::ReachedIdLimit:
         // 2.2 https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-MediaSource-addSourceBuffer-SourceBuffer-DOMString-type
         // Step 3: If the user agent can't handle any more SourceBuffer objects then throw
         // a QUOTA_EXCEEDED_ERR exception and abort these steps.
         ec = QUOTA_EXCEEDED_ERR;
-        return nullptr;
+        return 0;
     }
 
     ASSERT_NOT_REACHED();
-    return nullptr;
+    return 0;
 }
 
 void MediaSource::scheduleEvent(const AtomicString& eventName)
@@ -851,7 +875,7 @@ void MediaSource::scheduleEvent(const AtomicString& eventName)
     RefPtr<Event> event = Event::create(eventName, false, false);
     event->setTarget(this);
 
-    m_asyncEventQueue.enqueueEvent(event.release());
+    m_asyncEventQueue->enqueueEvent(event.release());
 }
 
 ScriptExecutionContext* MediaSource::scriptExecutionContext() const
@@ -859,9 +883,9 @@ ScriptExecutionContext* MediaSource::scriptExecutionContext() const
     return ActiveDOMObject::scriptExecutionContext();
 }
 
-EventTargetInterface MediaSource::eventTargetInterface() const
+const AtomicString& MediaSource::interfaceName() const
 {
-    return MediaSourceEventTargetInterfaceType;
+    return eventNames().interfaceForMediaSource;
 }
 
 URLRegistry& MediaSource::registry() const
@@ -871,8 +895,9 @@ URLRegistry& MediaSource::registry() const
 
 void MediaSource::regenerateActiveSourceBuffers()
 {
-    Vector<RefPtr<SourceBuffer>> newList;
-    for (auto& sourceBuffer : *m_sourceBuffers) {
+    Vector< RefPtr<SourceBuffer> > newList;
+    for (SourceBufferList::const_iterator it = m_sourceBuffers->begin(); it != m_sourceBuffers->end(); ++it) {
+        RefPtr<SourceBuffer> sourceBuffer = *it;
         if (sourceBuffer->active())
             newList.append(sourceBuffer);
     }
diff --git a/Source/WebCore/Modules/mediasource/MediaSource.h b/Source/WebCore/Modules/mediasource/MediaSource.h
index 6a0e18e..1e55e69 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.h
+++ b/Source/WebCore/Modules/mediasource/MediaSource.h
@@ -34,7 +34,6 @@
 #if ENABLE(MEDIA_SOURCE)
 
 #include "ActiveDOMObject.h"
-#include "EventTarget.h"
 #include "GenericEventQueue.h"
 #include "MediaSourcePrivate.h"
 #include "MediaSourcePrivateClient.h"
@@ -67,7 +66,7 @@ class MediaSource : public MediaSourcePrivateClient, public ActiveDOMObject, pub
     bool isOpen() const;
     bool isClosed() const;
     bool isEnded() const;
-    void sourceBufferDidChangeAcitveState(SourceBuffer*, bool);
+    void sourceBufferDidChangeActiveState(SourceBuffer*, bool);
     void streamEndedWithError(const AtomicString& error, ExceptionCode&);
 
     // MediaSourcePrivateClient
@@ -110,7 +109,7 @@ class MediaSource : public MediaSourcePrivateClient, public ActiveDOMObject, pub
     virtual void derefEventTarget() { deref(); }
 
     // URLRegistrable interface
-    virtual URLRegistry& registry() const;
+    virtual URLRegistry& registry() const OVERRIDE;
 
     using RefCounted<MediaSourcePrivateClient>::ref;
     using RefCounted<MediaSourcePrivateClient>::deref;
diff --git a/Source/WebCore/Modules/mediasource/MediaSource.idl b/Source/WebCore/Modules/mediasource/MediaSource.idl
index 56f284f..ae6f769 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.idl
+++ b/Source/WebCore/Modules/mediasource/MediaSource.idl
@@ -37,12 +37,10 @@ enum EndOfStreamError {
     Conditional=MEDIA_SOURCE,
     ActiveDOMObject,
     EventTarget,
-    EnabledBySetting=MediaSource,
-    JSGenerateToJSObject,
-    JSGenerateToNativeObject,
     Constructor,
     ConstructorCallWith=ScriptExecutionContext,
-] interface MediaSource : EventTarget {
+    InterfaceName=WebKitMediaSource
+] interface MediaSource {
     // All the source buffers created by this object.
     readonly attribute SourceBufferList sourceBuffers;
 
@@ -59,4 +57,14 @@ enum EndOfStreamError {
     [RaisesException] void endOfStream(optional EndOfStreamError error);
 
     static boolean isTypeSupported (DOMString type);
+
+    // EventTarget interface
+    void addEventListener(DOMString type,
+                          EventListener listener,
+                          optional boolean useCapture);
+    void removeEventListener(DOMString type,
+                             EventListener listener,
+                             optional boolean useCapture);
+    [RaisesException] boolean dispatchEvent(Event event);
 };
+

From 728f27553c6b372fbc16949d5fc30ec5de9746ec Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 13 Nov 2014 17:53:20 +0100
Subject: [PATCH 18/68] Fix prototype.

---
 Source/WebCore/Modules/mediasource/SourceBuffer.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.h b/Source/WebCore/Modules/mediasource/SourceBuffer.h
index feb7c87..8b96492 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.h
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.h
@@ -62,7 +62,7 @@ class VideoTrackList;
 
 class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, public EventTarget, public ScriptWrappable, public SourceBufferPrivateClient, public AudioTrackClient, public VideoTrackClient, public TextTrackClient {
 public:
-    static PassRefPtr<SourceBuffer> create(PassOwnPtr<SourceBufferPrivate>, PassRefPtr<MediaSource>);
+    static PassRefPtr<SourceBuffer> create(PassRefPtr<SourceBufferPrivate>, PassRefPtr<MediaSource>);
 
     virtual ~SourceBuffer();
 

From 75063768ade4b20c404a0c0709433e1d6d389af0 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Thu, 13 Nov 2014 18:40:05 +0100
Subject: [PATCH 19/68] Port more operators to MediaTime class

---
 Source/WTF/wtf/MediaTime.cpp | 73 +++++++++++++++++++++++++++++++++++++++++---
 Source/WTF/wtf/MediaTime.h   |  6 ++++
 2 files changed, 74 insertions(+), 5 deletions(-)

diff --git a/Source/WTF/wtf/MediaTime.cpp b/Source/WTF/wtf/MediaTime.cpp
index 4b2eee8..f8fb393 100644
--- a/Source/WTF/wtf/MediaTime.cpp
+++ b/Source/WTF/wtf/MediaTime.cpp
@@ -54,6 +54,11 @@ static int32_t leastCommonMultiple(int32_t a, int32_t b, int32_t &result)
     return safeMultiply(a, b / greatestCommonDivisor(a, b), result);
 }
 
+static int32_t signum(int64_t val)
+{
+    return (0 < val) - (val < 0);
+}
+
 const int32_t MediaTime::MaximumTimeScale = 0x7fffffffL;
 
 MediaTime::MediaTime()
@@ -215,6 +220,59 @@ MediaTime MediaTime::operator-(const MediaTime& rhs) const
     return a;
 }
 
+MediaTime MediaTime::operator-() const
+{
+    if (isInvalid())
+        return invalidTime();
+
+    if (isIndefinite())
+        return indefiniteTime();
+
+    if (isPositiveInfinite())
+        return negativeInfiniteTime();
+
+    if (isNegativeInfinite())
+        return positiveInfiniteTime();
+
+    MediaTime negativeTime = *this;
+    negativeTime.m_timeValue = -negativeTime.m_timeValue;
+    return negativeTime;
+}
+
+MediaTime MediaTime::operator*(int32_t rhs) const
+{
+    if (isInvalid())
+        return invalidTime();
+
+    if (isIndefinite())
+        return indefiniteTime();
+
+    if (!rhs)
+        return zeroTime();
+
+    if (isPositiveInfinite()) {
+        if (rhs > 0)
+            return positiveInfiniteTime();
+        return negativeInfiniteTime();
+    }
+
+    if (isNegativeInfinite()) {
+        if (rhs > 0)
+            return negativeInfiniteTime();
+        return positiveInfiniteTime();
+    }
+
+    MediaTime a = *this;
+
+    while (!safeMultiply(a.m_timeValue, rhs, a.m_timeValue)) {
+        if (a.m_timeScale == 1)
+            return signum(a.m_timeValue) == signum(rhs) ? positiveInfiniteTime() : negativeInfiniteTime();
+        a.setTimeScale(a.m_timeScale / 2);
+    }
+
+    return a;
+}
+
 bool MediaTime::operator<(const MediaTime& rhs) const
 {
     return compare(rhs) == LessThan;
@@ -240,6 +298,16 @@ bool MediaTime::operator<=(const MediaTime& rhs) const
     return compare(rhs) <= EqualTo;
 }
 
+bool MediaTime::operator!() const
+{
+    return compare(zeroTime()) == EqualTo;
+}
+
+MediaTime::operator bool() const
+{
+    return compare(zeroTime()) != EqualTo;
+}
+
 MediaTime::ComparisonFlags MediaTime::compare(const MediaTime& rhs) const
 {
     if ((isPositiveInfinite() && rhs.isPositiveInfinite())
@@ -332,11 +400,6 @@ void MediaTime::setTimeScale(int32_t timeScale)
     m_timeScale = timeScale;
 }
 
-static int32_t signum(int64_t val)
-{
-    return (0 < val) - (val < 0);
-}
-
 MediaTime abs(const MediaTime& rhs)
 {
     if (rhs.isInvalid())
diff --git a/Source/WTF/wtf/MediaTime.h b/Source/WTF/wtf/MediaTime.h
index b452c8b..eb79415 100644
--- a/Source/WTF/wtf/MediaTime.h
+++ b/Source/WTF/wtf/MediaTime.h
@@ -60,13 +60,19 @@ class WTF_EXPORT_PRIVATE MediaTime {
     double toDouble() const;
 
     MediaTime& operator=(const MediaTime& rhs);
+    MediaTime& operator+=(const MediaTime& rhs) { return *this = *this + rhs; }
+    MediaTime& operator-=(const MediaTime& rhs) { return *this = *this - rhs; }
     MediaTime operator+(const MediaTime& rhs) const;
     MediaTime operator-(const MediaTime& rhs) const;
+    MediaTime operator-() const;
+    MediaTime operator*(int32_t) const;
     bool operator<(const MediaTime& rhs) const;
     bool operator>(const MediaTime& rhs) const;
     bool operator==(const MediaTime& rhs) const;
     bool operator>=(const MediaTime& rhs) const;
     bool operator<=(const MediaTime& rhs) const;
+    bool operator!() const;
+    explicit operator bool() const;
 
     typedef enum {
         LessThan = -1,

From 96236df58775c02c17d53cb75f8804f8e3a49dc6 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Thu, 13 Nov 2014 18:40:20 +0100
Subject: [PATCH 20/68] Use the correct type

---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index b6ca75b..e6ffcca 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -622,8 +622,8 @@ void SourceBuffer::removeCodedFrames(const MediaTime& start, const MediaTime& en
 
     // 2. Let end be the end presentation timestamp for the removal range.
     // 3. For each track buffer in this source buffer, run the following steps:
-    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
-    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+    HashMap<AtomicString, TrackBuffer>::iterator bmend = m_trackBufferMap.end();
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != bmend; ++it) {
         TrackBuffer& trackBuffer = it->value;
 
         // 3.1. Let remove end timestamp be the current value of duration

From 9396657009c051bedb91932b22572c91ebc86ab4 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 14 Nov 2014 11:24:51 +0100
Subject: [PATCH 21/68] Backport new functions from upstream.

---
 .../graphics/gstreamer/GStreamerUtilities.cpp      | 98 +++++++++++++++++++++-
 .../graphics/gstreamer/GStreamerUtilities.h        | 42 ++++++++++
 2 files changed, 138 insertions(+), 2 deletions(-)

diff --git a/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.cpp b/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.cpp
index 3e66952..cee1c81 100644
--- a/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.cpp
@@ -18,14 +18,108 @@
 
 
 #include "config.h"
-#include "GStreamerUtilities.h"
 
 #if USE(GSTREAMER)
-#include <gst/gst.h>
+#include "GStreamerUtilities.h"
+
+#include "IntSize.h"
+
+#include <gst/audio/audio.h>
+#include <wtf/MathExtras.h>
 #include <wtf/gobject/GOwnPtr.h>
 
 namespace WebCore {
 
+const char* webkitGstMapInfoQuarkString = "webkit-gst-map-info";
+
+GstPad* webkitGstGhostPadFromStaticTemplate(GstStaticPadTemplate* staticPadTemplate, const gchar* name, GstPad* target)
+{
+    GstPad* pad;
+    GstPadTemplate* padTemplate = gst_static_pad_template_get(staticPadTemplate);
+
+    if (target)
+        pad = gst_ghost_pad_new_from_template(name, target, padTemplate);
+    else
+        pad = gst_ghost_pad_new_no_target_from_template(name, padTemplate);
+
+    gst_object_unref(padTemplate);
+
+    return pad;
+}
+
+#if ENABLE(VIDEO)
+bool getVideoSizeAndFormatFromCaps(GstCaps* caps, WebCore::IntSize& size, GstVideoFormat& format, int& pixelAspectRatioNumerator, int& pixelAspectRatioDenominator, int& stride)
+{
+    GstVideoInfo info;
+
+    gst_video_info_init(&info);
+    if (!gst_video_info_from_caps(&info, caps))
+        return false;
+
+    format = GST_VIDEO_INFO_FORMAT(&info);
+    size.setWidth(GST_VIDEO_INFO_WIDTH(&info));
+    size.setHeight(GST_VIDEO_INFO_HEIGHT(&info));
+    pixelAspectRatioNumerator = GST_VIDEO_INFO_PAR_N(&info);
+    pixelAspectRatioDenominator = GST_VIDEO_INFO_PAR_D(&info);
+    stride = GST_VIDEO_INFO_PLANE_STRIDE(&info, 0);
+
+    return true;
+}
+#endif
+
+GstBuffer* createGstBuffer(GstBuffer* buffer)
+{
+    gsize bufferSize = gst_buffer_get_size(buffer);
+    GstBuffer* newBuffer = gst_buffer_new_and_alloc(bufferSize);
+
+    if (!newBuffer)
+        return 0;
+
+    gst_buffer_copy_into(newBuffer, buffer, static_cast<GstBufferCopyFlags>(GST_BUFFER_COPY_METADATA), 0, bufferSize);
+    return newBuffer;
+}
+
+GstBuffer* createGstBufferForData(const char* data, int length)
+{
+    GstBuffer* buffer = gst_buffer_new_and_alloc(length);
+
+    gst_buffer_fill(buffer, 0, data, length);
+
+    return buffer;
+}
+
+char* getGstBufferDataPointer(GstBuffer* buffer)
+{
+    GstMiniObject* miniObject = reinterpret_cast<GstMiniObject*>(buffer);
+    GstMapInfo* mapInfo = static_cast<GstMapInfo*>(gst_mini_object_get_qdata(miniObject, g_quark_from_static_string(webkitGstMapInfoQuarkString)));
+    return reinterpret_cast<char*>(mapInfo->data);
+}
+
+void mapGstBuffer(GstBuffer* buffer)
+{
+    GstMapInfo* mapInfo = g_slice_new(GstMapInfo);
+    if (!gst_buffer_map(buffer, mapInfo, GST_MAP_WRITE)) {
+        g_slice_free(GstMapInfo, mapInfo);
+        gst_buffer_unref(buffer);
+        return;
+    }
+
+    GstMiniObject* miniObject = reinterpret_cast<GstMiniObject*>(buffer);
+    gst_mini_object_set_qdata(miniObject, g_quark_from_static_string(webkitGstMapInfoQuarkString), mapInfo, 0);
+}
+
+void unmapGstBuffer(GstBuffer* buffer)
+{
+    GstMiniObject* miniObject = reinterpret_cast<GstMiniObject*>(buffer);
+    GstMapInfo* mapInfo = static_cast<GstMapInfo*>(gst_mini_object_steal_qdata(miniObject, g_quark_from_static_string(webkitGstMapInfoQuarkString)));
+
+    if (!mapInfo)
+        return;
+
+    gst_buffer_unmap(buffer, mapInfo);
+    g_slice_free(GstMapInfo, mapInfo);
+}
+
 bool initializeGStreamer()
 {
 #if GST_CHECK_VERSION(0, 10, 31)
diff --git a/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.h b/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.h
index 68df7b9..907d132 100644
--- a/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.h
+++ b/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.h
@@ -16,6 +16,11 @@
  *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
  */
 
+#include "Logging.h"
+
+#include <gst/gst.h>
+#include <gst/video/video.h>
+
 #define LOG_MEDIA_MESSAGE(...) do { \
     GST_DEBUG(__VA_ARGS__); \
     LOG_VERBOSE(Media, __VA_ARGS__); } while (0)
@@ -28,7 +33,44 @@
     GST_INFO(__VA_ARGS__); \
     LOG_VERBOSE(Media, __VA_ARGS__); } while (0)
 
+#define WARN_MEDIA_MESSAGE(...) do { \
+    GST_WARNING(__VA_ARGS__); \
+    LOG_VERBOSE(Media, __VA_ARGS__); } while (0)
+
 namespace WebCore {
+
+class IntSize;
+
+inline bool webkitGstCheckVersion(guint major, guint minor, guint micro)
+{
+    guint currentMajor, currentMinor, currentMicro, currentNano;
+    gst_version(&currentMajor, &currentMinor, &currentMicro, &currentNano);
+
+    if (currentMajor < major)
+        return false;
+    if (currentMajor > major)
+        return true;
+
+    if (currentMinor < minor)
+        return false;
+    if (currentMinor > minor)
+        return true;
+
+    if (currentMicro < micro)
+        return false;
+
+    return true;
+}
+
+GstPad* webkitGstGhostPadFromStaticTemplate(GstStaticPadTemplate*, const gchar* name, GstPad* target);
+#if ENABLE(VIDEO)
+bool getVideoSizeAndFormatFromCaps(GstCaps*, WebCore::IntSize&, GstVideoFormat&, int& pixelAspectRatioNumerator, int& pixelAspectRatioDenominator, int& stride);
+#endif
+GstBuffer* createGstBuffer(GstBuffer*);
+GstBuffer* createGstBufferForData(const char* data, int length);
+char* getGstBufferDataPointer(GstBuffer*);
+void mapGstBuffer(GstBuffer*);
+void unmapGstBuffer(GstBuffer*);
 bool initializeGStreamer();
 unsigned getGstPlaysFlag(const char* nick);
 }

From 7ce55c1f8beebfe87be6f95412d3f8bd7d8ccef3 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 14 Nov 2014 11:26:32 +0100
Subject: [PATCH 22/68] Add some new files from upstream. Provides a new
 GStreamer source element for MediaSource scenario and implement a
 MediaSourcePrivate and SourceBufferPrivate class.

---
 .../graphics/gstreamer/MediaSourceGStreamer.cpp    |  83 +++
 .../graphics/gstreamer/MediaSourceGStreamer.h      |  66 ++
 .../gstreamer/SourceBufferPrivateGStreamer.cpp     |  68 ++
 .../gstreamer/SourceBufferPrivateGStreamer.h       |  65 ++
 .../gstreamer/WebKitMediaSourceGStreamer.cpp       | 780 +++++++++++++++++++++
 .../gstreamer/WebKitMediaSourceGStreamer.h         |  72 ++
 6 files changed, 1134 insertions(+)
 create mode 100644 Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.cpp
 create mode 100644 Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.h
 create mode 100644 Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.cpp
 create mode 100644 Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.h
 create mode 100644 Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
 create mode 100644 Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.h

diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.cpp
new file mode 100644
index 0000000..51a0716
--- /dev/null
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.cpp
@@ -0,0 +1,83 @@
+/*
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Orange
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "config.h"
+#include "MediaSourceGStreamer.h"
+
+#if ENABLE(MEDIA_SOURCE) && USE(GSTREAMER)
+
+#include "SourceBufferPrivateGStreamer.h"
+#include "WebKitMediaSourceGStreamer.h"
+#include <wtf/gobject/GRefPtr.h>
+
+namespace WebCore {
+
+void MediaSourceGStreamer::open(MediaSourcePrivateClient* mediaSource, WebKitMediaSrc* src)
+{
+    ASSERT(mediaSource);
+    RefPtr<MediaSourcePrivate> mediaSourcePrivate = adoptRef (new MediaSourceGStreamer(mediaSource, src));
+    mediaSource->setPrivateAndOpen(*mediaSourcePrivate);
+}
+
+MediaSourceGStreamer::MediaSourceGStreamer(MediaSourcePrivateClient* mediaSource, WebKitMediaSrc* src)
+    : m_client(adoptRef(new MediaSourceClientGstreamer(src)))
+    , m_mediaSource(mediaSource)
+    , m_readyState(MediaPlayer::HaveNothing)
+{
+    ASSERT(m_client);
+}
+
+MediaSourceGStreamer::~MediaSourceGStreamer()
+{
+}
+
+MediaSourceGStreamer::AddStatus MediaSourceGStreamer::addSourceBuffer(const ContentType& contentType, RefPtr<SourceBufferPrivate>& sourceBufferPrivate)
+{
+    sourceBufferPrivate = adoptRef(new SourceBufferPrivateGStreamer(m_client.get(), contentType));
+    return MediaSourceGStreamer::Ok;
+}
+
+void MediaSourceGStreamer::durationChanged()
+{
+    m_client->didReceiveDuration(m_mediaSource->duration().toDouble());
+}
+
+void MediaSourceGStreamer::markEndOfStream(EndOfStreamStatus)
+{
+    m_client->didFinishLoading(0);
+}
+
+void MediaSourceGStreamer::unmarkEndOfStream()
+{
+}
+
+}
+#endif
diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.h b/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.h
new file mode 100644
index 0000000..5681bb6
--- /dev/null
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.h
@@ -0,0 +1,66 @@
+/*
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Orange
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef MediaSourceGStreamer_h
+#define MediaSourceGStreamer_h
+
+#if ENABLE(MEDIA_SOURCE) && USE(GSTREAMER)
+#include "MediaSource.h"
+#include "WebKitMediaSourceGStreamer.h"
+
+namespace WebCore {
+
+class MediaSourceGStreamer : public MediaSourcePrivate {
+public:
+    static void open(MediaSourcePrivateClient*, WebKitMediaSrc*);
+    ~MediaSourceGStreamer();
+
+private:
+    // MediaSourcePrivate
+    virtual AddStatus addSourceBuffer(const ContentType&, RefPtr<SourceBufferPrivate>&) OVERRIDE;
+    virtual void durationChanged() OVERRIDE;
+    virtual void markEndOfStream(EndOfStreamStatus) OVERRIDE;
+    virtual void unmarkEndOfStream() OVERRIDE;
+    virtual MediaPlayer::ReadyState readyState() const OVERRIDE { return m_readyState; }
+    virtual void setReadyState(MediaPlayer::ReadyState readyState) OVERRIDE { m_readyState = readyState; }
+    virtual void waitForSeekCompleted() OVERRIDE { }
+    virtual void seekCompleted() OVERRIDE { }
+
+    RefPtr<MediaSourceClientGstreamer> m_client;
+    MediaSourcePrivateClient* m_mediaSource;
+    MediaSourceGStreamer(MediaSourcePrivateClient*, WebKitMediaSrc*);
+    MediaPlayer::ReadyState m_readyState;
+};
+
+}
+
+#endif
+#endif
diff --git a/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.cpp
new file mode 100644
index 0000000..45c5e91
--- /dev/null
+++ b/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.cpp
@@ -0,0 +1,68 @@
+/*
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Orange
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "config.h"
+#include "SourceBufferPrivateGStreamer.h"
+
+#if ENABLE(MEDIA_SOURCE) && USE(GSTREAMER)
+
+#include "ContentType.h"
+#include "NotImplemented.h"
+
+namespace WebCore {
+
+SourceBufferPrivateGStreamer::SourceBufferPrivateGStreamer(PassRefPtr<MediaSourceClientGstreamer> client, const ContentType& contentType)
+    : m_readyState(MediaPlayer::HaveNothing)
+{
+    m_client = client;
+    m_type = contentType.type();
+}
+
+void SourceBufferPrivateGStreamer::append(const unsigned char* data, unsigned length)
+{
+    ASSERT(m_client);
+    m_client->didReceiveData(reinterpret_cast_ptr<const char*>(data), length, m_type);
+
+    // FIXME: call SourceBufferPrivateClient::sourceBufferPrivateAppendComplete().
+}
+
+void SourceBufferPrivateGStreamer::abort()
+{
+    notImplemented();
+}
+
+void SourceBufferPrivateGStreamer::removedFromMediaSource()
+{
+    notImplemented();
+}
+
+}
+#endif
diff --git a/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.h b/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.h
new file mode 100644
index 0000000..613fe45
--- /dev/null
+++ b/Source/WebCore/platform/graphics/gstreamer/SourceBufferPrivateGStreamer.h
@@ -0,0 +1,65 @@
+/*
+ * Copyright (C) 2013 Google Inc. All rights reserved.
+ * Copyright (C) 2013 Orange
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *
+ *     * Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ * copyright notice, this list of conditions and the following disclaimer
+ * in the documentation and/or other materials provided with the
+ * distribution.
+ *     * Neither the name of Google Inc. nor the names of its
+ * contributors may be used to endorse or promote products derived from
+ * this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef SourceBufferPrivateGStreamer_h
+#define SourceBufferPrivateGStreamer_h
+
+#if ENABLE(MEDIA_SOURCE) && USE(GSTREAMER)
+
+#include "SourceBufferPrivate.h"
+#include "WebKitMediaSourceGStreamer.h"
+
+namespace WebCore {
+
+class SourceBufferPrivateGStreamer : public SourceBufferPrivate {
+public:
+    SourceBufferPrivateGStreamer(PassRefPtr<MediaSourceClientGstreamer>, const ContentType&);
+    ~SourceBufferPrivateGStreamer() { }
+
+    void setClient(SourceBufferPrivateClient*) { }
+    void append(const unsigned char*, unsigned);
+    void abort();
+    void removedFromMediaSource();
+    MediaPlayer::ReadyState readyState() const { return m_readyState; }
+    void setReadyState(MediaPlayer::ReadyState readyState) { m_readyState = readyState; }
+    void evictCodedFrames() { }
+    bool isFull() { return false; }
+
+private:
+    String m_type;
+    RefPtr<MediaSourceClientGstreamer> m_client;
+    MediaPlayer::ReadyState m_readyState;
+};
+
+}
+
+#endif
+#endif
diff --git a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
new file mode 100644
index 0000000..ddd2940
--- /dev/null
+++ b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
@@ -0,0 +1,780 @@
+/*
+ *  Copyright (C) 2009, 2010 Sebastian Dröge <sebastian.droege@collabora.co.uk>
+ *  Copyright (C) 2013 Collabora Ltd.
+ *  Copyright (C) 2013 Orange
+ *
+ *  This library is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU Lesser General Public
+ *  License as published by the Free Software Foundation; either
+ *  version 2 of the License, or (at your option) any later version.
+ *
+ *  This library is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  Lesser General Public License for more details.
+ *
+ *  You should have received a copy of the GNU Lesser General Public
+ *  License along with this library; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
+ */
+
+#include "config.h"
+#include "WebKitMediaSourceGStreamer.h"
+
+#if ENABLE(VIDEO) && ENABLE(MEDIA_SOURCE) && USE(GSTREAMER)
+
+#include "GRefPtrGStreamer.h"
+#include "GStreamerUtilities.h"
+#include "NotImplemented.h"
+#include "TimeRanges.h"
+#include <gst/app/gstappsrc.h>
+#include <gst/gst.h>
+#include <gst/pbutils/missing-plugins.h>
+#include <wtf/gobject/GOwnPtr.h>
+#include <wtf/text/CString.h>
+
+typedef struct _Source {
+    GstElement* appsrc;
+    guint sourceid;        /* To control the GSource */
+    GstPad* srcpad;
+    gboolean padAdded;
+
+    guint64 offset;
+    guint64 size;
+    gboolean paused;
+
+    guint64 requestedOffset;
+} Source;
+
+
+#define WEBKIT_MEDIA_SRC_GET_PRIVATE(obj) (G_TYPE_INSTANCE_GET_PRIVATE((obj), WEBKIT_TYPE_MEDIA_SRC, WebKitMediaSrcPrivate))
+
+struct _WebKitMediaSrcPrivate {
+    gchar* uri;
+    Source sourceVideo;
+    Source sourceAudio;
+    WebCore::MediaPlayer* player;
+    GstElement* playbin;
+    gint64 duration;
+    gboolean seekable;
+    gboolean noMorePad;
+    // TRUE if appsrc's version is >= 0.10.27, see
+    // https://bugzilla.gnome.org/show_bug.cgi?id=609423
+    gboolean haveAppSrc27;
+    guint nbSource;
+};
+
+enum {
+    PropLocation = 1,
+    ProLast
+};
+
+static GstStaticPadTemplate srcTemplate = GST_STATIC_PAD_TEMPLATE("src_%u", GST_PAD_SRC, GST_PAD_SOMETIMES, GST_STATIC_CAPS_ANY);
+
+GST_DEBUG_CATEGORY_STATIC(webkit_media_src_debug);
+#define GST_CAT_DEFAULT webkit_media_src_debug
+
+static void webKitMediaSrcUriHandlerInit(gpointer gIface, gpointer ifaceData);
+static void webKitMediaSrcFinalize(GObject*);
+static void webKitMediaSrcSetProperty(GObject*, guint propertyId, const GValue*, GParamSpec*);
+static void webKitMediaSrcGetProperty(GObject*, guint propertyId, GValue*, GParamSpec*);
+static GstStateChangeReturn webKitMediaSrcChangeState(GstElement*, GstStateChange);
+static gboolean webKitMediaSrcQueryWithParent(GstPad*, GstObject*, GstQuery*);
+
+static void webKitMediaVideoSrcNeedDataCb(GstAppSrc*, guint, gpointer);
+static void webKitMediaVideoSrcEnoughDataCb(GstAppSrc*, gpointer);
+static gboolean webKitMediaVideoSrcSeekDataCb(GstAppSrc*, guint64, gpointer);
+static void webKitMediaAudioSrcNeedDataCb(GstAppSrc*, guint, gpointer);
+static void webKitMediaAudioSrcEnoughDataCb(GstAppSrc*, gpointer);
+static gboolean webKitMediaAudioSrcSeekDataCb(GstAppSrc*, guint64, gpointer);
+static GstAppSrcCallbacks appsrcCallbacksVideo = {
+    webKitMediaVideoSrcNeedDataCb,
+    webKitMediaVideoSrcEnoughDataCb,
+    webKitMediaVideoSrcSeekDataCb,
+    { 0 }
+};
+static GstAppSrcCallbacks appsrcCallbacksAudio = {
+    webKitMediaAudioSrcNeedDataCb,
+    webKitMediaAudioSrcEnoughDataCb,
+    webKitMediaAudioSrcSeekDataCb,
+    { 0 }
+};
+#define webkit_media_src_parent_class parent_class
+// We split this out into another macro to avoid a check-webkit-style error.
+#define WEBKIT_MEDIA_SRC_CATEGORY_INIT GST_DEBUG_CATEGORY_INIT(webkit_media_src_debug, "webkitmediasrc", 0, "websrc element");
+G_DEFINE_TYPE_WITH_CODE(WebKitMediaSrc, webkit_media_src, GST_TYPE_BIN,
+    G_IMPLEMENT_INTERFACE(GST_TYPE_URI_HANDLER, webKitMediaSrcUriHandlerInit);
+    WEBKIT_MEDIA_SRC_CATEGORY_INIT);
+
+static void webkit_media_src_class_init(WebKitMediaSrcClass* klass)
+{
+    GObjectClass* oklass = G_OBJECT_CLASS(klass);
+    GstElementClass* eklass = GST_ELEMENT_CLASS(klass);
+
+    oklass->finalize = webKitMediaSrcFinalize;
+    oklass->set_property = webKitMediaSrcSetProperty;
+    oklass->get_property = webKitMediaSrcGetProperty;
+
+    gst_element_class_add_pad_template(eklass, gst_static_pad_template_get(&srcTemplate));
+
+    gst_element_class_set_metadata(eklass, "WebKit Media source element", "Source", "Handles Blob uris", "Stephane Jadaud <sjadaud@sii.fr>");
+
+    /* Allows setting the uri using the 'location' property, which is used
+     * for example by gst_element_make_from_uri() */
+    g_object_class_install_property(oklass,
+        PropLocation,
+        g_param_spec_string("location", "location", "Location to read from", 0,
+        (GParamFlags) (G_PARAM_READWRITE | G_PARAM_STATIC_STRINGS)));
+
+    eklass->change_state = webKitMediaSrcChangeState;
+
+    g_type_class_add_private(klass, sizeof(WebKitMediaSrcPrivate));
+}
+
+static void webKitMediaSrcAddSrc(WebKitMediaSrc* src, GstElement* element)
+{
+    GstPad* ghostPad;
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    if (!gst_bin_add(GST_BIN(src), element)) {
+        GST_DEBUG_OBJECT(src, "Src element not added");
+        return;
+    }
+    GRefPtr<GstPad> targetsrc = adoptGRef(gst_element_get_static_pad(element, "src"));
+    if (!targetsrc) {
+        GST_DEBUG_OBJECT(src, "Pad not found");
+        return;
+    }
+
+    gst_element_sync_state_with_parent(element);
+    GOwnPtr<gchar> name;
+    name.set(g_strdup_printf("src_%u", priv->nbSource));
+    ghostPad = WebCore::webkitGstGhostPadFromStaticTemplate(&srcTemplate, name.get(), targetsrc.get());
+    gst_pad_set_active(ghostPad, TRUE);
+
+    priv->nbSource++;
+
+    if (priv->sourceVideo.appsrc == element)
+        priv->sourceVideo.srcpad = ghostPad;
+    else if (priv->sourceAudio.appsrc == element)
+        priv->sourceAudio.srcpad = ghostPad;
+
+    GST_OBJECT_FLAG_SET(ghostPad, GST_PAD_FLAG_NEED_PARENT);
+    gst_pad_set_query_function(ghostPad, webKitMediaSrcQueryWithParent);
+}
+
+static void webkit_media_src_init(WebKitMediaSrc* src)
+{
+    WebKitMediaSrcPrivate* priv = WEBKIT_MEDIA_SRC_GET_PRIVATE(src);
+    src->priv = priv;
+    new (priv) WebKitMediaSrcPrivate();
+
+    priv->sourceVideo.appsrc = gst_element_factory_make("appsrc", "videoappsrc");
+    gst_app_src_set_callbacks(GST_APP_SRC(priv->sourceVideo.appsrc), &appsrcCallbacksVideo, src, 0);
+    webKitMediaSrcAddSrc(src, priv->sourceVideo.appsrc);
+
+    priv->sourceAudio.appsrc = gst_element_factory_make("appsrc", "audioappsrc");
+    gst_app_src_set_callbacks(GST_APP_SRC(priv->sourceAudio.appsrc), &appsrcCallbacksAudio, src, 0);
+    webKitMediaSrcAddSrc(src, priv->sourceAudio.appsrc);
+}
+
+static void webKitMediaSrcFinalize(GObject* object)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(object);
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    g_free(priv->uri);
+    priv->~WebKitMediaSrcPrivate();
+
+    GST_CALL_PARENT(G_OBJECT_CLASS, finalize, (object));
+}
+
+static void webKitMediaSrcSetProperty(GObject* object, guint propId, const GValue* value, GParamSpec* pspec)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(object);
+    switch (propId) {
+    case PropLocation:
+        gst_uri_handler_set_uri(reinterpret_cast<GstURIHandler*>(src), g_value_get_string(value), 0);
+        break;
+    default:
+        G_OBJECT_WARN_INVALID_PROPERTY_ID(object, propId, pspec);
+        break;
+    }
+}
+
+static void webKitMediaSrcGetProperty(GObject* object, guint propId, GValue* value, GParamSpec* pspec)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(object);
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_OBJECT_LOCK(src);
+    switch (propId) {
+    case PropLocation:
+        g_value_set_string(value, priv->uri);
+        break;
+    default:
+        G_OBJECT_WARN_INVALID_PROPERTY_ID(object, propId, pspec);
+        break;
+    }
+    GST_OBJECT_UNLOCK(src);
+}
+
+// must be called on main thread and with object unlocked
+static void webKitMediaVideoSrcStop(WebKitMediaSrc* src)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+    gboolean seeking;
+
+    GST_OBJECT_LOCK(src);
+
+    //seeking = priv->sourceVideo.seek.isActive();
+
+    //priv->sourceVideo.start.cancel();
+
+    priv->player = 0;
+    priv->playbin = 0;
+
+    //priv->sourceVideo.needData.cancel();
+    //priv->sourceVideo.enoughData.cancel();
+    //priv->sourceVideo.seek.cancel();
+
+    priv->sourceVideo.paused = FALSE;
+    priv->sourceVideo.offset = 0;
+    priv->seekable = FALSE;
+
+    priv->duration = 0;
+    priv->nbSource = 0;
+
+    GST_OBJECT_UNLOCK(src);
+
+    if (priv->sourceVideo.appsrc) {
+        gst_app_src_set_caps(GST_APP_SRC(priv->sourceVideo.appsrc), 0);
+        if (!seeking)
+            gst_app_src_set_size(GST_APP_SRC(priv->sourceVideo.appsrc), -1);
+    }
+
+    GST_DEBUG_OBJECT(src, "Stopped request");
+}
+
+static void webKitMediaAudioSrcStop(WebKitMediaSrc* src)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+    gboolean seeking;
+
+    GST_OBJECT_LOCK(src);
+
+    //seeking = priv->sourceAudio.seek.isActive();
+
+    //priv->sourceAudio.start.cancel();
+
+    priv->player = 0;
+
+    priv->playbin = 0;
+
+    //priv->sourceAudio.needData.cancel();
+    //priv->sourceAudio.enoughData.cancel();
+    //priv->sourceAudio.seek.cancel();
+
+    priv->sourceAudio.paused = FALSE;
+
+    priv->sourceAudio.offset = 0;
+
+    priv->seekable = FALSE;
+
+    priv->duration = 0;
+    priv->nbSource = 0;
+
+    GST_OBJECT_UNLOCK(src);
+
+    if (priv->sourceAudio.appsrc) {
+        gst_app_src_set_caps(GST_APP_SRC(priv->sourceAudio.appsrc), 0);
+        if (!seeking)
+            gst_app_src_set_size(GST_APP_SRC(priv->sourceAudio.appsrc), -1);
+    }
+
+    GST_DEBUG_OBJECT(src, "Stopped request");
+}
+
+// must be called on main thread and with object unlocked
+static void webKitMediaVideoSrcStart(WebKitMediaSrc* src)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_OBJECT_LOCK(src);
+    if (!priv->uri) {
+        GST_ERROR_OBJECT(src, "No URI provided");
+        GST_OBJECT_UNLOCK(src);
+        webKitMediaVideoSrcStop(src);
+        return;
+    }
+
+    GST_OBJECT_UNLOCK(src);
+    GST_DEBUG_OBJECT(src, "Started request");
+}
+
+// must be called on main thread and with object unlocked
+static void webKitMediaAudioSrcStart(WebKitMediaSrc* src)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_OBJECT_LOCK(src);
+    if (!priv->uri) {
+        GST_ERROR_OBJECT(src, "No URI provided");
+        GST_OBJECT_UNLOCK(src);
+        webKitMediaAudioSrcStop(src);
+        return;
+    }
+
+    GST_OBJECT_UNLOCK(src);
+    GST_DEBUG_OBJECT(src, "Started request");
+}
+
+static GstStateChangeReturn webKitMediaSrcChangeState(GstElement* element, GstStateChange transition)
+{
+    GstStateChangeReturn ret = GST_STATE_CHANGE_SUCCESS;
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(element);
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    switch (transition) {
+    case GST_STATE_CHANGE_NULL_TO_READY:
+        if (!priv->sourceVideo.appsrc && !priv->sourceAudio.appsrc) {
+            gst_element_post_message(element,
+                gst_missing_element_message_new(element, "appsrc"));
+            GST_ELEMENT_ERROR(src, CORE, MISSING_PLUGIN, (0), ("no appsrc"));
+            return GST_STATE_CHANGE_FAILURE;
+        }
+        break;
+    default:
+        break;
+    }
+
+    ret = GST_ELEMENT_CLASS(parent_class)->change_state(element, transition);
+    if (G_UNLIKELY(ret == GST_STATE_CHANGE_FAILURE)) {
+        GST_DEBUG_OBJECT(src, "State change failed");
+        return ret;
+    }
+
+    switch (transition) {
+    case GST_STATE_CHANGE_READY_TO_PAUSED:
+        GST_DEBUG_OBJECT(src, "READY->PAUSED");
+        GST_OBJECT_LOCK(src);
+
+        /*gst_object_ref(src);
+        priv->sourceVideo.start.schedule("[WebKit] webKitMediaVideoSrcStart", std::function<void()>(std::bind(webKitMediaVideoSrcStart, src)), G_PRIORITY_DEFAULT,
+            [src] { gst_object_unref(src); });
+
+        gst_object_ref(src);
+        priv->sourceAudio.start.schedule("[WebKit] webKitMediaAudioSrcStart", std::function<void()>(std::bind(webKitMediaAudioSrcStart, src)), G_PRIORITY_DEFAULT,
+            [src] { gst_object_unref(src); });
+
+        GST_OBJECT_UNLOCK(src);*/
+        break;
+    case GST_STATE_CHANGE_PAUSED_TO_READY:
+        GST_DEBUG_OBJECT(src, "PAUSED->READY");
+        GST_OBJECT_LOCK(src);
+
+        /*gst_object_ref(src);
+        priv->sourceVideo.stop.schedule("[WebKit] webKitMediaVideoSrcStop", std::function<void()>(std::bind(webKitMediaVideoSrcStop, src)), G_PRIORITY_DEFAULT,
+            [src] { gst_object_unref(src); });
+
+        gst_object_ref(src);
+        priv->sourceAudio.stop.schedule("[WebKit] webKitMediaAudioSrcStop", std::function<void()>(std::bind(webKitMediaAudioSrcStop, src)), G_PRIORITY_DEFAULT,
+            [src] { gst_object_unref(src); });*/
+
+        GST_OBJECT_UNLOCK(src);
+        break;
+    default:
+        break;
+    }
+
+    return ret;
+}
+
+static gboolean webKitMediaSrcQueryWithParent(GstPad* pad, GstObject* parent, GstQuery* query)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(GST_ELEMENT(parent));
+    gboolean result = FALSE;
+
+    switch (GST_QUERY_TYPE(query)) {
+    case GST_QUERY_DURATION: {
+        GstFormat format;
+        gst_query_parse_duration(query, &format, NULL);
+
+        GST_DEBUG_OBJECT(src, "duration query in format %s", gst_format_get_name(format));
+        GST_OBJECT_LOCK(src);
+        if ((format == GST_FORMAT_TIME) && (src->priv->duration > 0)) {
+            gst_query_set_duration(query, format, src->priv->duration);
+            result = TRUE;
+        }
+        GST_OBJECT_UNLOCK(src);
+        break;
+    }
+    case GST_QUERY_URI: {
+        GST_OBJECT_LOCK(src);
+        gst_query_set_uri(query, src->priv->uri);
+        GST_OBJECT_UNLOCK(src);
+        result = TRUE;
+        break;
+    }
+    default: {
+        GRefPtr<GstPad> target = adoptGRef(gst_ghost_pad_get_target(GST_GHOST_PAD_CAST(pad)));
+        // Forward the query to the proxy target pad.
+        if (target)
+            result = gst_pad_query(target.get(), query);
+        break;
+    }
+    }
+
+    return result;
+}
+
+// uri handler interface
+static GstURIType webKitMediaSrcUriGetType(GType)
+{
+    return GST_URI_SRC;
+}
+
+const gchar* const* webKitMediaSrcGetProtocols(GType)
+{
+    static const char* protocols[] = {"mediasourceblob", 0 };
+    return protocols;
+}
+
+static gchar* webKitMediaSrcGetUri(GstURIHandler* handler)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(handler);
+    gchar* ret;
+
+    GST_OBJECT_LOCK(src);
+    ret = g_strdup(src->priv->uri);
+    GST_OBJECT_UNLOCK(src);
+    return ret;
+}
+
+static gboolean webKitMediaSrcSetUri(GstURIHandler* handler, const gchar* uri, GError**)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(handler);
+    WebKitMediaSrcPrivate* priv = src->priv;
+    if (GST_STATE(src) >= GST_STATE_PAUSED) {
+        GST_ERROR_OBJECT(src, "URI can only be set in states < PAUSED");
+        return FALSE;
+    }
+
+    GST_OBJECT_LOCK(src);
+    g_free(priv->uri);
+    priv->uri = 0;
+    if (!uri) {
+        GST_OBJECT_UNLOCK(src);
+        return TRUE;
+    }
+
+    WebCore::KURL url(WebCore::KURL(), uri);
+
+    priv->uri = g_strdup(url.string().utf8().data());
+    GST_OBJECT_UNLOCK(src);
+    return TRUE;
+}
+
+static void webKitMediaSrcUriHandlerInit(gpointer gIface, gpointer)
+{
+    GstURIHandlerInterface* iface = (GstURIHandlerInterface *) gIface;
+
+    iface->get_type = webKitMediaSrcUriGetType;
+    iface->get_protocols = webKitMediaSrcGetProtocols;
+    iface->get_uri = webKitMediaSrcGetUri;
+    iface->set_uri = webKitMediaSrcSetUri;
+}
+
+// appsrc callbacks
+static void webKitMediaVideoSrcNeedDataMainCb(WebKitMediaSrc* src)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_OBJECT_LOCK(src);
+    priv->sourceVideo.paused = FALSE;
+    GST_OBJECT_UNLOCK(src);
+}
+
+static void webKitMediaAudioSrcNeedDataMainCb(WebKitMediaSrc* src)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_OBJECT_LOCK(src);
+    priv->sourceAudio.paused = FALSE;
+    GST_OBJECT_UNLOCK(src);
+}
+
+static void webKitMediaVideoSrcNeedDataCb(GstAppSrc*, guint length, gpointer userData)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
+    //WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_DEBUG_OBJECT(src, "Need more data: %u", length);
+
+    GST_OBJECT_LOCK(src);
+    /*if (priv->sourceVideo.needData.isScheduled() || !priv->sourceVideo.paused) {
+        GST_OBJECT_UNLOCK(src);
+        return;
+    }
+
+    gst_object_ref(src);
+    priv->sourceVideo.needData.schedule("[WebKit] webKitMediaVideoSrcNeedDataMainCb", std::function<void()>(std::bind(webKitMediaVideoSrcNeedDataMainCb, src)), G_PRIORITY_DEFAULT,
+        [src] { gst_object_unref(src); });*/
+    GST_OBJECT_UNLOCK(src);
+}
+
+static void webKitMediaAudioSrcNeedDataCb(GstAppSrc*, guint length, gpointer userData)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
+    //WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_DEBUG_OBJECT(src, "Need more data: %u", length);
+
+    GST_OBJECT_LOCK(src);
+    /*if (priv->sourceAudio.needData.isScheduled() || !priv->sourceAudio.paused) {
+        GST_OBJECT_UNLOCK(src);
+        return;
+    }
+
+    gst_object_ref(src);
+    priv->sourceAudio.needData.schedule("[WebKit] webKitMediaAudioSrcNeedDataMainCb", std::function<void()>(std::bind(webKitMediaAudioSrcNeedDataMainCb, src)), G_PRIORITY_DEFAULT,
+        [src] { gst_object_unref(src); });*/
+    GST_OBJECT_UNLOCK(src);
+}
+
+static void webKitMediaVideoSrcEnoughDataMainCb(WebKitMediaSrc* src)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_OBJECT_LOCK(src);
+    priv->sourceVideo.paused = TRUE;
+    GST_OBJECT_UNLOCK(src);
+}
+
+static void webKitMediaAudioSrcEnoughDataMainCb(WebKitMediaSrc* src)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_OBJECT_LOCK(src);
+    priv->sourceAudio.paused = TRUE;
+    GST_OBJECT_UNLOCK(src);
+}
+
+static void webKitMediaVideoSrcEnoughDataCb(GstAppSrc*, gpointer userData)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
+    //WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_DEBUG_OBJECT(src, "Have enough data");
+
+    GST_OBJECT_LOCK(src);
+    /*if (priv->sourceVideo.enoughData.isScheduled() || priv->sourceVideo.paused) {
+        GST_OBJECT_UNLOCK(src);
+        return;
+    }
+
+    gst_object_ref(src);
+    priv->sourceVideo.enoughData.schedule("[WebKit] webKitMediaVideoSrcEnoughDataMainCb", std::function<void()>(std::bind(webKitMediaVideoSrcEnoughDataMainCb, src)), G_PRIORITY_DEFAULT,
+        [src] { gst_object_unref(src); });*/
+
+    GST_OBJECT_UNLOCK(src);
+}
+
+static void webKitMediaAudioSrcEnoughDataCb(GstAppSrc*, gpointer userData)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
+    //WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_DEBUG_OBJECT(src, "Have enough data");
+
+    GST_OBJECT_LOCK(src);
+    /*if (priv->sourceAudio.enoughData.isScheduled() || priv->sourceAudio.paused) {
+        GST_OBJECT_UNLOCK(src);
+        return;
+    }
+
+    gst_object_ref(src);
+    priv->sourceAudio.enoughData.schedule("[WebKit] webKitMediaAudioSrcEnoughDataMainCb", std::function<void()>(std::bind(webKitMediaAudioSrcEnoughDataMainCb, src)), G_PRIORITY_DEFAULT,
+        [src] { gst_object_unref(src); });*/
+
+    GST_OBJECT_UNLOCK(src);
+}
+
+static void webKitMediaVideoSrcSeekMainCb(WebKitMediaSrc*)
+{
+    notImplemented();
+}
+
+
+static void webKitMediaAudioSrcSeekMainCb(WebKitMediaSrc*)
+{
+    notImplemented();
+}
+
+static gboolean webKitMediaVideoSrcSeekDataCb(GstAppSrc*, guint64 offset, gpointer userData)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_DEBUG_OBJECT(src, "Seeking to offset: %" G_GUINT64_FORMAT, offset);
+    GST_OBJECT_LOCK(src);
+    if (offset == priv->sourceVideo.offset && priv->sourceVideo.requestedOffset == priv->sourceVideo.offset) {
+        GST_OBJECT_UNLOCK(src);
+        return TRUE;
+    }
+
+    if (!priv->seekable) {
+        GST_OBJECT_UNLOCK(src);
+        return FALSE;
+    }
+    if (offset > priv->sourceVideo.size) {
+        GST_OBJECT_UNLOCK(src);
+        return FALSE;
+    }
+
+    GST_DEBUG_OBJECT(src, "Doing range-request seek");
+    priv->sourceVideo.requestedOffset = offset;
+
+    /*gst_object_ref(src);
+    priv->sourceVideo.seek.schedule("[WebKit] webKitMediaVideoSrcSeekMainCb", std::function<void()>(std::bind(webKitMediaVideoSrcSeekMainCb, src)), G_PRIORITY_DEFAULT,
+        [src] { gst_object_unref(src); });*/
+
+    GST_OBJECT_UNLOCK(src);
+
+    return TRUE;
+}
+
+static gboolean webKitMediaAudioSrcSeekDataCb(GstAppSrc*, guint64 offset, gpointer userData)
+{
+    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
+    WebKitMediaSrcPrivate* priv = src->priv;
+
+    GST_DEBUG_OBJECT(src, "Seeking to offset: %" G_GUINT64_FORMAT, offset);
+    GST_OBJECT_LOCK(src);
+    if (offset == priv->sourceAudio.offset && priv->sourceAudio.requestedOffset == priv->sourceAudio.offset) {
+        GST_OBJECT_UNLOCK(src);
+        return TRUE;
+    }
+
+    if (!priv->seekable) {
+        GST_OBJECT_UNLOCK(src);
+        return FALSE;
+    }
+    if (offset > priv->sourceAudio.size) {
+        GST_OBJECT_UNLOCK(src);
+        return FALSE;
+    }
+
+    GST_DEBUG_OBJECT(src, "Doing range-request seek");
+    priv->sourceAudio.requestedOffset = offset;
+
+    /*gst_object_ref(src);
+    priv->sourceAudio.seek.schedule("[WebKit] webKitMediaAudioSrcSeekMainCb", std::function<void()>(std::bind(webKitMediaAudioSrcSeekMainCb, src)), G_PRIORITY_DEFAULT,
+        [src] { gst_object_unref(src); });*/
+
+    GST_OBJECT_UNLOCK(src);
+
+    return TRUE;
+}
+
+void webKitMediaSrcSetMediaPlayer(WebKitMediaSrc* src, WebCore::MediaPlayer* player)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+    priv->player = player;
+}
+
+void webKitMediaSrcSetPlayBin(WebKitMediaSrc* src, GstElement* playBin)
+{
+    WebKitMediaSrcPrivate* priv = src->priv;
+    priv->playbin = playBin;
+}
+
+MediaSourceClientGstreamer::MediaSourceClientGstreamer(WebKitMediaSrc* src)
+    : m_src(static_cast<WebKitMediaSrc*>(gst_object_ref(src)))
+{
+}
+
+MediaSourceClientGstreamer::~MediaSourceClientGstreamer()
+{
+    gst_object_unref(m_src);
+}
+
+void MediaSourceClientGstreamer::didReceiveDuration(double duration)
+{
+    WebKitMediaSrcPrivate* priv = m_src->priv;
+    GST_DEBUG_OBJECT(m_src, "Received duration: %lf", duration);
+
+    GST_OBJECT_LOCK(m_src);
+    priv->duration = duration >= 0.0 ? static_cast<gint64>(duration*GST_SECOND) : 0;
+    GST_OBJECT_UNLOCK(m_src);
+}
+
+void MediaSourceClientGstreamer::didReceiveData(const char* data, int length, String type)
+{
+    WebKitMediaSrcPrivate* priv = m_src->priv;
+    GstFlowReturn ret = GST_FLOW_OK;
+    GstBuffer * buffer;
+
+    if (type.startsWith("video")) {
+        if (priv->noMorePad == FALSE && priv->sourceVideo.padAdded == TRUE) {
+            gst_element_no_more_pads(GST_ELEMENT(m_src));
+            priv->noMorePad = TRUE;
+        }
+        if (priv->noMorePad == FALSE && priv->sourceVideo.padAdded == FALSE) {
+            gst_element_add_pad(GST_ELEMENT(m_src), priv->sourceVideo.srcpad);
+            priv->sourceVideo.padAdded = TRUE;
+        }
+        GST_OBJECT_LOCK(m_src);
+        buffer = WebCore::createGstBufferForData(data, length);
+        GST_OBJECT_UNLOCK(m_src);
+
+        ret = gst_app_src_push_buffer(GST_APP_SRC(priv->sourceVideo.appsrc), buffer);
+    } else if (type.startsWith("audio")) {
+        if (priv->noMorePad == FALSE && priv->sourceAudio.padAdded == TRUE) {
+            gst_element_no_more_pads(GST_ELEMENT(m_src));
+            priv->noMorePad = TRUE;
+        }
+        if (priv->noMorePad == FALSE && priv->sourceAudio.padAdded == FALSE) {
+            gst_element_add_pad(GST_ELEMENT(m_src), priv->sourceAudio.srcpad);
+            priv->sourceAudio.padAdded = TRUE;
+        }
+        GST_OBJECT_LOCK(m_src);
+        buffer = WebCore::createGstBufferForData(data, length);
+        GST_OBJECT_UNLOCK(m_src);
+
+        ret = gst_app_src_push_buffer(GST_APP_SRC(priv->sourceAudio.appsrc), buffer);
+    }
+
+    if (ret != GST_FLOW_OK && ret != GST_FLOW_EOS)
+        GST_ELEMENT_ERROR(m_src, CORE, FAILED, (0), (0));
+}
+
+void MediaSourceClientGstreamer::didFinishLoading(double)
+{
+    //WebKitMediaSrcPrivate* priv = m_src->priv;
+
+    GST_DEBUG_OBJECT(m_src, "Have EOS");
+
+    GST_OBJECT_LOCK(m_src);
+/*    if (!priv->sourceVideo.seek.isActive()) {
+        GST_OBJECT_UNLOCK(m_src);
+        gst_app_src_end_of_stream(GST_APP_SRC(priv->sourceVideo.appsrc));
+    } else*/
+        GST_OBJECT_UNLOCK(m_src);
+
+    GST_OBJECT_LOCK(m_src);
+    /*if (!priv->sourceAudio.seek.isActive()) {
+        GST_OBJECT_UNLOCK(m_src);
+        gst_app_src_end_of_stream(GST_APP_SRC(priv->sourceAudio.appsrc));
+    } else*/
+        GST_OBJECT_UNLOCK(m_src);
+}
+
+void MediaSourceClientGstreamer::didFail()
+{
+    gst_app_src_end_of_stream(GST_APP_SRC(m_src->priv->sourceVideo.appsrc));
+    gst_app_src_end_of_stream(GST_APP_SRC(m_src->priv->sourceAudio.appsrc));
+}
+
+#endif // USE(GSTREAMER)
+
diff --git a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.h b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.h
new file mode 100644
index 0000000..78892c3
--- /dev/null
+++ b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.h
@@ -0,0 +1,72 @@
+/*
+ *  Copyright (C) 2009, 2010 Sebastian Dröge <sebastian.droege@collabora.co.uk>
+ *  Copyright (C) 2013 Collabora Ltd.
+ *  Copyright (C) 2013 Orange
+ *
+ *  This library is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU Lesser General Public
+ *  License as published by the Free Software Foundation; either
+ *  version 2 of the License, or (at your option) any later version.
+ *
+ *  This library is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  Lesser General Public License for more details.
+ *
+ *  You should have received a copy of the GNU Lesser General Public
+ *  License along with this library; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
+ */
+
+#ifndef WebKitMediaSourceGStreamer_h
+#define WebKitMediaSourceGStreamer_h
+#if ENABLE(VIDEO) && ENABLE(MEDIA_SOURCE) && USE(GSTREAMER)
+
+#include "MediaPlayer.h"
+#include <gst/gst.h>
+
+G_BEGIN_DECLS
+
+#define WEBKIT_TYPE_MEDIA_SRC            (webkit_media_src_get_type ())
+#define WEBKIT_MEDIA_SRC(obj)            (G_TYPE_CHECK_INSTANCE_CAST ((obj), WEBKIT_TYPE_MEDIA_SRC, WebKitMediaSrc))
+#define WEBKIT_MEDIA_SRC_CLASS(klass)    (G_TYPE_CHECK_CLASS_CAST ((klass), WEBKIT_TYPE_MEDIA_SRC, WebKitMediaSrcClass))
+#define WEBKIT_IS_MEDIA_SRC(obj)         (G_TYPE_CHECK_INSTANCE_TYPE ((obj), WEBKIT_TYPE_MEDIA_SRC))
+#define WEBKIT_IS_MEDIA_SRC_CLASS(klass) (G_TYPE_CHECK_CLASS_TYPE ((klass), WEBKIT_TYPE_MEDIA_SRC))
+
+typedef struct _WebKitMediaSrc        WebKitMediaSrc;
+typedef struct _WebKitMediaSrcClass   WebKitMediaSrcClass;
+typedef struct _WebKitMediaSrcPrivate WebKitMediaSrcPrivate;
+
+struct _WebKitMediaSrc {
+    GstBin parent;
+
+    WebKitMediaSrcPrivate *priv;
+};
+
+struct _WebKitMediaSrcClass {
+    GstBinClass parentClass;
+};
+
+GType webkit_media_src_get_type(void);
+void webKitMediaSrcSetMediaPlayer(WebKitMediaSrc*, WebCore::MediaPlayer*);
+void webKitMediaSrcSetPlayBin(WebKitMediaSrc*, GstElement*);
+
+G_END_DECLS
+
+class MediaSourceClientGstreamer: public RefCounted<MediaSourceClientGstreamer> {
+    public:
+        MediaSourceClientGstreamer(WebKitMediaSrc*);
+        ~MediaSourceClientGstreamer();
+
+        void didReceiveDuration(double);
+        void didReceiveData(const char*, int, String);
+        void didFinishLoading(double);
+        void didFail();
+
+    private:
+        WebKitMediaSrc* m_src;
+};
+
+
+#endif // USE(GSTREAMER)
+#endif

From 93e47f7e8888567e7f0fb2c7d9280863fc3fef31 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 14 Nov 2014 11:26:42 +0100
Subject: [PATCH 23/68] Build the new files.

---
 Source/WebCore/Target.pri | 10 ++++++++++
 1 file changed, 10 insertions(+)

diff --git a/Source/WebCore/Target.pri b/Source/WebCore/Target.pri
index 52085a1..6d34025 100644
--- a/Source/WebCore/Target.pri
+++ b/Source/WebCore/Target.pri
@@ -3217,6 +3217,16 @@ enable?(MEDIA_SOURCE) {
         Modules/mediasource/MediaSourceRegistry.cpp \
         Modules/mediasource/SourceBuffer.cpp \
         Modules/mediasource/SourceBufferList.cpp
+        
+    use?(GSTREAMER) {
+        HEADERS += \
+            platform/graphics/gstreamer/WebKitMediaSourceGStreamer.h \
+            platform/graphics/gstreamer/SourceBufferPrivateGStreamer.h \ 
+            platform/graphics/gstreamer/MediaSourceGStreamer.h
+        SOURCES += \
+            platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp \
+            platform/graphics/gstreamer/MediaSourceGStreamer.cpp
+    }
 }
 
 enable?(ICONDATABASE) {

From 7ea7e5433e471fcc25310c19d5bfe02b887999b2 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 14 Nov 2014 11:26:57 +0100
Subject: [PATCH 24/68] Prepare to use the new MediaSource related code.

---
 .../gstreamer/MediaPlayerPrivateGStreamer.cpp      | 36 ++++++++++++++++------
 .../gstreamer/MediaPlayerPrivateGStreamer.h        |  9 +++++-
 2 files changed, 35 insertions(+), 10 deletions(-)

diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
index a79abc4..7482e24 100644
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
@@ -62,6 +62,11 @@ static const char* gPlaybinName = "playbin2";
 static const gint64 gPercentMax = 100;
 #endif
 
+#if ENABLE(MEDIA_SOURCE)
+#include "MediaSource.h"
+#include "WebKitMediaSourceGStreamer.h"
+#endif
+
 GST_DEBUG_CATEGORY_EXTERN(webkit_media_player_debug);
 #define GST_CAT_DEFAULT webkit_media_player_debug
 
@@ -179,9 +184,14 @@ bool initializeGStreamerAndRegisterWebKitElements()
     GRefPtr<GstElementFactory> srcFactory = gst_element_factory_find("webkitwebsrc");
     if (!srcFactory) {
         GST_DEBUG_CATEGORY_INIT(webkit_media_player_debug, "webkitmediaplayer", 0, "WebKit media player");
-        return gst_element_register(0, "webkitwebsrc", GST_RANK_PRIMARY + 100, WEBKIT_TYPE_WEB_SRC);
+        gst_element_register(0, "webkitwebsrc", GST_RANK_PRIMARY + 100, WEBKIT_TYPE_WEB_SRC);
     }
 
+#if ENABLE(MEDIA_SOURCE)
+    GRefPtr<GstElementFactory> WebKitMediaSrcFactory = gst_element_factory_find("webkitmediasrc");
+    if (!WebKitMediaSrcFactory)
+        gst_element_register(0, "webkitmediasrc", GST_RANK_PRIMARY + 100, WEBKIT_TYPE_MEDIA_SRC);
+#endif
     return true;
 }
 
@@ -330,9 +340,11 @@ void MediaPlayerPrivateGStreamer::load(const String& urlString)
 }
 
 #if ENABLE(MEDIA_SOURCE)
-void MediaPlayerPrivateGStreamer::load(const String& url, PassRefPtr<MediaSource>)
+void MediaPlayerPrivateGStreamer::load(const String& url, MediaSourcePrivateClient* mediaSource)
 {
-    notImplemented();
+    String mediasourceUri = String::format("mediasource%s", url.utf8().data());
+    m_mediaSource = mediaSource;
+    load(mediasourceUri);
 }
 #endif
 
@@ -744,9 +756,9 @@ void MediaPlayerPrivateGStreamer::setPreservesPitch(bool preservesPitch)
     m_preservesPitch = preservesPitch;
 }
 
-PassRefPtr<TimeRanges> MediaPlayerPrivateGStreamer::buffered() const
+PassRefPtr<PlatformTimeRanges> MediaPlayerPrivateGStreamer::buffered() const
 {
-    RefPtr<TimeRanges> timeRanges = TimeRanges::create();
+    RefPtr<PlatformTimeRanges> timeRanges = PlatformTimeRanges::create();
     if (m_errorOccured || isLiveStream())
         return timeRanges.release();
 
@@ -766,21 +778,21 @@ PassRefPtr<TimeRanges> MediaPlayerPrivateGStreamer::buffered() const
     for (guint index = 0; index < numBufferingRanges; index++) {
         gint64 rangeStart = 0, rangeStop = 0;
         if (gst_query_parse_nth_buffering_range(query, index, &rangeStart, &rangeStop))
-            timeRanges->add(static_cast<float>((rangeStart * mediaDuration) / gPercentMax),
-                static_cast<float>((rangeStop * mediaDuration) / gPercentMax));
+            timeRanges->add(MediaTime::createWithDouble((rangeStart * mediaDuration) / gPercentMax),
+                MediaTime::createWithDouble((rangeStop * mediaDuration) / gPercentMax));
     }
 
     // Fallback to the more general maxTimeLoaded() if no range has
     // been found.
     if (!timeRanges->length())
         if (float loaded = maxTimeLoaded())
-            timeRanges->add(0, loaded);
+            timeRanges->add(MediaTime::zeroTime(), MediaTime::createWithDouble(loaded));
 
     gst_query_unref(query);
 #else
     float loaded = maxTimeLoaded();
     if (!m_errorOccured && !isLiveStream() && loaded > 0)
-        timeRanges->add(0, loaded);
+        timeRanges->add(MediaTime::zeroTime(), MediaTime::createWithDouble(loaded));
 #endif
     return timeRanges.release();
 }
@@ -1159,6 +1171,12 @@ void MediaPlayerPrivateGStreamer::sourceChanged()
 
     if (WEBKIT_IS_WEB_SRC(m_source.get()))
         webKitWebSrcSetMediaPlayer(WEBKIT_WEB_SRC(m_source.get()), m_player);
+#if ENABLE(MEDIA_SOURCE)
+    if (m_mediaSource && WEBKIT_IS_MEDIA_SRC(m_source.get())) {
+        MediaSourceGStreamer::open(m_mediaSource.get(), WEBKIT_MEDIA_SRC(m_source.get()));
+        webKitMediaSrcSetPlayBin(WEBKIT_MEDIA_SRC(m_source.get()), m_playBin.get());
+    }
+#endif
 }
 
 void MediaPlayerPrivateGStreamer::cancelLoad()
diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h
index f3608c1..50cde99 100644
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h
@@ -37,6 +37,10 @@
 #include <wtf/threads/BinarySemaphore.h>
 #endif
 
+#if ENABLE(MEDIA_SOURCE)
+#include "MediaSourceGStreamer.h"
+#endif
+
 typedef struct _GstBuffer GstBuffer;
 typedef struct _GstMessage GstMessage;
 typedef struct _GstElement GstElement;
@@ -56,7 +60,7 @@ class MediaPlayerPrivateGStreamer : public MediaPlayerPrivateGStreamerBase {
 
     void load(const String &url);
 #if ENABLE(MEDIA_SOURCE)
-    void load(const String& url, PassRefPtr<MediaSource>);
+    void load(const String& url, MediaSourcePrivateClient*);
 #endif
     void commitLoad();
     void cancelLoad();
@@ -198,6 +202,9 @@ class MediaPlayerPrivateGStreamer : public MediaPlayerPrivateGStreamerBase {
 #if ENABLE(ENCRYPTED_MEDIA) || ENABLE(ENCRYPTED_MEDIA_V2)
     BinarySemaphore m_drmKeySemaphore;
 #endif
+#if ENABLE(MEDIA_SOURCE)
+    RefPtr<MediaSourcePrivateClient> m_mediaSource;
+#endif
 };
 }
 

From 3b32b40be4548d3093a9a978e0d29fbfba757e8f Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 12:25:24 +0100
Subject: [PATCH 25/68] Port more track API

---
 Source/WebCore/html/track/AudioTrack.cpp    | 76 +++++++++++++++++-----------
 Source/WebCore/html/track/AudioTrack.h      | 10 ++--
 Source/WebCore/html/track/TextTrack.cpp     |  9 +++-
 Source/WebCore/html/track/TextTrack.h       |  4 +-
 Source/WebCore/html/track/TrackBase.cpp     |  4 +-
 Source/WebCore/html/track/TrackBase.h       | 11 ++++-
 Source/WebCore/html/track/TrackListBase.cpp | 10 ++++
 Source/WebCore/html/track/TrackListBase.h   |  2 +
 Source/WebCore/html/track/VideoTrack.cpp    | 77 ++++++++++++++++++-----------
 Source/WebCore/html/track/VideoTrack.h      | 10 ++--
 10 files changed, 142 insertions(+), 71 deletions(-)

diff --git a/Source/WebCore/html/track/AudioTrack.cpp b/Source/WebCore/html/track/AudioTrack.cpp
index db51dd8..6ee8e31 100644
--- a/Source/WebCore/html/track/AudioTrack.cpp
+++ b/Source/WebCore/html/track/AudioTrack.cpp
@@ -80,40 +80,14 @@ const AtomicString& AudioTrack::commentaryKeyword()
 }
 
 AudioTrack::AudioTrack(AudioTrackClient* client, PassRefPtr<AudioTrackPrivate> trackPrivate)
-    : TrackBase(TrackBase::AudioTrack, trackPrivate->label(), trackPrivate->language())
+    : TrackBase(TrackBase::AudioTrack, trackPrivate->id(), trackPrivate->label(), trackPrivate->language())
     , m_id(trackPrivate->id())
     , m_enabled(trackPrivate->enabled())
     , m_client(client)
     , m_private(trackPrivate)
 {
     m_private->setClient(this);
-
-    switch (m_private->kind()) {
-    case AudioTrackPrivate::Alternative:
-        setKind(AudioTrack::alternativeKeyword());
-        break;
-    case AudioTrackPrivate::Description:
-        setKind(AudioTrack::descriptionKeyword());
-        break;
-    case AudioTrackPrivate::Main:
-        setKind(AudioTrack::mainKeyword());
-        break;
-    case AudioTrackPrivate::MainDesc:
-        setKind(AudioTrack::mainDescKeyword());
-        break;
-    case AudioTrackPrivate::Translation:
-        setKind(AudioTrack::translationKeyword());
-        break;
-    case AudioTrackPrivate::Commentary:
-        setKind(AudioTrack::commentaryKeyword());
-        break;
-    case AudioTrackPrivate::None:
-        setKind(emptyString());
-        break;
-    default:
-        ASSERT_NOT_REACHED();
-        break;
-    }
+    updateKindFromPrivate();
 }
 
 AudioTrack::~AudioTrack()
@@ -121,6 +95,22 @@ AudioTrack::~AudioTrack()
     m_private->setClient(0);
 }
 
+void AudioTrack::setPrivate(PassRefPtr<AudioTrackPrivate> trackPrivate)
+{
+    ASSERT(m_private);
+    ASSERT(trackPrivate);
+
+    if (m_private == trackPrivate)
+        return;
+
+    m_private->setClient(0);
+    m_private = trackPrivate;
+    m_private->setClient(this);
+
+    m_private->setEnabled(m_enabled);
+    updateKindFromPrivate();
+}
+
 bool AudioTrack::isValidKind(const AtomicString& value) const
 {
     if (value == alternativeKeyword())
@@ -163,6 +153,36 @@ void AudioTrack::willRemoveAudioTrackPrivate(AudioTrackPrivate* trackPrivate)
     mediaElement()->removeAudioTrack(this);
 }
 
+void AudioTrack::updateKindFromPrivate()
+{
+    switch (m_private->kind()) {
+    case AudioTrackPrivate::Alternative:
+        setKind(AudioTrack::alternativeKeyword());
+        break;
+    case AudioTrackPrivate::Description:
+        setKind(AudioTrack::descriptionKeyword());
+        break;
+    case AudioTrackPrivate::Main:
+        setKind(AudioTrack::mainKeyword());
+        break;
+    case AudioTrackPrivate::MainDesc:
+        setKind(AudioTrack::mainDescKeyword());
+        break;
+    case AudioTrackPrivate::Translation:
+        setKind(AudioTrack::translationKeyword());
+        break;
+    case AudioTrackPrivate::Commentary:
+        setKind(AudioTrack::commentaryKeyword());
+        break;
+    case AudioTrackPrivate::None:
+        setKind(emptyString());
+        break;
+    default:
+        ASSERT_NOT_REACHED();
+        break;
+    }
+}
+
 } // namespace WebCore
 
 #endif
diff --git a/Source/WebCore/html/track/AudioTrack.h b/Source/WebCore/html/track/AudioTrack.h
index 053ecb6..257ef21 100644
--- a/Source/WebCore/html/track/AudioTrack.h
+++ b/Source/WebCore/html/track/AudioTrack.h
@@ -54,9 +54,6 @@ class AudioTrack : public TrackBase, public AudioTrackPrivateClient {
     }
     virtual ~AudioTrack();
 
-    AtomicString id() const { return m_id; }
-    void setId(const AtomicString& id) { m_id = id; }
-
     static const AtomicString& alternativeKeyword();
     static const AtomicString& descriptionKeyword();
     static const AtomicString& mainKeyword();
@@ -65,7 +62,7 @@ class AudioTrack : public TrackBase, public AudioTrackPrivateClient {
     static const AtomicString& commentaryKeyword();
     virtual const AtomicString& defaultKindKeyword() const OVERRIDE { return emptyAtom; }
 
-    bool enabled() const { return m_enabled; }
+    virtual bool enabled() const OVERRIDE { return m_enabled; }
     virtual void setEnabled(const bool);
 
     virtual void clearClient() OVERRIDE { m_client = 0; }
@@ -73,6 +70,8 @@ class AudioTrack : public TrackBase, public AudioTrackPrivateClient {
 
     size_t inbandTrackIndex();
 
+    void setPrivate(PassRefPtr<AudioTrackPrivate>);
+
 protected:
     AudioTrack(AudioTrackClient*, PassRefPtr<AudioTrackPrivate>);
 
@@ -80,7 +79,8 @@ class AudioTrack : public TrackBase, public AudioTrackPrivateClient {
     virtual bool isValidKind(const AtomicString&) const OVERRIDE;
     virtual void willRemoveAudioTrackPrivate(AudioTrackPrivate*) OVERRIDE;
 
-    AtomicString m_id;
+    void updateKindFromPrivate();
+
     bool m_enabled;
     AudioTrackClient* m_client;
 
diff --git a/Source/WebCore/html/track/TextTrack.cpp b/Source/WebCore/html/track/TextTrack.cpp
index c692ed9..8d667d7 100644
--- a/Source/WebCore/html/track/TextTrack.cpp
+++ b/Source/WebCore/html/track/TextTrack.cpp
@@ -113,8 +113,8 @@ TextTrack* TextTrack::captionMenuAutomaticItem()
     return automatic.get();
 }
 
-TextTrack::TextTrack(ScriptExecutionContext* context, TextTrackClient* client, const AtomicString& kind, const AtomicString& label, const AtomicString& language, TextTrackType type)
-    : TrackBase(TrackBase::TextTrack, label, language)
+TextTrack::TextTrack(ScriptExecutionContext* context, TextTrackClient* client, const AtomicString& kind, const AtomicString& id, const AtomicString& label, const AtomicString& language, TextTrackType type)
+    : TrackBase(TrackBase::TextTrack, id, label, language)
     , m_cues(0)
     , m_scriptExecutionContext(context)
 #if ENABLE(WEBVTT_REGIONS)
@@ -172,6 +172,11 @@ bool TextTrack::isValidKind(const AtomicString& value) const
     return TextTrack::isValidKindKeyword(value);
 }
 
+bool TextTrack::enabled() const
+{
+    return m_mode != disabledKeyword();
+}
+
 bool TextTrack::isValidKindKeyword(const AtomicString& value)
 {
     if (value == subtitlesKeyword())
diff --git a/Source/WebCore/html/track/TextTrack.h b/Source/WebCore/html/track/TextTrack.h
index 3e79bdf..92db3fb 100644
--- a/Source/WebCore/html/track/TextTrack.h
+++ b/Source/WebCore/html/track/TextTrack.h
@@ -67,7 +67,7 @@ class TextTrack : public TrackBase, public EventTarget
 #endif
     {
 public:
-    static PassRefPtr<TextTrack> create(ScriptExecutionContext* context, TextTrackClient* client, const AtomicString& kind, const AtomicString& label, const AtomicString& language)
+    static PassRefPtr<TextTrack> create(ScriptExecutionContext* context, TextTrackClient* client, const AtomicString& kind, const AtomicString& id, const AtomicString& label, const AtomicString& language)
     {
         return adoptRef(new TextTrack(context, client, kind, label, language, AddTrack));
     }
@@ -88,6 +88,8 @@ class TextTrack : public TrackBase, public EventTarget
     virtual const AtomicString& defaultKindKeyword() const OVERRIDE { return subtitlesKeyword(); }
     static bool isValidKindKeyword(const AtomicString&);
 
+    virtual bool enabled() const OVERRIDE;
+
     static const AtomicString& disabledKeyword();
     static const AtomicString& hiddenKeyword();
     static const AtomicString& showingKeyword();
diff --git a/Source/WebCore/html/track/TrackBase.cpp b/Source/WebCore/html/track/TrackBase.cpp
index 9327d5a..7f06584 100644
--- a/Source/WebCore/html/track/TrackBase.cpp
+++ b/Source/WebCore/html/track/TrackBase.cpp
@@ -32,11 +32,13 @@
 
 namespace WebCore {
 
-TrackBase::TrackBase(Type type, const AtomicString& label, const AtomicString& language)
+TrackBase::TrackBase(Type type, const AtomicString& id, const AtomicString& label, const AtomicString& language)
     : m_mediaElement(0)
 #if ENABLE(MEDIA_SOURCE)
     , m_sourceBuffer(0)
 #endif
+    , m_uniqueId(++s_uniqueId)
+    , m_id(id)
     , m_label(label)
     , m_language(language)
 {
diff --git a/Source/WebCore/html/track/TrackBase.h b/Source/WebCore/html/track/TrackBase.h
index 17a0e05..2a07058 100644
--- a/Source/WebCore/html/track/TrackBase.h
+++ b/Source/WebCore/html/track/TrackBase.h
@@ -48,6 +48,9 @@ class TrackBase : public RefCounted<TrackBase> {
     HTMLMediaElement* mediaElement() { return m_mediaElement; }
     virtual Element* element();
 
+    virtual AtomicString id() const { return m_id; }
+    virtual void setId(const AtomicString& id) { m_id = id; }
+
     AtomicString kind() const { return m_kind; }
     virtual void setKind(const AtomicString&);
 
@@ -59,13 +62,17 @@ class TrackBase : public RefCounted<TrackBase> {
 
     virtual void clearClient() = 0;
 
+    virtual int uniqueId() const { return m_uniqueId; }
+
 #if ENABLE(MEDIA_SOURCE)
     SourceBuffer* sourceBuffer() const { return m_sourceBuffer; }
     void setSourceBuffer(SourceBuffer* buffer) { m_sourceBuffer = buffer; }
 #endif
 
+    virtual bool enabled() const = 0;
+
 protected:
-    TrackBase(Type, const AtomicString& label, const AtomicString& language);
+    TrackBase(Type, const AtomicString& id, const AtomicString& label, const AtomicString& language);
 
     virtual bool isValidKind(const AtomicString&) const = 0;
     virtual const AtomicString& defaultKindKeyword() const = 0;
@@ -78,6 +85,8 @@ class TrackBase : public RefCounted<TrackBase> {
 
 private:
     Type m_type;
+    int m_uniqueId;
+    AtomicString m_id;
     AtomicString m_kind;
     AtomicString m_label;
     AtomicString m_language;
diff --git a/Source/WebCore/html/track/TrackListBase.cpp b/Source/WebCore/html/track/TrackListBase.cpp
index 229097f..ba5a8fa 100644
--- a/Source/WebCore/html/track/TrackListBase.cpp
+++ b/Source/WebCore/html/track/TrackListBase.cpp
@@ -180,4 +180,14 @@ void TrackListBase::asyncEventTimerFired(Timer<TrackListBase>*)
     --m_dispatchingEvents;
 }
 
+bool TrackListBase::isAnyTrackEnabled() const
+{
+    for (size_t i = 0; i < m_inbandTracks.size(); ++i) {
+        TrackBase* track = m_inbandTracks[i].get();
+        if (track->enabled())
+            return true;
+    }
+    return false;
+}
+
 #endif
diff --git a/Source/WebCore/html/track/TrackListBase.h b/Source/WebCore/html/track/TrackListBase.h
index 9b51b65..36acb30 100644
--- a/Source/WebCore/html/track/TrackListBase.h
+++ b/Source/WebCore/html/track/TrackListBase.h
@@ -68,6 +68,8 @@ class TrackListBase : public RefCounted<TrackListBase>, public EventTarget {
     // Needs to be public so tracks can call it
     void scheduleChangeEvent();
 
+    bool isAnyTrackEnabled() const;
+
 protected:
     TrackListBase(HTMLMediaElement*, ScriptExecutionContext*);
 
diff --git a/Source/WebCore/html/track/VideoTrack.cpp b/Source/WebCore/html/track/VideoTrack.cpp
index cfa0826..f9c73dd 100644
--- a/Source/WebCore/html/track/VideoTrack.cpp
+++ b/Source/WebCore/html/track/VideoTrack.cpp
@@ -80,40 +80,13 @@ const AtomicString& VideoTrack::commentaryKeyword()
 }
 
 VideoTrack::VideoTrack(VideoTrackClient* client, PassRefPtr<VideoTrackPrivate> trackPrivate)
-    : TrackBase(TrackBase::VideoTrack, trackPrivate->label(), trackPrivate->language())
-    , m_id(trackPrivate->id())
+    : TrackBase(TrackBase::VideoTrack, trackPrivate->id(), trackPrivate->label(), trackPrivate->language())
     , m_selected(trackPrivate->selected())
     , m_client(client)
     , m_private(trackPrivate)
 {
     m_private->setClient(this);
-
-    switch (m_private->kind()) {
-    case VideoTrackPrivate::Alternative:
-        setKind(VideoTrack::alternativeKeyword());
-        break;
-    case VideoTrackPrivate::Captions:
-        setKind(VideoTrack::captionsKeyword());
-        break;
-    case VideoTrackPrivate::Main:
-        setKind(VideoTrack::mainKeyword());
-        break;
-    case VideoTrackPrivate::Sign:
-        setKind(VideoTrack::signKeyword());
-        break;
-    case VideoTrackPrivate::Subtitles:
-        setKind(VideoTrack::subtitlesKeyword());
-        break;
-    case VideoTrackPrivate::Commentary:
-        setKind(VideoTrack::commentaryKeyword());
-        break;
-    case VideoTrackPrivate::None:
-        setKind(emptyString());
-        break;
-    default:
-        ASSERT_NOT_REACHED();
-        break;
-    }
+    updateKindFromPrivate();
 }
 
 VideoTrack::~VideoTrack()
@@ -121,6 +94,22 @@ VideoTrack::~VideoTrack()
     m_private->setClient(0);
 }
 
+void VideoTrack::setPrivate(PassRefPtr<VideoTrackPrivate> trackPrivate)
+{
+    ASSERT(m_private);
+    ASSERT(trackPrivate);
+
+    if (m_private == trackPrivate)
+        return;
+
+    m_private->setClient(nullptr);
+    m_private = trackPrivate;
+    m_private->setClient(this);
+
+    m_private->setSelected(m_selected);
+    updateKindFromPrivate();
+}
+
 bool VideoTrack::isValidKind(const AtomicString& value) const
 {
     if (value == alternativeKeyword())
@@ -163,6 +152,36 @@ void VideoTrack::willRemoveVideoTrackPrivate(VideoTrackPrivate* trackPrivate)
     mediaElement()->removeVideoTrack(this);
 }
 
+void VideoTrack::updateKindFromPrivate()
+{
+    switch (m_private->kind()) {
+    case VideoTrackPrivate::Alternative:
+        setKindInternal(VideoTrack::alternativeKeyword());
+        break;
+    case VideoTrackPrivate::Captions:
+        setKindInternal(VideoTrack::captionsKeyword());
+        break;
+    case VideoTrackPrivate::Main:
+        setKindInternal(VideoTrack::mainKeyword());
+        break;
+    case VideoTrackPrivate::Sign:
+        setKindInternal(VideoTrack::signKeyword());
+        break;
+    case VideoTrackPrivate::Subtitles:
+        setKindInternal(VideoTrack::subtitlesKeyword());
+        break;
+    case VideoTrackPrivate::Commentary:
+        setKindInternal(VideoTrack::commentaryKeyword());
+        break;
+    case VideoTrackPrivate::None:
+        setKindInternal(emptyString());
+        break;
+    default:
+        ASSERT_NOT_REACHED();
+        break;
+    }
+}
+
 } // namespace WebCore
 
 #endif
diff --git a/Source/WebCore/html/track/VideoTrack.h b/Source/WebCore/html/track/VideoTrack.h
index f091e3b..a38513b 100644
--- a/Source/WebCore/html/track/VideoTrack.h
+++ b/Source/WebCore/html/track/VideoTrack.h
@@ -54,9 +54,6 @@ class VideoTrack : public TrackBase, public VideoTrackPrivateClient {
     }
     virtual ~VideoTrack();
 
-    AtomicString id() const { return m_id; }
-    void setId(const AtomicString& id) { m_id = id; }
-
     static const AtomicString& alternativeKeyword();
     static const AtomicString& captionsKeyword();
     static const AtomicString& mainKeyword();
@@ -73,6 +70,8 @@ class VideoTrack : public TrackBase, public VideoTrackPrivateClient {
 
     size_t inbandTrackIndex();
 
+    void setPrivate(PassRefPtr<VideoTrackPrivate>);
+
 protected:
     VideoTrack(VideoTrackClient*, PassRefPtr<VideoTrackPrivate> privateTrack);
 
@@ -80,7 +79,10 @@ class VideoTrack : public TrackBase, public VideoTrackPrivateClient {
     virtual bool isValidKind(const AtomicString&) const OVERRIDE;
     virtual void willRemoveVideoTrackPrivate(VideoTrackPrivate*) OVERRIDE;
 
-    AtomicString m_id;
+    virtual bool enabled() const OVERRIDE { return selected(); }
+
+    void updateKindFromPrivate();
+
     bool m_selected;
     VideoTrackClient* m_client;
 

From 1a6f7db83ac18ca0355cd42aeea1f0bfc1cf3574 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 12:25:48 +0100
Subject: [PATCH 26/68] More fixes

---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp | 21 ++++++++++-----------
 1 file changed, 10 insertions(+), 11 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index e6ffcca..63f5a67 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -144,7 +144,7 @@ PassRefPtr<TimeRanges> SourceBuffer::buffered(ExceptionCode& ec) const
     //    INVALID_STATE_ERR exception and abort these steps.
     if (isRemoved()) {
         ec = INVALID_STATE_ERR;
-        return nullptr;
+        return 0;
     }
 
     // 2. Return a new static normalized TimeRanges object for the media segments buffered.
@@ -578,8 +578,7 @@ static PassRefPtr<TimeRanges> removeSamplesFromTrackBuffer(const DecodeOrderSamp
 #if !LOG_DISABLED
         size_t startBufferSize = trackBuffer.samples.sizeInBytes();
 #endif
-
-        RefPtr<MediaSample>& sample = it->second;
+        const RefPtr<MediaSample>& sample = it->second;
         LOG(MediaSource, "SourceBuffer::%s(%p) - removing sample(%s)", logPrefix, buffer, toString(*it->second).utf8().data());
 
         // Remove the erased samples from the TrackBuffer sample map.
@@ -679,7 +678,7 @@ void SourceBuffer::removeCodedFrames(const MediaTime& start, const MediaTime& en
     LOG(Media, "SourceBuffer::removeCodedFrames(%p) - buffered = %s", this, toString(m_buffered->ranges()).utf8().data());
 }
 
-void SourceBuffer::removeTimerFired(Timer*)
+void SourceBuffer::removeTimerFired(Timer<SourceBuffer>*)
 {
     ASSERT(m_updating);
     ASSERT(m_pendingRemoveStart.isValid());
@@ -794,7 +793,7 @@ void SourceBuffer::evictCodedFrames(size_t newDataSize)
     LOG(MediaSource, "SourceBuffer::evictCodedFrames(%p) - evicted %zu bytes%s", this, initialBufferedSize - extraMemoryCost(), m_bufferFull ? "" : " but FAILED to free enough");
 }
 
-size_t SourceBuffer::maximumBufferSize()
+size_t SourceBuffer::maximumBufferSize() const
 {
     if (isRemoved())
         return 0;
@@ -821,7 +820,7 @@ const AtomicString& SourceBuffer::networkError()
 VideoTrackList* SourceBuffer::videoTracks()
 {
     if (!m_source || !m_source->mediaElement())
-        return nullptr;
+        return 0;
 
     if (!m_videoTracks)
         m_videoTracks = VideoTrackList::create(m_source->mediaElement(), ActiveDOMObject::scriptExecutionContext());
@@ -832,7 +831,7 @@ VideoTrackList* SourceBuffer::videoTracks()
 AudioTrackList* SourceBuffer::audioTracks()
 {
     if (!m_source || !m_source->mediaElement())
-        return nullptr;
+        return 0;
 
     if (!m_audioTracks)
         m_audioTracks = AudioTrackList::create(m_source->mediaElement(), ActiveDOMObject::scriptExecutionContext());
@@ -843,7 +842,7 @@ AudioTrackList* SourceBuffer::audioTracks()
 TextTrackList* SourceBuffer::textTracks()
 {
     if (!m_source || !m_source->mediaElement())
-        return nullptr;
+        return 0;
 
     if (!m_textTracks)
         m_textTracks = TextTrackList::create(m_source->mediaElement(), ActiveDOMObject::scriptExecutionContext());
@@ -912,7 +911,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
                 break;
             }
 
-            AudioTrack audioTrack = audioTracks()->getTrackById(audioTrackInfo.track->id());
+            AudioTrack *audioTrack = audioTracks()->getTrackById(audioTrackInfo.track->id());
             ASSERT(audioTrack);
             audioTrack->setPrivate(audioTrackInfo.track);
         }
@@ -927,7 +926,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
                 break;
             }
 
-            VideoTrack videoTrack = videoTracks()->getTrackById(videoTrackInfo.track->id());
+            VideoTrack *videoTrack = videoTracks()->getTrackById(videoTrackInfo.track->id());
             ASSERT(videoTrack);
             videoTrack->setPrivate(videoTrackInfo.track);
         }
@@ -940,7 +939,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
                 break;
             }
 
-            TextTrack textTrack = textTracks()->getTrackById(textTrackInfo.track->id());
+            TextTrack *textTrack = textTracks()->getTrackById(textTrackInfo.track->id());
             ASSERT(textTrack);
             static_cast<InbandTextTrack>(*textTrack).setPrivate(textTrackInfo.track);
         }

From 5fd4904eb7ab08d3031df572189e98e43af224a3 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 14 Nov 2014 12:39:07 +0100
Subject: [PATCH 27/68] As MediaSource is a ref counted object we can use
 OwnPtr.

---
 Source/WebCore/Modules/mediasource/MediaSource.cpp                  | 4 ++--
 Source/WebCore/Modules/mediasource/MediaSource.h                    | 2 +-
 Source/WebCore/platform/graphics/MediaSourcePrivateClient.h         | 2 +-
 Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.cpp | 4 ++--
 4 files changed, 6 insertions(+), 6 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/MediaSource.cpp b/Source/WebCore/Modules/mediasource/MediaSource.cpp
index 6938b77..8918998 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.cpp
+++ b/Source/WebCore/Modules/mediasource/MediaSource.cpp
@@ -110,11 +110,11 @@ const AtomicString& MediaSource::endedKeyword()
     return ended;
 }
 
-void MediaSource::setPrivateAndOpen(PassOwnPtr<MediaSourcePrivate> mediaSourcePrivate)
+void MediaSource::setPrivateAndOpen(PassRefPtr<MediaSourcePrivate> mediaSourcePrivate)
 {
     ASSERT(!m_private);
     ASSERT(m_mediaElement);
-    m_private = mediaSourcePrivate.get ();
+    m_private = mediaSourcePrivate;
     setReadyState(openKeyword());
 }
 
diff --git a/Source/WebCore/Modules/mediasource/MediaSource.h b/Source/WebCore/Modules/mediasource/MediaSource.h
index 1e55e69..f0625d3 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.h
+++ b/Source/WebCore/Modules/mediasource/MediaSource.h
@@ -70,7 +70,7 @@ class MediaSource : public MediaSourcePrivateClient, public ActiveDOMObject, pub
     void streamEndedWithError(const AtomicString& error, ExceptionCode&);
 
     // MediaSourcePrivateClient
-    virtual void setPrivateAndOpen(PassOwnPtr<MediaSourcePrivate>) OVERRIDE;
+    virtual void setPrivateAndOpen(PassRefPtr<MediaSourcePrivate>) OVERRIDE;
     virtual MediaTime duration() const;
     virtual PassOwnPtr<PlatformTimeRanges> buffered() const;
     virtual void seekToTime(const MediaTime&);
diff --git a/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h b/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h
index 5827763..76e9fe8 100644
--- a/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h
+++ b/Source/WebCore/platform/graphics/MediaSourcePrivateClient.h
@@ -41,7 +41,7 @@ class MediaSourcePrivateClient : public RefCounted<MediaSourcePrivateClient> {
 public:
     virtual ~MediaSourcePrivateClient() { }
 
-    virtual void setPrivateAndOpen(PassOwnPtr<MediaSourcePrivate>) = 0;
+    virtual void setPrivateAndOpen(PassRefPtr<MediaSourcePrivate>) = 0;
     virtual MediaTime duration() const = 0;
     virtual PassOwnPtr<PlatformTimeRanges> buffered() const = 0;
     virtual void seekToTime(const MediaTime&) = 0;
diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.cpp
index 51a0716..6cd3709 100644
--- a/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaSourceGStreamer.cpp
@@ -43,8 +43,8 @@ namespace WebCore {
 void MediaSourceGStreamer::open(MediaSourcePrivateClient* mediaSource, WebKitMediaSrc* src)
 {
     ASSERT(mediaSource);
-    RefPtr<MediaSourcePrivate> mediaSourcePrivate = adoptRef (new MediaSourceGStreamer(mediaSource, src));
-    mediaSource->setPrivateAndOpen(*mediaSourcePrivate);
+    RefPtr<MediaSourceGStreamer> mediaSourcePrivate = new MediaSourceGStreamer(mediaSource, src);
+    mediaSource->setPrivateAndOpen(mediaSourcePrivate.release());
 }
 
 MediaSourceGStreamer::MediaSourceGStreamer(MediaSourcePrivateClient* mediaSource, WebKitMediaSrc* src)

From d32af9ae823f0636fcf641f5d2c168048c896a78 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 12:45:06 +0100
Subject: [PATCH 28/68] Fix more errors

---
 .../WebCore/Modules/mediasource/SourceBuffer.cpp   | 22 +++++++++++-----------
 Source/WebCore/Modules/mediasource/SourceBuffer.h  |  4 ++--
 2 files changed, 13 insertions(+), 13 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index 63f5a67..49a138a 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -96,14 +96,14 @@ struct SourceBuffer::TrackBuffer {
     }
 };
 
-PassRefPtr<SourceBuffer> SourceBuffer::create(PassRefPtr<SourceBufferPrivate> sourceBufferPrivate, MediaSource* source)
+PassRefPtr<SourceBuffer> SourceBuffer::create(PassRefPtr<SourceBufferPrivate> sourceBufferPrivate, PassRefPtr<MediaSource> source)
 {
     RefPtr<SourceBuffer> sourceBuffer(adoptRef(new SourceBuffer(WTF::move(sourceBufferPrivate), source)));
     sourceBuffer->suspendIfNeeded();
     return sourceBuffer.releaseNonNull();
 }
 
-SourceBuffer::SourceBuffer(PassRefPtr<SourceBufferPrivate> sourceBufferPrivate, MediaSource* source)
+SourceBuffer::SourceBuffer(PassRefPtr<SourceBufferPrivate> sourceBufferPrivate, PassRefPtr<MediaSource> source)
     : ActiveDOMObject(source->scriptExecutionContext())
     , m_private(WTF::move(sourceBufferPrivate))
     , m_source(source)
@@ -961,9 +961,9 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         // NOTE: This check is the responsibility of the SourceBufferPrivate.
 
         // 5.2 For each audio track in the initialization segment, run following steps:
-        Vector<InitializationSegment::AudioTrackInformation>::iterator aend = segment.audioTracks.end();
-        for (Vector<InitializationSegment::AudioTrackInformation>::iterator it = segment.audioTracks.begin(); it != aend; ++it) {
-            InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
+        Vector<InitializationSegment::AudioTrackInformation>::const_iterator aend = segment.audioTracks.end();
+        for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != aend; ++it) {
+            const InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
             AudioTrackPrivate* audioTrackPrivate = audioTrackInfo.track.get();
 
             // 5.2.1 Let new audio track be a new AudioTrack object.
@@ -1003,9 +1003,9 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         }
 
         // 5.3 For each video track in the initialization segment, run following steps:
-        Vector<InitializationSegment::VideoTrackInformation>::iterator vend = segment.videoTracks.end();
-        for (Vector<InitializationSegment::VideoTrackInformation>::iterator it = segment.videoTracks.begin(); it != vend; ++it) {
-            InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
+        Vector<InitializationSegment::VideoTrackInformation>::const_iterator vend = segment.videoTracks.end();
+        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+            const InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
             VideoTrackPrivate* videoTrackPrivate = videoTrackInfo.track.get();
 
             // 5.3.1 Let new video track be a new VideoTrack object.
@@ -1045,9 +1045,9 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         }
 
         // 5.4 For each text track in the initialization segment, run following steps:
-        Vector<InitializationSegment::TextTrackInformation>::iterator tend = segment.textTracks.end();
-        for (Vector<InitializationSegment::TextTrackInformation>::iterator it = segment.textTracks.begin(); it != tend; ++it) {
-            InitializationSegment::TextTrackInformation & textTrackInfo = *it;
+        Vector<InitializationSegment::TextTrackInformation>::const_iterator tend = segment.textTracks.end();
+        for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != tend; ++it) {
+            const InitializationSegment::TextTrackInformation & textTrackInfo = *it;
             InbandTextTrackPrivate* textTrackPrivate = textTrackInfo.track.get();
 
             // 5.4.1 Let new text track be a new TextTrack object with its properties populated with the
diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.h b/Source/WebCore/Modules/mediasource/SourceBuffer.h
index 8b96492..5a8bd02 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.h
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.h
@@ -124,8 +124,8 @@ class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, pu
     virtual void sourceBufferPrivateDidEndStream(SourceBufferPrivate*, const WTF::AtomicString&);
     virtual void sourceBufferPrivateDidReceiveInitializationSegment(SourceBufferPrivate*, const InitializationSegment&);
     virtual void sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, PassRefPtr<MediaSample>);
-    virtual bool sourceBufferPrivateHasAudio(const SourceBufferPrivate*);
-    virtual bool sourceBufferPrivateHasVideo(const SourceBufferPrivate*);
+    virtual bool sourceBufferPrivateHasAudio(const SourceBufferPrivate*) const;
+    virtual bool sourceBufferPrivateHasVideo(const SourceBufferPrivate*) const;
     virtual void sourceBufferPrivateDidBecomeReadyForMoreSamples(SourceBufferPrivate*, AtomicString trackID);
     virtual MediaTime sourceBufferPrivateFastSeekTimeForMediaTime(SourceBufferPrivate*, const MediaTime&, const MediaTime& negativeThreshold, const MediaTime& positiveThreshold);
     virtual void sourceBufferPrivateAppendComplete(SourceBufferPrivate*, AppendResult);

From 6c799d17cfce0620ac0fc896ebb01ea360e16868 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 14 Nov 2014 14:41:29 +0100
Subject: [PATCH 29/68] Revert "Backport new functions from upstream."

This reverts commit 9396657009c051bedb91932b22572c91ebc86ab4.
---
 .../graphics/gstreamer/GStreamerUtilities.cpp      | 98 +---------------------
 .../graphics/gstreamer/GStreamerUtilities.h        | 42 ----------
 2 files changed, 2 insertions(+), 138 deletions(-)

diff --git a/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.cpp b/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.cpp
index cee1c81..3e66952 100644
--- a/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.cpp
@@ -18,108 +18,14 @@
 
 
 #include "config.h"
-
-#if USE(GSTREAMER)
 #include "GStreamerUtilities.h"
 
-#include "IntSize.h"
-
-#include <gst/audio/audio.h>
-#include <wtf/MathExtras.h>
+#if USE(GSTREAMER)
+#include <gst/gst.h>
 #include <wtf/gobject/GOwnPtr.h>
 
 namespace WebCore {
 
-const char* webkitGstMapInfoQuarkString = "webkit-gst-map-info";
-
-GstPad* webkitGstGhostPadFromStaticTemplate(GstStaticPadTemplate* staticPadTemplate, const gchar* name, GstPad* target)
-{
-    GstPad* pad;
-    GstPadTemplate* padTemplate = gst_static_pad_template_get(staticPadTemplate);
-
-    if (target)
-        pad = gst_ghost_pad_new_from_template(name, target, padTemplate);
-    else
-        pad = gst_ghost_pad_new_no_target_from_template(name, padTemplate);
-
-    gst_object_unref(padTemplate);
-
-    return pad;
-}
-
-#if ENABLE(VIDEO)
-bool getVideoSizeAndFormatFromCaps(GstCaps* caps, WebCore::IntSize& size, GstVideoFormat& format, int& pixelAspectRatioNumerator, int& pixelAspectRatioDenominator, int& stride)
-{
-    GstVideoInfo info;
-
-    gst_video_info_init(&info);
-    if (!gst_video_info_from_caps(&info, caps))
-        return false;
-
-    format = GST_VIDEO_INFO_FORMAT(&info);
-    size.setWidth(GST_VIDEO_INFO_WIDTH(&info));
-    size.setHeight(GST_VIDEO_INFO_HEIGHT(&info));
-    pixelAspectRatioNumerator = GST_VIDEO_INFO_PAR_N(&info);
-    pixelAspectRatioDenominator = GST_VIDEO_INFO_PAR_D(&info);
-    stride = GST_VIDEO_INFO_PLANE_STRIDE(&info, 0);
-
-    return true;
-}
-#endif
-
-GstBuffer* createGstBuffer(GstBuffer* buffer)
-{
-    gsize bufferSize = gst_buffer_get_size(buffer);
-    GstBuffer* newBuffer = gst_buffer_new_and_alloc(bufferSize);
-
-    if (!newBuffer)
-        return 0;
-
-    gst_buffer_copy_into(newBuffer, buffer, static_cast<GstBufferCopyFlags>(GST_BUFFER_COPY_METADATA), 0, bufferSize);
-    return newBuffer;
-}
-
-GstBuffer* createGstBufferForData(const char* data, int length)
-{
-    GstBuffer* buffer = gst_buffer_new_and_alloc(length);
-
-    gst_buffer_fill(buffer, 0, data, length);
-
-    return buffer;
-}
-
-char* getGstBufferDataPointer(GstBuffer* buffer)
-{
-    GstMiniObject* miniObject = reinterpret_cast<GstMiniObject*>(buffer);
-    GstMapInfo* mapInfo = static_cast<GstMapInfo*>(gst_mini_object_get_qdata(miniObject, g_quark_from_static_string(webkitGstMapInfoQuarkString)));
-    return reinterpret_cast<char*>(mapInfo->data);
-}
-
-void mapGstBuffer(GstBuffer* buffer)
-{
-    GstMapInfo* mapInfo = g_slice_new(GstMapInfo);
-    if (!gst_buffer_map(buffer, mapInfo, GST_MAP_WRITE)) {
-        g_slice_free(GstMapInfo, mapInfo);
-        gst_buffer_unref(buffer);
-        return;
-    }
-
-    GstMiniObject* miniObject = reinterpret_cast<GstMiniObject*>(buffer);
-    gst_mini_object_set_qdata(miniObject, g_quark_from_static_string(webkitGstMapInfoQuarkString), mapInfo, 0);
-}
-
-void unmapGstBuffer(GstBuffer* buffer)
-{
-    GstMiniObject* miniObject = reinterpret_cast<GstMiniObject*>(buffer);
-    GstMapInfo* mapInfo = static_cast<GstMapInfo*>(gst_mini_object_steal_qdata(miniObject, g_quark_from_static_string(webkitGstMapInfoQuarkString)));
-
-    if (!mapInfo)
-        return;
-
-    gst_buffer_unmap(buffer, mapInfo);
-    g_slice_free(GstMapInfo, mapInfo);
-}
-
 bool initializeGStreamer()
 {
 #if GST_CHECK_VERSION(0, 10, 31)
diff --git a/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.h b/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.h
index 907d132..68df7b9 100644
--- a/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.h
+++ b/Source/WebCore/platform/graphics/gstreamer/GStreamerUtilities.h
@@ -16,11 +16,6 @@
  *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
  */
 
-#include "Logging.h"
-
-#include <gst/gst.h>
-#include <gst/video/video.h>
-
 #define LOG_MEDIA_MESSAGE(...) do { \
     GST_DEBUG(__VA_ARGS__); \
     LOG_VERBOSE(Media, __VA_ARGS__); } while (0)
@@ -33,44 +28,7 @@
     GST_INFO(__VA_ARGS__); \
     LOG_VERBOSE(Media, __VA_ARGS__); } while (0)
 
-#define WARN_MEDIA_MESSAGE(...) do { \
-    GST_WARNING(__VA_ARGS__); \
-    LOG_VERBOSE(Media, __VA_ARGS__); } while (0)
-
 namespace WebCore {
-
-class IntSize;
-
-inline bool webkitGstCheckVersion(guint major, guint minor, guint micro)
-{
-    guint currentMajor, currentMinor, currentMicro, currentNano;
-    gst_version(&currentMajor, &currentMinor, &currentMicro, &currentNano);
-
-    if (currentMajor < major)
-        return false;
-    if (currentMajor > major)
-        return true;
-
-    if (currentMinor < minor)
-        return false;
-    if (currentMinor > minor)
-        return true;
-
-    if (currentMicro < micro)
-        return false;
-
-    return true;
-}
-
-GstPad* webkitGstGhostPadFromStaticTemplate(GstStaticPadTemplate*, const gchar* name, GstPad* target);
-#if ENABLE(VIDEO)
-bool getVideoSizeAndFormatFromCaps(GstCaps*, WebCore::IntSize&, GstVideoFormat&, int& pixelAspectRatioNumerator, int& pixelAspectRatioDenominator, int& stride);
-#endif
-GstBuffer* createGstBuffer(GstBuffer*);
-GstBuffer* createGstBufferForData(const char* data, int length);
-char* getGstBufferDataPointer(GstBuffer*);
-void mapGstBuffer(GstBuffer*);
-void unmapGstBuffer(GstBuffer*);
 bool initializeGStreamer();
 unsigned getGstPlaysFlag(const char* nick);
 }

From 7951f542b9d555ba096adb77622eb133517bc040 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 14 Nov 2014 14:47:11 +0100
Subject: [PATCH 30/68] Use the helper functions from GStreamerVersioning
 instead of Utilities.

---
 .../platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp    | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
index ddd2940..02fdc2f 100644
--- a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
@@ -24,7 +24,7 @@
 #if ENABLE(VIDEO) && ENABLE(MEDIA_SOURCE) && USE(GSTREAMER)
 
 #include "GRefPtrGStreamer.h"
-#include "GStreamerUtilities.h"
+#include "GStreamerVersioning.h"
 #include "NotImplemented.h"
 #include "TimeRanges.h"
 #include <gst/app/gstappsrc.h>
@@ -149,7 +149,7 @@ static void webKitMediaSrcAddSrc(WebKitMediaSrc* src, GstElement* element)
     gst_element_sync_state_with_parent(element);
     GOwnPtr<gchar> name;
     name.set(g_strdup_printf("src_%u", priv->nbSource));
-    ghostPad = WebCore::webkitGstGhostPadFromStaticTemplate(&srcTemplate, name.get(), targetsrc.get());
+    ghostPad = webkitGstGhostPadFromStaticTemplate(&srcTemplate, name.get(), targetsrc.get());
     gst_pad_set_active(ghostPad, TRUE);
 
     priv->nbSource++;
@@ -725,7 +725,7 @@ void MediaSourceClientGstreamer::didReceiveData(const char* data, int length, St
             priv->sourceVideo.padAdded = TRUE;
         }
         GST_OBJECT_LOCK(m_src);
-        buffer = WebCore::createGstBufferForData(data, length);
+        buffer = createGstBufferForData(data, length);
         GST_OBJECT_UNLOCK(m_src);
 
         ret = gst_app_src_push_buffer(GST_APP_SRC(priv->sourceVideo.appsrc), buffer);
@@ -739,7 +739,7 @@ void MediaSourceClientGstreamer::didReceiveData(const char* data, int length, St
             priv->sourceAudio.padAdded = TRUE;
         }
         GST_OBJECT_LOCK(m_src);
-        buffer = WebCore::createGstBufferForData(data, length);
+        buffer = createGstBufferForData(data, length);
         GST_OBJECT_UNLOCK(m_src);
 
         ret = gst_app_src_push_buffer(GST_APP_SRC(priv->sourceAudio.appsrc), buffer);

From 442a69d66970c491a0c03d4d5da71b9276a75bf6 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 14:28:14 +0100
Subject: [PATCH 31/68] There is no member m_id anymore

---
 Source/WebCore/html/track/AudioTrack.cpp | 1 -
 1 file changed, 1 deletion(-)

diff --git a/Source/WebCore/html/track/AudioTrack.cpp b/Source/WebCore/html/track/AudioTrack.cpp
index 6ee8e31..aac2aa1 100644
--- a/Source/WebCore/html/track/AudioTrack.cpp
+++ b/Source/WebCore/html/track/AudioTrack.cpp
@@ -81,7 +81,6 @@ const AtomicString& AudioTrack::commentaryKeyword()
 
 AudioTrack::AudioTrack(AudioTrackClient* client, PassRefPtr<AudioTrackPrivate> trackPrivate)
     : TrackBase(TrackBase::AudioTrack, trackPrivate->id(), trackPrivate->label(), trackPrivate->language())
-    , m_id(trackPrivate->id())
     , m_enabled(trackPrivate->enabled())
     , m_client(client)
     , m_private(trackPrivate)

From 457efed00b48aea934a5f8dd9764c419c76f2a44 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 14:48:39 +0100
Subject: [PATCH 32/68] Fix more errors

---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp |  3 ++-
 Source/WebCore/Modules/mediasource/SourceBuffer.h   | 15 ++++++++++-----
 2 files changed, 12 insertions(+), 6 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index 49a138a..b42300c 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -934,6 +934,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         ASSERT(segment.textTracks.size() == textTracks()->length());
         Vector<InitializationSegment::TextTrackInformation>::const_iterator tend = segment.textTracks.end();
         for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != tend; ++it) {
+            const InitializationSegment::TextTrackInformation & textTrackInfo = *it;
             if (textTracks()->length() == 1) {
                 static_cast<InbandTextTrack>(*textTracks()->item(0)).setPrivate(textTrackInfo.track);
                 break;
@@ -1815,7 +1816,7 @@ void SourceBuffer::reportExtraMemoryCost()
 
     JSC::JSLockHolder lock(scriptExecutionContext()->vm());
     if (extraMemoryCostDelta > 0)
-        scriptExecutionContext()->vm().heap.reportExtraMemoryCost(extraMemoryCostDelta);
+        scriptExecutionContext()->vm()->heap.reportExtraMemoryCost(extraMemoryCostDelta);
 }
 
 Vector<String> SourceBuffer::bufferedSamplesForTrackID(const AtomicString& trackID)
diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.h b/Source/WebCore/Modules/mediasource/SourceBuffer.h
index 5a8bd02..91b496b 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.h
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.h
@@ -99,11 +99,14 @@ class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, pu
     bool active() const { return m_active; }
 
     // ActiveDOMObject interface
-    virtual bool hasPendingActivity();
-    virtual void stop();
+    virtual bool hasPendingActivity() const OVERRIDE;
+    virtual void stop() OVERRIDE;
 
     // EventTarget interface
-    virtual ScriptExecutionContext* scriptExecutionContext() { return ActiveDOMObject::scriptExecutionContext(); }
+    virtual const AtomicString& interfaceName() const; 
+    virtual ScriptExecutionContext* scriptExecutionContext() const OVERRIDE { return ActiveDOMObject::scriptExecutionContext(); }
+    virtual EventTargetData* eventTargetData() { return &m_eventTargetData; }
+    virtual EventTargetData* ensureEventTargetData() { return &m_eventTargetData; }
 
     using RefCounted<SourceBuffer>::ref;
     using RefCounted<SourceBuffer>::deref;
@@ -114,8 +117,8 @@ class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, pu
 
 protected:
     // EventTarget interface
-    virtual void refEventTarget() { ref(); }
-    virtual void derefEventTarget() { deref(); }
+    virtual void refEventTarget() OVERRIDE { ref(); }
+    virtual void derefEventTarget() OVERRIDE { deref(); }
 
 private:
     SourceBuffer(PassOwnPtr<SourceBufferPrivate>, PassRefPtr<MediaSource>);
@@ -216,6 +219,8 @@ class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, pu
     bool m_receivedFirstInitializationSegment;
     bool m_active;
     bool m_bufferFull;
+
+    EventTargetData m_eventTargetData;
 };
 
 } // namespace WebCore

From 2016978c0585763092fd261ce29e942a4de9e50b Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 16:33:26 +0100
Subject: [PATCH 33/68] Fix the iterators

---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp | 20 ++++++++++----------
 1 file changed, 10 insertions(+), 10 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index b42300c..c053ee1 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -313,8 +313,8 @@ void SourceBuffer::removedFromMediaSource()
 
     abortIfUpdating();
 
-    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
-    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
         TrackBuffer& trackBuffer = it->value;
         trackBuffer.samples.clear();
         trackBuffer.decodeQueue.clear();
@@ -344,8 +344,8 @@ MediaTime SourceBuffer::sourceBufferPrivateFastSeekTimeForMediaTime(SourceBuffer
     MediaTime lowerBoundTime = targetTime - negativeThreshold;
     MediaTime upperBoundTime = targetTime + positiveThreshold;
 
-    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
-    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
         TrackBuffer& trackBuffer = it->value;
         // Find the sample which contains the target time time.
         DecodeOrderSampleMap::iterator futureSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSampleAfterPresentationTime(targetTime, positiveThreshold);
@@ -945,8 +945,8 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
             static_cast<InbandTextTrack>(*textTrack).setPrivate(textTrackInfo.track);
         }
 
-        HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
-        for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+        HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
+        for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
             TrackBuffer& trackBuffer = it->value;
             trackBuffer.needRandomAccessFlag = true;
         }
@@ -1268,8 +1268,8 @@ void SourceBuffer::sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, Pas
             // Set group start timestamp equal to the highest presentation end timestamp.
             // FIXME: Add support for "sequence" mode.
 
-            HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
-            for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+            HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
+            for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
                 TrackBuffer& trackBuffer = it->value;
                 // 1.7.2 Unset the last decode timestamp on all track buffers.
                 trackBuffer.lastDecodeTimestamp = MediaTime::invalidTime();
@@ -1796,8 +1796,8 @@ bool SourceBuffer::canPlayThrough()
 size_t SourceBuffer::extraMemoryCost() const
 {
     size_t extraMemoryCost = m_pendingAppendData.capacity();
-    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.values().end();
-    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.values().begin(); it != end; ++it) {
+    HashMap<AtomicString, TrackBuffer>::const_iterator end = m_trackBufferMap.end();
+    for (HashMap<AtomicString, TrackBuffer>::const_iterator it = m_trackBufferMap.begin(); it != end; ++it) {
         TrackBuffer& trackBuffer = it->value;
         extraMemoryCost += trackBuffer.samples.sizeInBytes();
     }

From 3822d6b0006a5a96506c3075f4af944f32c36abb Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 17:04:00 +0100
Subject: [PATCH 34/68] Port more API from upstream

---
 Source/WebCore/html/track/TextTrack.cpp     |  4 ++--
 Source/WebCore/html/track/TextTrack.h       |  4 ++--
 Source/WebCore/html/track/TextTrackList.cpp | 18 +++++++++++++++++-
 Source/WebCore/html/track/TextTrackList.h   |  1 +
 4 files changed, 22 insertions(+), 5 deletions(-)

diff --git a/Source/WebCore/html/track/TextTrack.cpp b/Source/WebCore/html/track/TextTrack.cpp
index 8d667d7..af8535e 100644
--- a/Source/WebCore/html/track/TextTrack.cpp
+++ b/Source/WebCore/html/track/TextTrack.cpp
@@ -103,13 +103,13 @@ const AtomicString& TextTrack::showingKeyword()
 
 TextTrack* TextTrack::captionMenuOffItem()
 {
-    DEFINE_STATIC_LOCAL(RefPtr<TextTrack>, off, (TextTrack::create(0, 0, "off menu item", "", "")));
+    DEFINE_STATIC_LOCAL(RefPtr<TextTrack>, off, (TextTrack::create(0, 0, "off menu item", "", "", "")));
     return off.get();
 }
 
 TextTrack* TextTrack::captionMenuAutomaticItem()
 {
-    DEFINE_STATIC_LOCAL(RefPtr<TextTrack>, automatic, (TextTrack::create(0, 0, "automatic menu item", "", "")));
+    DEFINE_STATIC_LOCAL(RefPtr<TextTrack>, automatic, (TextTrack::create(0, 0, "automatic menu item" ,"",  "", "")));
     return automatic.get();
 }
 
diff --git a/Source/WebCore/html/track/TextTrack.h b/Source/WebCore/html/track/TextTrack.h
index 92db3fb..3ac8ec2 100644
--- a/Source/WebCore/html/track/TextTrack.h
+++ b/Source/WebCore/html/track/TextTrack.h
@@ -69,7 +69,7 @@ class TextTrack : public TrackBase, public EventTarget
 public:
     static PassRefPtr<TextTrack> create(ScriptExecutionContext* context, TextTrackClient* client, const AtomicString& kind, const AtomicString& id, const AtomicString& label, const AtomicString& language)
     {
-        return adoptRef(new TextTrack(context, client, kind, label, language, AddTrack));
+        return adoptRef(new TextTrack(context, client, kind, id, label, language, AddTrack));
     }
     virtual ~TextTrack();
 
@@ -156,7 +156,7 @@ class TextTrack : public TrackBase, public EventTarget
     using RefCounted<TrackBase>::deref;
 
 protected:
-    TextTrack(ScriptExecutionContext*, TextTrackClient*, const AtomicString& kind, const AtomicString& label, const AtomicString& language, TextTrackType);
+    TextTrack(ScriptExecutionContext*, TextTrackClient*, const AtomicString& kind, const AtomicString& id, const AtomicString& label, const AtomicString& language, TextTrackType);
 #if ENABLE(VIDEO_TRACK) && ENABLE(WEBVTT_REGIONS)
     TextTrackRegionList* regionList();
 #endif
diff --git a/Source/WebCore/html/track/TextTrackList.cpp b/Source/WebCore/html/track/TextTrackList.cpp
index 2e9d909..631292e 100644
--- a/Source/WebCore/html/track/TextTrackList.cpp
+++ b/Source/WebCore/html/track/TextTrackList.cpp
@@ -105,7 +105,7 @@ int TextTrackList::getTrackIndexRelativeToRenderedTracks(TextTrack *textTrack)
     return -1;
 }
 
-TextTrack* TextTrackList::item(unsigned index)
+TextTrack* TextTrackList::item(unsigned index) const
 {
     // 4.8.10.12.1 Text track model
     // The text tracks are sorted as follows:
@@ -128,6 +128,22 @@ TextTrack* TextTrackList::item(unsigned index)
     return 0;
 }
 
+TextTrack* TextTrackList::getTrackById(const AtomicString& id)
+{
+    // 4.8.10.12.5 Text track API
+    // The getTrackById(id) method must return the first TextTrack in the
+    // TextTrackList object whose id IDL attribute would return a value equal
+    // to the value of the id argument.
+    for (unsigned i = 0; i < length(); ++i) {
+        TextTrack* track = item(i);
+        if (track->id() == id)
+            return track;
+    }
+
+    // When no tracks match the given argument, the method must return null.
+    return 0;
+}
+
 void TextTrackList::invalidateTrackIndexesAfterTrack(TextTrack* track)
 {
     Vector<RefPtr<TrackBase> >* tracks = 0;
diff --git a/Source/WebCore/html/track/TextTrackList.h b/Source/WebCore/html/track/TextTrackList.h
index bf1ba75..ad6c2b4 100644
--- a/Source/WebCore/html/track/TextTrackList.h
+++ b/Source/WebCore/html/track/TextTrackList.h
@@ -48,6 +48,7 @@ class TextTrackList : public TrackListBase {
     virtual bool contains(TrackBase*) const OVERRIDE;
 
     TextTrack* item(unsigned index) const;
+    TextTrack* getTrackById(const AtomicString&);
     TextTrack* lastItem() const { return item(length() - 1); }
     void append(PassRefPtr<TextTrack>);
     virtual void remove(TrackBase*) OVERRIDE;

From 1d87dacd7db4e032720744fc5895f4ae178748c4 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 17:04:19 +0100
Subject: [PATCH 35/68] Fix more consts

---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp | 12 ++++++------
 1 file changed, 6 insertions(+), 6 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index c053ee1..b294e33 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -663,7 +663,7 @@ void SourceBuffer::removeCodedFrames(const MediaTime& start, const MediaTime& en
         }
 
         erasedRanges->invert();
-        m_buffered->intersectWith(*erasedRanges);
+        m_buffered->intersectWith(erasedRanges);
 
         // 3.4 If this object is in activeSourceBuffers, the current playback position is greater than or equal to start
         // and less than the remove end timestamp, and HTMLMediaElement.readyState is greater than HAVE_METADATA, then set
@@ -904,7 +904,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         ASSERT(segment.audioTracks.size() == audioTracks()->length());
         Vector<InitializationSegment::AudioTrackInformation>::const_iterator aend = segment.audioTracks.end();
         for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != aend; ++it) {
-            InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
+            const InitializationSegment::AudioTrackInformation& audioTrackInfo = *it;
 
             if (audioTracks()->length() == 1) {
                 audioTracks()->item(0)->setPrivate(audioTrackInfo.track);
@@ -920,7 +920,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         ASSERT(segment.videoTracks.size() == videoTracks()->length());
         Vector<InitializationSegment::VideoTrackInformation>::const_iterator vend = segment.videoTracks.end();
         for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
-            InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
+            const InitializationSegment::VideoTrackInformation& videoTrackInfo = *it;
             if (videoTracks()->length() == 1) {
                 videoTracks()->item(0)->setPrivate(videoTrackInfo.track);
                 break;
@@ -934,7 +934,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         ASSERT(segment.textTracks.size() == textTracks()->length());
         Vector<InitializationSegment::TextTrackInformation>::const_iterator tend = segment.textTracks.end();
         for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != tend; ++it) {
-            const InitializationSegment::TextTrackInformation & textTrackInfo = *it;
+            const InitializationSegment::TextTrackInformation &textTrackInfo = *it;
             if (textTracks()->length() == 1) {
                 static_cast<InbandTextTrack>(*textTracks()->item(0)).setPrivate(textTrackInfo.track);
                 break;
@@ -1417,7 +1417,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, Pas
             }
 
             erasedRanges->invert();
-            m_buffered->intersectWith(*erasedRanges);
+            m_buffered->intersectWith(erasedRanges);
         }
 
         // 1.17 If spliced audio frame is set:
@@ -1798,7 +1798,7 @@ size_t SourceBuffer::extraMemoryCost() const
     size_t extraMemoryCost = m_pendingAppendData.capacity();
     HashMap<AtomicString, TrackBuffer>::const_iterator end = m_trackBufferMap.end();
     for (HashMap<AtomicString, TrackBuffer>::const_iterator it = m_trackBufferMap.begin(); it != end; ++it) {
-        TrackBuffer& trackBuffer = it->value;
+        const TrackBuffer& trackBuffer = it->value;
         extraMemoryCost += trackBuffer.samples.sizeInBytes();
     }
 

From b7a960397aa2f793439f42abb3df4aa807a6bc47 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 17:21:55 +0100
Subject: [PATCH 36/68] Add the id on the InbandTextTrack class

---
 Source/WebCore/html/track/InbandTextTrack.cpp             | 2 +-
 Source/WebCore/platform/graphics/InbandTextTrackPrivate.h | 1 +
 2 files changed, 2 insertions(+), 1 deletion(-)

diff --git a/Source/WebCore/html/track/InbandTextTrack.cpp b/Source/WebCore/html/track/InbandTextTrack.cpp
index 0d5cf82..7172f66 100644
--- a/Source/WebCore/html/track/InbandTextTrack.cpp
+++ b/Source/WebCore/html/track/InbandTextTrack.cpp
@@ -193,7 +193,7 @@ PassRefPtr<InbandTextTrack> InbandTextTrack::create(ScriptExecutionContext* cont
 }
 
 InbandTextTrack::InbandTextTrack(ScriptExecutionContext* context, TextTrackClient* client, PassRefPtr<InbandTextTrackPrivate> tracksPrivate)
-    : TextTrack(context, client, emptyString(), tracksPrivate->label(), tracksPrivate->language(), InBand)
+    : TextTrack(context, client, emptyString(), tracksPrivate->id(), tracksPrivate->label(), tracksPrivate->language(), InBand)
     , m_private(tracksPrivate)
 {
     m_private->setClient(this);
diff --git a/Source/WebCore/platform/graphics/InbandTextTrackPrivate.h b/Source/WebCore/platform/graphics/InbandTextTrackPrivate.h
index 91066ea..ae1e2c0 100644
--- a/Source/WebCore/platform/graphics/InbandTextTrackPrivate.h
+++ b/Source/WebCore/platform/graphics/InbandTextTrackPrivate.h
@@ -74,6 +74,7 @@ class InbandTextTrackPrivate : public RefCounted<InbandTextTrackPrivate> {
 
     virtual AtomicString label() const { return emptyAtom; }
     virtual AtomicString language() const { return emptyAtom; }
+    virtual AtomicString id() const { return emptyAtom; }
     virtual bool isDefault() const { return false; }
 
     virtual int textTrackIndex() const { return 0; }

From 06583f037f09ed2c4823f4248872e51d604c8dbc Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 17:53:20 +0100
Subject: [PATCH 37/68] Workaround for varadic templates

The NeverDestroyed uses the variadic template feature.
On our build system it is not enabled so we must use a single
argument constructor
---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp | 8 +++++---
 1 file changed, 5 insertions(+), 3 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index b294e33..77cfa3a 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -66,7 +66,9 @@ static double ExponentialMovingAverageCoefficient = 0.1;
 // Allow hasCurrentTime() to be off by as much as the length of a 24fps video frame
 static const MediaTime& currentTimeFudgeFactor()
 {
-    static NeverDestroyed<MediaTime> fudgeFactor(1, 24);
+    // Given that we can nt use the variadic on templates, use the default constructor
+    // which uses a 6000 scale, so 1/24 = 250/6000
+    static NeverDestroyed<MediaTime> fudgeFactor(250);
     return fudgeFactor;
 }
 
@@ -807,13 +809,13 @@ size_t SourceBuffer::maximumBufferSize() const
 
 const AtomicString& SourceBuffer::decodeError()
 {
-    static NeverDestroyed<AtomicString> decode("decode", AtomicString::ConstructFromLiteral);
+    static NeverDestroyed<AtomicString> decode("decode");
     return decode;
 }
 
 const AtomicString& SourceBuffer::networkError()
 {
-    static NeverDestroyed<AtomicString> network("network", AtomicString::ConstructFromLiteral);
+    static NeverDestroyed<AtomicString> network("network");
     return network;
 }
 

From fc76dab3b7cd5d725f66533a693c3f964aa474fc Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 18:46:30 +0100
Subject: [PATCH 38/68] Correctly get the the raw pointer

There was a typo too
---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index 77cfa3a..3fa3359 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -665,7 +665,7 @@ void SourceBuffer::removeCodedFrames(const MediaTime& start, const MediaTime& en
         }
 
         erasedRanges->invert();
-        m_buffered->intersectWith(erasedRanges);
+        m_buffered->intersectWith(erasedRanges.get());
 
         // 3.4 If this object is in activeSourceBuffers, the current playback position is greater than or equal to start
         // and less than the remove end timestamp, and HTMLMediaElement.readyState is greater than HAVE_METADATA, then set
@@ -860,7 +860,7 @@ void SourceBuffer::setActive(bool active)
     m_active = active;
     m_private->setActive(active);
     if (!isRemoved())
-        m_source->sourceBufferDidChangeAcitveState(this, active);
+        m_source->sourceBufferDidChangeActiveState(this, active);
 }
 
 void SourceBuffer::sourceBufferPrivateDidEndStream(SourceBufferPrivate*, const WTF::AtomicString& error)
@@ -1419,7 +1419,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, Pas
             }
 
             erasedRanges->invert();
-            m_buffered->intersectWith(erasedRanges);
+            m_buffered->intersectWith(erasedRanges.get());
         }
 
         // 1.17 If spliced audio frame is set:

From 0b6af08a7fc55aa32d48dbd14e54667d97e2a21c Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 18:48:03 +0100
Subject: [PATCH 39/68] Add missing counter

---
 Source/WebCore/html/track/TrackBase.cpp | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/Source/WebCore/html/track/TrackBase.cpp b/Source/WebCore/html/track/TrackBase.cpp
index 7f06584..f17f3c6 100644
--- a/Source/WebCore/html/track/TrackBase.cpp
+++ b/Source/WebCore/html/track/TrackBase.cpp
@@ -32,6 +32,8 @@
 
 namespace WebCore {
 
+static int s_uniqueId = 0;
+
 TrackBase::TrackBase(Type type, const AtomicString& id, const AtomicString& label, const AtomicString& language)
     : m_mediaElement(0)
 #if ENABLE(MEDIA_SOURCE)

From 3fb8ff1db1def93c0db1b5dd7396f0e3c11421a2 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 18:48:20 +0100
Subject: [PATCH 40/68] Use parents unique id

---
 Source/WebCore/html/track/TextTrack.cpp | 4 +---
 1 file changed, 1 insertion(+), 3 deletions(-)

diff --git a/Source/WebCore/html/track/TextTrack.cpp b/Source/WebCore/html/track/TextTrack.cpp
index af8535e..40d84d5 100644
--- a/Source/WebCore/html/track/TextTrack.cpp
+++ b/Source/WebCore/html/track/TextTrack.cpp
@@ -532,8 +532,6 @@ bool TextTrack::hasCue(TextTrackCue* cue, TextTrackCue::CueMatchRules match)
 #if USE(PLATFORM_TEXT_TRACK_MENU)
 PassRefPtr<PlatformTextTrack> TextTrack::platformTextTrack()
 {
-    static int uniqueId = 0;
-
     if (m_platformTextTrack)
         return m_platformTextTrack;
 
@@ -559,7 +557,7 @@ PassRefPtr<PlatformTextTrack> TextTrack::platformTextTrack()
     else if (m_trackType == InBand)
         type = PlatformTextTrack::InBand;
 
-    m_platformTextTrack = PlatformTextTrack::create(this, label(), language(), platformKind, type, ++uniqueId);
+    m_platformTextTrack = PlatformTextTrack::create(this, label(), language(), platformKind, type, uniqueId());
 
     return m_platformTextTrack;
 }

From 43eb486ff29ff88b26029e82928a910d07759990 Mon Sep 17 00:00:00 2001
From: Jorge Zapata <jorgeluis.zapata@gmail.com>
Date: Fri, 14 Nov 2014 18:50:21 +0100
Subject: [PATCH 41/68] Use release instead of releaseNonNull

---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index 3fa3359..9e9ead3 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -102,7 +102,7 @@ PassRefPtr<SourceBuffer> SourceBuffer::create(PassRefPtr<SourceBufferPrivate> so
 {
     RefPtr<SourceBuffer> sourceBuffer(adoptRef(new SourceBuffer(WTF::move(sourceBufferPrivate), source)));
     sourceBuffer->suspendIfNeeded();
-    return sourceBuffer.releaseNonNull();
+    return sourceBuffer.release();
 }
 
 SourceBuffer::SourceBuffer(PassRefPtr<SourceBufferPrivate> sourceBufferPrivate, PassRefPtr<MediaSource> source)

From fcd08d397465d4b0c011f2e0dbb2df0a052592e8 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 14 Nov 2014 17:56:57 +0100
Subject: [PATCH 42/68] Simplify code and use WebKit provided functions to
 proxy to Main thread.

---
 .../gstreamer/WebKitMediaSourceGStreamer.cpp       | 250 +++++----------------
 1 file changed, 55 insertions(+), 195 deletions(-)

diff --git a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
index 02fdc2f..3303e00 100644
--- a/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp
@@ -32,10 +32,16 @@
 #include <gst/pbutils/missing-plugins.h>
 #include <wtf/gobject/GOwnPtr.h>
 #include <wtf/text/CString.h>
+#include <wtf/MainThread.h>
+
+struct MainThreadAppSrcCallbackInfo {
+    MainThreadAppSrcCallbackInfo(WebKitMediaSrc* src, GstElement* appsrc) : src(src), appsrc(appsrc) { }
+    WebKitMediaSrc* src;
+    GstElement* appsrc;
+};
 
 typedef struct _Source {
     GstElement* appsrc;
-    guint sourceid;        /* To control the GSource */
     GstPad* srcpad;
     gboolean padAdded;
 
@@ -81,24 +87,16 @@ static void webKitMediaSrcGetProperty(GObject*, guint propertyId, GValue*, GPara
 static GstStateChangeReturn webKitMediaSrcChangeState(GstElement*, GstStateChange);
 static gboolean webKitMediaSrcQueryWithParent(GstPad*, GstObject*, GstQuery*);
 
-static void webKitMediaVideoSrcNeedDataCb(GstAppSrc*, guint, gpointer);
-static void webKitMediaVideoSrcEnoughDataCb(GstAppSrc*, gpointer);
-static gboolean webKitMediaVideoSrcSeekDataCb(GstAppSrc*, guint64, gpointer);
-static void webKitMediaAudioSrcNeedDataCb(GstAppSrc*, guint, gpointer);
-static void webKitMediaAudioSrcEnoughDataCb(GstAppSrc*, gpointer);
-static gboolean webKitMediaAudioSrcSeekDataCb(GstAppSrc*, guint64, gpointer);
-static GstAppSrcCallbacks appsrcCallbacksVideo = {
-    webKitMediaVideoSrcNeedDataCb,
-    webKitMediaVideoSrcEnoughDataCb,
-    webKitMediaVideoSrcSeekDataCb,
-    { 0 }
-};
-static GstAppSrcCallbacks appsrcCallbacksAudio = {
-    webKitMediaAudioSrcNeedDataCb,
-    webKitMediaAudioSrcEnoughDataCb,
-    webKitMediaAudioSrcSeekDataCb,
+static void webKitMediaAppSrcNeedDataCb(GstAppSrc*, guint, gpointer);
+static void webKitMediaAppSrcEnoughDataCb(GstAppSrc*, gpointer);
+static gboolean webKitMediaAppSrcSeekDataCb(GstAppSrc*, guint64, gpointer);
+static GstAppSrcCallbacks appsrcCallbacks = {
+    webKitMediaAppSrcNeedDataCb,
+    webKitMediaAppSrcEnoughDataCb,
+    webKitMediaAppSrcSeekDataCb,
     { 0 }
 };
+
 #define webkit_media_src_parent_class parent_class
 // We split this out into another macro to avoid a check-webkit-style error.
 #define WEBKIT_MEDIA_SRC_CATEGORY_INIT GST_DEBUG_CATEGORY_INIT(webkit_media_src_debug, "webkitmediasrc", 0, "websrc element");
@@ -170,11 +168,11 @@ static void webkit_media_src_init(WebKitMediaSrc* src)
     new (priv) WebKitMediaSrcPrivate();
 
     priv->sourceVideo.appsrc = gst_element_factory_make("appsrc", "videoappsrc");
-    gst_app_src_set_callbacks(GST_APP_SRC(priv->sourceVideo.appsrc), &appsrcCallbacksVideo, src, 0);
+    gst_app_src_set_callbacks(GST_APP_SRC(priv->sourceVideo.appsrc), &appsrcCallbacks, src, 0);
     webKitMediaSrcAddSrc(src, priv->sourceVideo.appsrc);
 
     priv->sourceAudio.appsrc = gst_element_factory_make("appsrc", "audioappsrc");
-    gst_app_src_set_callbacks(GST_APP_SRC(priv->sourceAudio.appsrc), &appsrcCallbacksAudio, src, 0);
+    gst_app_src_set_callbacks(GST_APP_SRC(priv->sourceAudio.appsrc), &appsrcCallbacks, src, 0);
     webKitMediaSrcAddSrc(src, priv->sourceAudio.appsrc);
 }
 
@@ -223,21 +221,13 @@ static void webKitMediaSrcGetProperty(GObject* object, guint propId, GValue* val
 static void webKitMediaVideoSrcStop(WebKitMediaSrc* src)
 {
     WebKitMediaSrcPrivate* priv = src->priv;
-    gboolean seeking;
+    gboolean seeking = FALSE;
 
     GST_OBJECT_LOCK(src);
 
-    //seeking = priv->sourceVideo.seek.isActive();
-
-    //priv->sourceVideo.start.cancel();
-
     priv->player = 0;
     priv->playbin = 0;
 
-    //priv->sourceVideo.needData.cancel();
-    //priv->sourceVideo.enoughData.cancel();
-    //priv->sourceVideo.seek.cancel();
-
     priv->sourceVideo.paused = FALSE;
     priv->sourceVideo.offset = 0;
     priv->seekable = FALSE;
@@ -259,22 +249,14 @@ static void webKitMediaVideoSrcStop(WebKitMediaSrc* src)
 static void webKitMediaAudioSrcStop(WebKitMediaSrc* src)
 {
     WebKitMediaSrcPrivate* priv = src->priv;
-    gboolean seeking;
+    gboolean seeking = FALSE;
 
     GST_OBJECT_LOCK(src);
 
-    //seeking = priv->sourceAudio.seek.isActive();
-
-    //priv->sourceAudio.start.cancel();
-
     priv->player = 0;
 
     priv->playbin = 0;
 
-    //priv->sourceAudio.needData.cancel();
-    //priv->sourceAudio.enoughData.cancel();
-    //priv->sourceAudio.seek.cancel();
-
     priv->sourceAudio.paused = FALSE;
 
     priv->sourceAudio.offset = 0;
@@ -485,140 +467,66 @@ static void webKitMediaSrcUriHandlerInit(gpointer gIface, gpointer)
     iface->set_uri = webKitMediaSrcSetUri;
 }
 
-// appsrc callbacks
-static void webKitMediaVideoSrcNeedDataMainCb(WebKitMediaSrc* src)
-{
-    WebKitMediaSrcPrivate* priv = src->priv;
-
-    GST_OBJECT_LOCK(src);
-    priv->sourceVideo.paused = FALSE;
-    GST_OBJECT_UNLOCK(src);
-}
-
-static void webKitMediaAudioSrcNeedDataMainCb(WebKitMediaSrc* src)
+static Source* webKitMediaSrcGetSourceForAppSrc (WebKitMediaSrcPrivate* priv, GstElement* appSrc)
 {
-    WebKitMediaSrcPrivate* priv = src->priv;
-
-    GST_OBJECT_LOCK(src);
-    priv->sourceAudio.paused = FALSE;
-    GST_OBJECT_UNLOCK(src);
+  if (appSrc == priv->sourceVideo.appsrc) {
+    return &priv->sourceVideo;
+  } else if (appSrc == priv->sourceAudio.appsrc) {
+    return &priv->sourceAudio;
+  } else {
+    GST_WARNING_OBJECT (appSrc, "could not locate matching source");
+    return 0;
+  }
 }
 
-static void webKitMediaVideoSrcNeedDataCb(GstAppSrc*, guint length, gpointer userData)
+// appsrc callbacks
+static void webKitMediaAppSrcNeedDataMainCb(void* invocation)
 {
-    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
-    //WebKitMediaSrcPrivate* priv = src->priv;
-
-    GST_DEBUG_OBJECT(src, "Need more data: %u", length);
+    MainThreadAppSrcCallbackInfo* info = static_cast<MainThreadAppSrcCallbackInfo*>(invocation);
+    Source* source = webKitMediaSrcGetSourceForAppSrc (info->src->priv, info->appsrc);
 
-    GST_OBJECT_LOCK(src);
-    /*if (priv->sourceVideo.needData.isScheduled() || !priv->sourceVideo.paused) {
-        GST_OBJECT_UNLOCK(src);
-        return;
-    }
-
-    gst_object_ref(src);
-    priv->sourceVideo.needData.schedule("[WebKit] webKitMediaVideoSrcNeedDataMainCb", std::function<void()>(std::bind(webKitMediaVideoSrcNeedDataMainCb, src)), G_PRIORITY_DEFAULT,
-        [src] { gst_object_unref(src); });*/
-    GST_OBJECT_UNLOCK(src);
+    source->paused = FALSE;
 }
 
-static void webKitMediaAudioSrcNeedDataCb(GstAppSrc*, guint length, gpointer userData)
+static void webKitMediaAppSrcNeedDataCb(GstAppSrc* appsrc, guint length, gpointer userData)
 {
     WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
-    //WebKitMediaSrcPrivate* priv = src->priv;
 
     GST_DEBUG_OBJECT(src, "Need more data: %u", length);
 
-    GST_OBJECT_LOCK(src);
-    /*if (priv->sourceAudio.needData.isScheduled() || !priv->sourceAudio.paused) {
-        GST_OBJECT_UNLOCK(src);
-        return;
-    }
-
-    gst_object_ref(src);
-    priv->sourceAudio.needData.schedule("[WebKit] webKitMediaAudioSrcNeedDataMainCb", std::function<void()>(std::bind(webKitMediaAudioSrcNeedDataMainCb, src)), G_PRIORITY_DEFAULT,
-        [src] { gst_object_unref(src); });*/
-    GST_OBJECT_UNLOCK(src);
-}
-
-static void webKitMediaVideoSrcEnoughDataMainCb(WebKitMediaSrc* src)
-{
-    WebKitMediaSrcPrivate* priv = src->priv;
-
-    GST_OBJECT_LOCK(src);
-    priv->sourceVideo.paused = TRUE;
-    GST_OBJECT_UNLOCK(src);
+    MainThreadAppSrcCallbackInfo info(src, GST_ELEMENT_CAST (appsrc));
+    callOnMainThreadAndWait(webKitMediaAppSrcNeedDataMainCb, &info);
 }
 
-static void webKitMediaAudioSrcEnoughDataMainCb(WebKitMediaSrc* src)
+static void webKitMediaAppSrcEnoughDataMainCb(void* invocation)
 {
-    WebKitMediaSrcPrivate* priv = src->priv;
+    MainThreadAppSrcCallbackInfo* info = static_cast<MainThreadAppSrcCallbackInfo*>(invocation);
+    Source* source = webKitMediaSrcGetSourceForAppSrc (info->src->priv, info->appsrc);
 
-    GST_OBJECT_LOCK(src);
-    priv->sourceAudio.paused = TRUE;
-    GST_OBJECT_UNLOCK(src);
+    source->paused = TRUE;
 }
 
-static void webKitMediaVideoSrcEnoughDataCb(GstAppSrc*, gpointer userData)
+static void webKitMediaAppSrcEnoughDataCb(GstAppSrc* appsrc, gpointer userData)
 {
     WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
-    //WebKitMediaSrcPrivate* priv = src->priv;
 
     GST_DEBUG_OBJECT(src, "Have enough data");
 
-    GST_OBJECT_LOCK(src);
-    /*if (priv->sourceVideo.enoughData.isScheduled() || priv->sourceVideo.paused) {
-        GST_OBJECT_UNLOCK(src);
-        return;
-    }
-
-    gst_object_ref(src);
-    priv->sourceVideo.enoughData.schedule("[WebKit] webKitMediaVideoSrcEnoughDataMainCb", std::function<void()>(std::bind(webKitMediaVideoSrcEnoughDataMainCb, src)), G_PRIORITY_DEFAULT,
-        [src] { gst_object_unref(src); });*/
-
-    GST_OBJECT_UNLOCK(src);
+    MainThreadAppSrcCallbackInfo info(src, GST_ELEMENT_CAST (appsrc));
+    callOnMainThreadAndWait(webKitMediaAppSrcEnoughDataMainCb, &info);
 }
 
-static void webKitMediaAudioSrcEnoughDataCb(GstAppSrc*, gpointer userData)
-{
-    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
-    //WebKitMediaSrcPrivate* priv = src->priv;
-
-    GST_DEBUG_OBJECT(src, "Have enough data");
-
-    GST_OBJECT_LOCK(src);
-    /*if (priv->sourceAudio.enoughData.isScheduled() || priv->sourceAudio.paused) {
-        GST_OBJECT_UNLOCK(src);
-        return;
-    }
-
-    gst_object_ref(src);
-    priv->sourceAudio.enoughData.schedule("[WebKit] webKitMediaAudioSrcEnoughDataMainCb", std::function<void()>(std::bind(webKitMediaAudioSrcEnoughDataMainCb, src)), G_PRIORITY_DEFAULT,
-        [src] { gst_object_unref(src); });*/
-
-    GST_OBJECT_UNLOCK(src);
-}
-
-static void webKitMediaVideoSrcSeekMainCb(WebKitMediaSrc*)
-{
-    notImplemented();
-}
-
-
-static void webKitMediaAudioSrcSeekMainCb(WebKitMediaSrc*)
-{
-    notImplemented();
-}
-
-static gboolean webKitMediaVideoSrcSeekDataCb(GstAppSrc*, guint64 offset, gpointer userData)
+static gboolean webKitMediaAppSrcSeekDataCb(GstAppSrc* appsrc, guint64 offset, gpointer userData)
 {
     WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
     WebKitMediaSrcPrivate* priv = src->priv;
+    Source* source = webKitMediaSrcGetSourceForAppSrc (priv, GST_ELEMENT_CAST (appsrc));
 
     GST_DEBUG_OBJECT(src, "Seeking to offset: %" G_GUINT64_FORMAT, offset);
+    
     GST_OBJECT_LOCK(src);
-    if (offset == priv->sourceVideo.offset && priv->sourceVideo.requestedOffset == priv->sourceVideo.offset) {
+    
+    if (offset == source->offset && source->requestedOffset == source->offset) {
         GST_OBJECT_UNLOCK(src);
         return TRUE;
     }
@@ -627,50 +535,13 @@ static gboolean webKitMediaVideoSrcSeekDataCb(GstAppSrc*, guint64 offset, gpoint
         GST_OBJECT_UNLOCK(src);
         return FALSE;
     }
-    if (offset > priv->sourceVideo.size) {
+    if (offset > source->size) {
         GST_OBJECT_UNLOCK(src);
         return FALSE;
     }
 
     GST_DEBUG_OBJECT(src, "Doing range-request seek");
-    priv->sourceVideo.requestedOffset = offset;
-
-    /*gst_object_ref(src);
-    priv->sourceVideo.seek.schedule("[WebKit] webKitMediaVideoSrcSeekMainCb", std::function<void()>(std::bind(webKitMediaVideoSrcSeekMainCb, src)), G_PRIORITY_DEFAULT,
-        [src] { gst_object_unref(src); });*/
-
-    GST_OBJECT_UNLOCK(src);
-
-    return TRUE;
-}
-
-static gboolean webKitMediaAudioSrcSeekDataCb(GstAppSrc*, guint64 offset, gpointer userData)
-{
-    WebKitMediaSrc* src = WEBKIT_MEDIA_SRC(userData);
-    WebKitMediaSrcPrivate* priv = src->priv;
-
-    GST_DEBUG_OBJECT(src, "Seeking to offset: %" G_GUINT64_FORMAT, offset);
-    GST_OBJECT_LOCK(src);
-    if (offset == priv->sourceAudio.offset && priv->sourceAudio.requestedOffset == priv->sourceAudio.offset) {
-        GST_OBJECT_UNLOCK(src);
-        return TRUE;
-    }
-
-    if (!priv->seekable) {
-        GST_OBJECT_UNLOCK(src);
-        return FALSE;
-    }
-    if (offset > priv->sourceAudio.size) {
-        GST_OBJECT_UNLOCK(src);
-        return FALSE;
-    }
-
-    GST_DEBUG_OBJECT(src, "Doing range-request seek");
-    priv->sourceAudio.requestedOffset = offset;
-
-    /*gst_object_ref(src);
-    priv->sourceAudio.seek.schedule("[WebKit] webKitMediaAudioSrcSeekMainCb", std::function<void()>(std::bind(webKitMediaAudioSrcSeekMainCb, src)), G_PRIORITY_DEFAULT,
-        [src] { gst_object_unref(src); });*/
+    source->requestedOffset = offset;
 
     GST_OBJECT_UNLOCK(src);
 
@@ -689,6 +560,8 @@ void webKitMediaSrcSetPlayBin(WebKitMediaSrc* src, GstElement* playBin)
     priv->playbin = playBin;
 }
 
+// MediaSourceClient receives notifications from MediaSource
+
 MediaSourceClientGstreamer::MediaSourceClientGstreamer(WebKitMediaSrc* src)
     : m_src(static_cast<WebKitMediaSrc*>(gst_object_ref(src)))
 {
@@ -751,23 +624,10 @@ void MediaSourceClientGstreamer::didReceiveData(const char* data, int length, St
 
 void MediaSourceClientGstreamer::didFinishLoading(double)
 {
-    //WebKitMediaSrcPrivate* priv = m_src->priv;
-
     GST_DEBUG_OBJECT(m_src, "Have EOS");
-
-    GST_OBJECT_LOCK(m_src);
-/*    if (!priv->sourceVideo.seek.isActive()) {
-        GST_OBJECT_UNLOCK(m_src);
-        gst_app_src_end_of_stream(GST_APP_SRC(priv->sourceVideo.appsrc));
-    } else*/
-        GST_OBJECT_UNLOCK(m_src);
-
-    GST_OBJECT_LOCK(m_src);
-    /*if (!priv->sourceAudio.seek.isActive()) {
-        GST_OBJECT_UNLOCK(m_src);
-        gst_app_src_end_of_stream(GST_APP_SRC(priv->sourceAudio.appsrc));
-    } else*/
-        GST_OBJECT_UNLOCK(m_src);
+    
+    gst_app_src_end_of_stream(GST_APP_SRC(m_src->priv->sourceVideo.appsrc));
+    gst_app_src_end_of_stream(GST_APP_SRC(m_src->priv->sourceAudio.appsrc));
 }
 
 void MediaSourceClientGstreamer::didFail()

From 1069407c5a95364cdb62fd00f70bdbb87f071eb6 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Mon, 17 Nov 2014 12:54:56 +0100
Subject: [PATCH 43/68] Add setPrivate API and expose protected API for derived
 classes.

---
 Source/WebCore/html/track/InbandTextTrack.cpp | 20 ++++++++++++++++++++
 Source/WebCore/html/track/InbandTextTrack.h   |  6 ++++++
 2 files changed, 26 insertions(+)

diff --git a/Source/WebCore/html/track/InbandTextTrack.cpp b/Source/WebCore/html/track/InbandTextTrack.cpp
index 7172f66..b395a50 100644
--- a/Source/WebCore/html/track/InbandTextTrack.cpp
+++ b/Source/WebCore/html/track/InbandTextTrack.cpp
@@ -229,10 +229,30 @@ InbandTextTrack::~InbandTextTrack()
     m_private->setClient(0);
 }
 
+void InbandTextTrack::setPrivate(PassRefPtr<InbandTextTrackPrivate> trackPrivate)
+{
+    ASSERT(m_private);
+    ASSERT(trackPrivate);
+
+    if (m_private == trackPrivate)
+        return;
+
+    m_private->setClient(0);
+    m_private = trackPrivate;
+    m_private->setClient(this);
+
+    setModeInternal(mode());
+    updateKindFromPrivate();
+}
+
 void InbandTextTrack::setMode(const AtomicString& mode)
 {
     TextTrack::setMode(mode);
+    setModeInternal(mode);
+}
 
+void InbandTextTrack::setModeInternal(const AtomicString& mode)
+{
     if (mode == TextTrack::disabledKeyword())
         m_private->setMode(InbandTextTrackPrivate::Disabled);
     else if (mode == TextTrack::hiddenKeyword())
diff --git a/Source/WebCore/html/track/InbandTextTrack.h b/Source/WebCore/html/track/InbandTextTrack.h
index 51e38e0..6d80d43 100644
--- a/Source/WebCore/html/track/InbandTextTrack.h
+++ b/Source/WebCore/html/track/InbandTextTrack.h
@@ -82,6 +82,12 @@ class InbandTextTrack : public TextTrack, public InbandTextTrackPrivateClient {
     virtual void setMode(const AtomicString&) OVERRIDE;
     size_t inbandTrackIndex();
 
+    void setPrivate(PassRefPtr<InbandTextTrackPrivate>);
+
+protected:
+    void setModeInternal(const AtomicString&);
+    void updateKindFromPrivate();
+
 private:
     InbandTextTrack(ScriptExecutionContext*, TextTrackClient*, PassRefPtr<InbandTextTrackPrivate>);
 

From 1d960faa5df80ca542f40fc8d3458b00cdb7b272 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Mon, 17 Nov 2014 12:55:46 +0100
Subject: [PATCH 44/68] MediaSource load function now takes the content type as
 well.

---
 Source/WebCore/platform/graphics/MediaPlayer.cpp | 9 +++++----
 Source/WebCore/platform/graphics/MediaPlayer.h   | 2 +-
 2 files changed, 6 insertions(+), 5 deletions(-)

diff --git a/Source/WebCore/platform/graphics/MediaPlayer.cpp b/Source/WebCore/platform/graphics/MediaPlayer.cpp
index 9d30ad1..e978a75 100644
--- a/Source/WebCore/platform/graphics/MediaPlayer.cpp
+++ b/Source/WebCore/platform/graphics/MediaPlayer.cpp
@@ -93,7 +93,7 @@ class NullMediaPlayerPrivate : public MediaPlayerPrivateInterface {
 
     virtual void load(const String&) { }
 #if ENABLE(MEDIA_SOURCE)
-    virtual void load(const String&, PassRefPtr<MediaSource>) { }
+    virtual void load(const String&, MediaSourcePrivateClient*) { }
 #endif
     virtual void cancelLoad() { }
 
@@ -396,11 +396,12 @@ bool MediaPlayer::load(const KURL& url, const ContentType& contentType, const St
 }
 
 #if ENABLE(MEDIA_SOURCE)
-bool MediaPlayer::load(const KURL& url, PassRefPtr<MediaSource> mediaSource)
+bool MediaPlayer::load(const KURL& url, const ContentType& contentType, MediaSourcePrivateClient* mediaSource)
 {
+    ASSERT(mediaSource);
     m_mediaSource = mediaSource;
-    m_contentMIMEType = "";
-    m_contentTypeCodecs = "";
+    m_contentMIMEType = contentType.type().lower();
+    m_contentTypeCodecs = contentType.parameter(codecs());
     m_url = url;
     m_keySystem = "";
     m_contentMIMETypeWasInferredFromExtension = false;
diff --git a/Source/WebCore/platform/graphics/MediaPlayer.h b/Source/WebCore/platform/graphics/MediaPlayer.h
index 011aa18..aa96b02 100644
--- a/Source/WebCore/platform/graphics/MediaPlayer.h
+++ b/Source/WebCore/platform/graphics/MediaPlayer.h
@@ -281,7 +281,7 @@ class MediaPlayer {
 
     bool load(const KURL&, const ContentType&, const String& keySystem);
 #if ENABLE(MEDIA_SOURCE)
-    bool load(const KURL&, PassRefPtr<MediaSource>);
+    bool load(const KURL&, const ContentType&, MediaSourcePrivateClient*);
 #endif
     void cancelLoad();
 

From 3ad115a68f086ad90f70697980b91fddde448c36 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Mon, 17 Nov 2014 12:56:37 +0100
Subject: [PATCH 45/68] Old C++ does not support the explicit keyword

---
 Source/WTF/wtf/MediaTime.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Source/WTF/wtf/MediaTime.h b/Source/WTF/wtf/MediaTime.h
index eb79415..c1734e5 100644
--- a/Source/WTF/wtf/MediaTime.h
+++ b/Source/WTF/wtf/MediaTime.h
@@ -72,7 +72,7 @@ class WTF_EXPORT_PRIVATE MediaTime {
     bool operator>=(const MediaTime& rhs) const;
     bool operator<=(const MediaTime& rhs) const;
     bool operator!() const;
-    explicit operator bool() const;
+    operator bool() const;
 
     typedef enum {
         LessThan = -1,

From e284e6ffa180e7de5a59aeb2005e50e12927fe66 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Mon, 17 Nov 2014 19:41:55 +0100
Subject: [PATCH 46/68] New API for derived classes.

---
 Source/WebCore/html/track/TrackBase.cpp | 5 +++++
 Source/WebCore/html/track/TrackBase.h   | 2 ++
 2 files changed, 7 insertions(+)

diff --git a/Source/WebCore/html/track/TrackBase.cpp b/Source/WebCore/html/track/TrackBase.cpp
index f17f3c6..ff0b6ca 100644
--- a/Source/WebCore/html/track/TrackBase.cpp
+++ b/Source/WebCore/html/track/TrackBase.cpp
@@ -59,6 +59,11 @@ Element* TrackBase::element()
 
 void TrackBase::setKind(const AtomicString& kind)
 {
+    setKindInternal(kind);
+}
+
+void TrackBase::setKindInternal(const AtomicString& kind)
+{
     String oldKind = m_kind;
 
     if (isValidKind(kind))
diff --git a/Source/WebCore/html/track/TrackBase.h b/Source/WebCore/html/track/TrackBase.h
index 2a07058..4eec4bf 100644
--- a/Source/WebCore/html/track/TrackBase.h
+++ b/Source/WebCore/html/track/TrackBase.h
@@ -77,6 +77,8 @@ class TrackBase : public RefCounted<TrackBase> {
     virtual bool isValidKind(const AtomicString&) const = 0;
     virtual const AtomicString& defaultKindKeyword() const = 0;
 
+    void setKindInternal(const AtomicString&);
+
     HTMLMediaElement* m_mediaElement;
 
 #if ENABLE(MEDIA_SOURCE)

From 48ff54e028d6bbabf00c546a2236ef0b20c3625d Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Mon, 17 Nov 2014 19:42:23 +0100
Subject: [PATCH 47/68] Properly initialize parent class with new id parameter.

---
 Source/WebCore/html/track/LoadableTextTrack.cpp | 9 ++++++++-
 Source/WebCore/html/track/LoadableTextTrack.h   | 2 ++
 2 files changed, 10 insertions(+), 1 deletion(-)

diff --git a/Source/WebCore/html/track/LoadableTextTrack.cpp b/Source/WebCore/html/track/LoadableTextTrack.cpp
index 623b4f0..5390a04 100644
--- a/Source/WebCore/html/track/LoadableTextTrack.cpp
+++ b/Source/WebCore/html/track/LoadableTextTrack.cpp
@@ -38,7 +38,7 @@
 namespace WebCore {
 
 LoadableTextTrack::LoadableTextTrack(HTMLTrackElement* track, const String& kind, const String& label, const String& language)
-    : TextTrack(track->document(), track, kind, label, language, TrackElement)
+    : TextTrack(track->document(), track, kind, emptyString(), label, language, TrackElement)
     , m_trackElement(track)
     , m_loadTimer(this, &LoadableTextTrack::loadTimerFired)
     , m_isDefault(false)
@@ -149,6 +149,13 @@ void LoadableTextTrack::newRegionsAvailable(TextTrackLoader* loader)
 }
 #endif
 
+AtomicString LoadableTextTrack::id() const
+{
+    if (m_trackElement)
+        return m_trackElement->getAttribute("id");
+    return emptyString();
+}
+
 size_t LoadableTextTrack::trackElementIndex()
 {
     ASSERT(m_trackElement);
diff --git a/Source/WebCore/html/track/LoadableTextTrack.h b/Source/WebCore/html/track/LoadableTextTrack.h
index 188ead1..83262c8 100644
--- a/Source/WebCore/html/track/LoadableTextTrack.h
+++ b/Source/WebCore/html/track/LoadableTextTrack.h
@@ -57,6 +57,8 @@ class LoadableTextTrack : public TextTrack, private TextTrackLoaderClient {
 
     virtual void clearClient();
 
+    virtual AtomicString id() const OVERRIDE;
+
     size_t trackElementIndex();
     HTMLTrackElement* trackElement() { return m_trackElement; }
     void setTrackElement(HTMLTrackElement*);

From d4c11c95a3d2b98168f5b6fdc27aeb6f72f1f6db Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Mon, 17 Nov 2014 19:45:05 +0100
Subject: [PATCH 48/68] New API to set kind and language, fix small errors.

---
 Source/WebCore/html/track/VideoTrack.cpp | 50 ++++++++++++++++++++++++++++++--
 Source/WebCore/html/track/VideoTrack.h   |  5 ++++
 2 files changed, 53 insertions(+), 2 deletions(-)

diff --git a/Source/WebCore/html/track/VideoTrack.cpp b/Source/WebCore/html/track/VideoTrack.cpp
index f9c73dd..92e8ccf 100644
--- a/Source/WebCore/html/track/VideoTrack.cpp
+++ b/Source/WebCore/html/track/VideoTrack.cpp
@@ -38,9 +38,12 @@
 #include "Event.h"
 #include "ExceptionCode.h"
 #include "HTMLMediaElement.h"
-#include "TrackBase.h"
 #include "VideoTrackList.h"
 
+#if ENABLE(MEDIA_SOURCE)
+#include "SourceBuffer.h"
+#endif
+
 namespace WebCore {
 
 const AtomicString& VideoTrack::alternativeKeyword()
@@ -102,7 +105,7 @@ void VideoTrack::setPrivate(PassRefPtr<VideoTrackPrivate> trackPrivate)
     if (m_private == trackPrivate)
         return;
 
-    m_private->setClient(nullptr);
+    m_private->setClient(0);
     m_private = trackPrivate;
     m_private->setClient(this);
 
@@ -152,6 +155,49 @@ void VideoTrack::willRemoveVideoTrackPrivate(VideoTrackPrivate* trackPrivate)
     mediaElement()->removeVideoTrack(this);
 }
 
+#if ENABLE(MEDIA_SOURCE)
+void VideoTrack::setKind(const AtomicString& kind)
+{
+    // 10.1 kind, on setting:
+    // 1. If the value being assigned to this attribute does not match one of the video track kinds,
+    // then abort these steps.
+    if (!isValidKind(kind))
+        return;
+
+    // 2. Update this attribute to the new value.
+    setKindInternal(kind);
+
+    // 3. If the sourceBuffer attribute on this track is not null, then queue a task to fire a simple
+    // event named change at sourceBuffer.videoTracks.
+    if (m_sourceBuffer)
+        m_sourceBuffer->videoTracks()->scheduleChangeEvent();
+
+    // 4. Queue a task to fire a simple event named change at the VideoTrackList object referenced by
+    // the videoTracks attribute on the HTMLMediaElement.
+    mediaElement()->videoTracks()->scheduleChangeEvent();
+}
+
+void VideoTrack::setLanguage(const AtomicString& language)
+{
+    // 10.1 language, on setting:
+    // 1. If the value being assigned to this attribute is not an empty string or a BCP 47 language
+    // tag[BCP47], then abort these steps.
+    // FIXME(123926): Validate the BCP47-ness of langague.
+
+    // 2. Update this attribute to the new value.
+    TrackBase::setLanguage(language);
+
+    // 3. If the sourceBuffer attribute on this track is not null, then queue a task to fire a simple
+    // event named change at sourceBuffer.videoTracks.
+    if (m_sourceBuffer)
+        m_sourceBuffer->videoTracks()->scheduleChangeEvent();
+
+    // 4. Queue a task to fire a simple event named change at the VideoTrackList object referenced by
+    // the videoTracks attribute on the HTMLMediaElement.
+    mediaElement()->videoTracks()->scheduleChangeEvent();
+}
+#endif
+
 void VideoTrack::updateKindFromPrivate()
 {
     switch (m_private->kind()) {
diff --git a/Source/WebCore/html/track/VideoTrack.h b/Source/WebCore/html/track/VideoTrack.h
index a38513b..f8bd391 100644
--- a/Source/WebCore/html/track/VideoTrack.h
+++ b/Source/WebCore/html/track/VideoTrack.h
@@ -70,6 +70,11 @@ class VideoTrack : public TrackBase, public VideoTrackPrivateClient {
 
     size_t inbandTrackIndex();
 
+#if ENABLE(MEDIA_SOURCE)
+    virtual void setKind(const AtomicString&) OVERRIDE;
+    virtual void setLanguage(const AtomicString&) OVERRIDE;
+#endif
+
     void setPrivate(PassRefPtr<VideoTrackPrivate>);
 
 protected:

From 365057bd88b355830929af09df267a4c65b33288 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Mon, 17 Nov 2014 19:46:22 +0100
Subject: [PATCH 49/68] Use PlatformTimeRanges and MediaSourcePrivate in the
 MediaPlayer infrastructure.

---
 Source/WebCore/platform/graphics/MediaPlayer.cpp         | 16 ++++++++--------
 Source/WebCore/platform/graphics/MediaPlayer.h           |  9 +++++----
 Source/WebCore/platform/graphics/MediaPlayerPrivate.h    | 11 ++++++-----
 .../graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp   |  4 ++--
 .../graphics/gstreamer/MediaPlayerPrivateGStreamer.h     |  2 +-
 Source/WebCore/platform/qt/RenderThemeQt.cpp             |  6 +++---
 6 files changed, 25 insertions(+), 23 deletions(-)

diff --git a/Source/WebCore/platform/graphics/MediaPlayer.cpp b/Source/WebCore/platform/graphics/MediaPlayer.cpp
index e978a75..991ceef 100644
--- a/Source/WebCore/platform/graphics/MediaPlayer.cpp
+++ b/Source/WebCore/platform/graphics/MediaPlayer.cpp
@@ -36,8 +36,8 @@
 #include "Logging.h"
 #include "MIMETypeRegistry.h"
 #include "MediaPlayerPrivate.h"
+#include "PlatformTimeRanges.h"
 #include "Settings.h"
-#include "TimeRanges.h"
 #include <wtf/text/CString.h>
 
 #if ENABLE(VIDEO_TRACK)
@@ -45,7 +45,7 @@
 #endif
 
 #if ENABLE(MEDIA_SOURCE)
-#include "MediaSource.h"
+#include "MediaSourcePrivateClient.h"
 #endif
 
 #if PLATFORM(QT)
@@ -136,7 +136,7 @@ class NullMediaPlayerPrivate : public MediaPlayerPrivateInterface {
 
     virtual double maxTimeSeekableDouble() const { return 0; }
     virtual double minTimeSeekable() const { return 0; }
-    virtual PassRefPtr<TimeRanges> buffered() const { return TimeRanges::create(); }
+    virtual PassOwnPtr<PlatformTimeRanges> buffered() const { return PlatformTimeRanges::create(); }
 
     virtual unsigned long long totalBytes() const { return 0; }
     virtual bool didLoadingProgress() const { return false; }
@@ -444,7 +444,7 @@ void MediaPlayer::loadWithNextMediaEngine(MediaPlayerFactory* current)
     if (m_private) {
 #if ENABLE(MEDIA_SOURCE)
         if (m_mediaSource)
-            m_private->load(m_url.string(), m_mediaSource);
+            m_private->load(m_url.string(), m_mediaSource.get ());
         else
 #endif
         m_private->load(m_url.string());
@@ -677,24 +677,24 @@ void MediaPlayer::setPreservesPitch(bool preservesPitch)
     m_private->setPreservesPitch(preservesPitch);
 }
 
-PassRefPtr<TimeRanges> MediaPlayer::buffered()
+PassOwnPtr<PlatformTimeRanges> MediaPlayer::buffered()
 {
     return m_private->buffered();
 }
 
-PassRefPtr<TimeRanges> MediaPlayer::seekable()
+PassOwnPtr<PlatformTimeRanges> MediaPlayer::seekable()
 {
     return m_private->seekable();
 }
 
 double MediaPlayer::maxTimeSeekable()
 {
-    return m_private->maxTimeSeekableDouble();
+    return m_private->maxMediaTimeSeekable();
 }
 
 double MediaPlayer::minTimeSeekable()
 {
-    return m_private->minTimeSeekable();
+    return m_private->minMediaTimeSeekable();
 }
 
 bool MediaPlayer::didLoadingProgress()
diff --git a/Source/WebCore/platform/graphics/MediaPlayer.h b/Source/WebCore/platform/graphics/MediaPlayer.h
index aa96b02..9027b43 100644
--- a/Source/WebCore/platform/graphics/MediaPlayer.h
+++ b/Source/WebCore/platform/graphics/MediaPlayer.h
@@ -69,7 +69,7 @@ class Document;
 class GStreamerGWorld;
 class MediaPlayerPrivateInterface;
 #if ENABLE(MEDIA_SOURCE)
-class MediaSource;
+class MediaSourcePrivateClient;
 #endif
 class TextTrackRepresentation;
 
@@ -113,6 +113,7 @@ class IntRect;
 class IntSize;
 class MediaPlayer;
 struct MediaPlayerFactory;
+class PlatformTimeRanges;
 class TimeRanges;
 class HostWindow;
 
@@ -324,8 +325,8 @@ class MediaPlayer {
     bool preservesPitch() const;    
     void setPreservesPitch(bool);
 
-    PassRefPtr<TimeRanges> buffered();
-    PassRefPtr<TimeRanges> seekable();
+    PassOwnPtr<PlatformTimeRanges> buffered();
+    PassOwnPtr<PlatformTimeRanges> seekable();
     double minTimeSeekable();
     double maxTimeSeekable();
 
@@ -518,7 +519,7 @@ class MediaPlayer {
 #endif
 
 #if ENABLE(MEDIA_SOURCE)
-    RefPtr<MediaSource> m_mediaSource;
+    RefPtr<MediaSourcePrivateClient> m_mediaSource;
 #endif
 };
 
diff --git a/Source/WebCore/platform/graphics/MediaPlayerPrivate.h b/Source/WebCore/platform/graphics/MediaPlayerPrivate.h
index 17ac026..c7d5c52 100644
--- a/Source/WebCore/platform/graphics/MediaPlayerPrivate.h
+++ b/Source/WebCore/platform/graphics/MediaPlayerPrivate.h
@@ -29,7 +29,7 @@
 #if ENABLE(VIDEO)
 
 #include "MediaPlayer.h"
-#include "TimeRanges.h"
+#include "PlatformTimeRanges.h"
 #include <wtf/Forward.h>
 
 namespace WebCore {
@@ -46,7 +46,7 @@ class MediaPlayerPrivateInterface {
 
     virtual void load(const String& url) = 0;
 #if ENABLE(MEDIA_SOURCE)
-    virtual void load(const String& url, PassRefPtr<MediaSource>) = 0;
+    virtual void load(const String& url, MediaSourcePrivateClient*) = 0;
 #endif
     virtual void cancelLoad() = 0;
     
@@ -105,11 +105,12 @@ class MediaPlayerPrivateInterface {
     virtual MediaPlayer::NetworkState networkState() const = 0;
     virtual MediaPlayer::ReadyState readyState() const = 0;
 
-    virtual PassRefPtr<TimeRanges> seekable() const { return maxTimeSeekableDouble() ? TimeRanges::create(minTimeSeekable(), maxTimeSeekableDouble()) : TimeRanges::create(); }
+    virtual PassOwnPtr<PlatformTimeRanges> seekable() const { return maxMediaTimeSeekable() == MediaTime::zeroTime() ? PlatformTimeRanges::create() : PlatformTimeRanges::create(minMediaTimeSeekable(), maxMediaTimeSeekable()); }
     virtual float maxTimeSeekable() const { return 0; }
-    virtual double maxTimeSeekableDouble() const { return maxTimeSeekable(); }
+    virtual MediaTime maxMediaTimeSeekable() const { return MediaTime::createWithDouble(maxTimeSeekable()); }
     virtual double minTimeSeekable() const { return 0; }
-    virtual PassRefPtr<TimeRanges> buffered() const = 0;
+    virtual MediaTime minMediaTimeSeekable() const { return MediaTime::createWithDouble(minTimeSeekable()); }
+    virtual PassOwnPtr<PlatformTimeRanges> buffered() const = 0;
 
     virtual unsigned long long totalBytes() const { return 0; }
     virtual bool didLoadingProgress() const = 0;
diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
index 7482e24..bb7aa9e 100644
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
@@ -756,9 +756,9 @@ void MediaPlayerPrivateGStreamer::setPreservesPitch(bool preservesPitch)
     m_preservesPitch = preservesPitch;
 }
 
-PassRefPtr<PlatformTimeRanges> MediaPlayerPrivateGStreamer::buffered() const
+PassOwnPtr<PlatformTimeRanges> MediaPlayerPrivateGStreamer::buffered() const
 {
-    RefPtr<PlatformTimeRanges> timeRanges = PlatformTimeRanges::create();
+    OwnPtr<PlatformTimeRanges> timeRanges = PlatformTimeRanges::create();
     if (m_errorOccured || isLiveStream())
         return timeRanges.release();
 
diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h
index 50cde99..cb3cc2e 100644
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.h
@@ -82,7 +82,7 @@ class MediaPlayerPrivateGStreamer : public MediaPlayerPrivateGStreamerBase {
     void setPreload(MediaPlayer::Preload);
     void fillTimerFired(Timer<MediaPlayerPrivateGStreamer>*);
 
-    PassRefPtr<TimeRanges> buffered() const;
+    PassOwnPtr<PlatformTimeRanges> buffered() const;
     float maxTimeSeekable() const;
     bool didLoadingProgress() const;
     unsigned long long totalBytes() const;
diff --git a/Source/WebCore/platform/qt/RenderThemeQt.cpp b/Source/WebCore/platform/qt/RenderThemeQt.cpp
index 321fd11..c33f847 100644
--- a/Source/WebCore/platform/qt/RenderThemeQt.cpp
+++ b/Source/WebCore/platform/qt/RenderThemeQt.cpp
@@ -814,7 +814,7 @@ bool RenderThemeQt::paintMediaSliderTrack(RenderObject* o, const PaintInfo& pain
 
     if (MediaPlayer* player = mediaElement->player()) {
         // Get the buffered parts of the media
-        RefPtr<TimeRanges> buffered = player->buffered();
+        OwnPtr<PlatformTimeRanges> buffered = player->buffered();
         if (buffered->length() > 0 && player->duration() < std::numeric_limits<float>::infinity()) {
             // Set the transform and brush
             WorldMatrixTransformer transformer(p->painter, o, r);
@@ -822,8 +822,8 @@ bool RenderThemeQt::paintMediaSliderTrack(RenderObject* o, const PaintInfo& pain
 
             // Paint each buffered section
             for (int i = 0; i < buffered->length(); i++) {
-                float startX = (buffered->start(i, IGNORE_EXCEPTION) / player->duration()) * 100;
-                float width = ((buffered->end(i, IGNORE_EXCEPTION) / player->duration()) * 100) - startX;
+                float startX = (buffered->start(i) / player->duration()) * 100;
+                float width = ((buffered->end(i) / player->duration()) * 100) - startX;
                 p->painter->drawRect(startX, 37, width, 26);
             }
         }

From fa65657236e2441beeae4865651bdcc44d77704f Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Tue, 18 Nov 2014 10:28:13 +0100
Subject: [PATCH 50/68] IDL generated constructors provide a pointer to the
 argument, not the reference.

---
 Source/WebCore/Modules/mediasource/MediaSource.cpp | 6 +++---
 Source/WebCore/Modules/mediasource/MediaSource.h   | 4 ++--
 2 files changed, 5 insertions(+), 5 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/MediaSource.cpp b/Source/WebCore/Modules/mediasource/MediaSource.cpp
index 8918998..f433503 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.cpp
+++ b/Source/WebCore/Modules/mediasource/MediaSource.cpp
@@ -66,15 +66,15 @@ void MediaSource::setRegistry(URLRegistry* registry)
     s_registry = registry;
 }
 
-PassRefPtr<MediaSource> MediaSource::create(ScriptExecutionContext& context)
+PassRefPtr<MediaSource> MediaSource::create(ScriptExecutionContext* context)
 {
     RefPtr<MediaSource> mediaSource(adoptRef(new MediaSource(context)));
     mediaSource->suspendIfNeeded();
     return mediaSource.release();
 }
 
-MediaSource::MediaSource(ScriptExecutionContext& context)
-    : ActiveDOMObject(&context)
+MediaSource::MediaSource(ScriptExecutionContext* context)
+    : ActiveDOMObject(context)
     , m_mediaElement(0)
     , m_duration(MediaTime::invalidTime())
     , m_pendingSeekTime(MediaTime::invalidTime())
diff --git a/Source/WebCore/Modules/mediasource/MediaSource.h b/Source/WebCore/Modules/mediasource/MediaSource.h
index f0625d3..20de1cc 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.h
+++ b/Source/WebCore/Modules/mediasource/MediaSource.h
@@ -57,7 +57,7 @@ class MediaSource : public MediaSourcePrivateClient, public ActiveDOMObject, pub
     static const AtomicString& closedKeyword();
     static const AtomicString& endedKeyword();
 
-    static PassRefPtr<MediaSource> create(ScriptExecutionContext&);
+    static PassRefPtr<MediaSource> create(ScriptExecutionContext*);
     virtual ~MediaSource();
 
     void addedToRegistry();
@@ -115,7 +115,7 @@ class MediaSource : public MediaSourcePrivateClient, public ActiveDOMObject, pub
     using RefCounted<MediaSourcePrivateClient>::deref;
 
 protected:
-    explicit MediaSource(ScriptExecutionContext&);
+    explicit MediaSource(ScriptExecutionContext*);
 
     void onReadyStateChange(const AtomicString& oldState, const AtomicString& newState);
     Vector<PlatformTimeRanges> activeRanges() const;

From d2e053962cba909084ee5e39e0d7949ab3b8b27e Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Tue, 18 Nov 2014 10:28:48 +0100
Subject: [PATCH 51/68] Minor fixes to accomodate with the new API.

---
 Source/WebCore/html/HTMLMediaElement.cpp | 32 ++++++++++++++++++++++++--------
 1 file changed, 24 insertions(+), 8 deletions(-)

diff --git a/Source/WebCore/html/HTMLMediaElement.cpp b/Source/WebCore/html/HTMLMediaElement.cpp
index 8ef0348..ac713eb 100644
--- a/Source/WebCore/html/HTMLMediaElement.cpp
+++ b/Source/WebCore/html/HTMLMediaElement.cpp
@@ -1098,11 +1098,17 @@ void HTMLMediaElement::loadResource(const KURL& initialURL, ContentType& content
     ASSERT(!m_mediaSource);
 
     if (url.protocolIs(mediaSourceBlobProtocol))
-        m_mediaSource = MediaSourceRegistry::registry().lookupMediaSource(url.string());
+        m_mediaSource = MediaSource::lookup(url.string());
 
     if (m_mediaSource) {
-        if (!m_player->load(url, m_mediaSource))
+        if (m_mediaSource->attachToElement(this))
+            m_player->load(url, contentType, static_cast<MediaSourcePrivateClient*> (m_mediaSource.get()));
+        else {
+            // Forget our reference to the MediaSource, so we leave it alone
+            // while processing remainder of load failure.
+            m_mediaSource = 0;
             mediaLoadingFailed(MediaPlayer::FormatError);
+        }
     } else
 #endif
     if (!m_player->load(url, contentType, keySystem))
@@ -2868,10 +2874,11 @@ double HTMLMediaElement::percentLoaded() const
         return 0;
 
     double buffered = 0;
-    RefPtr<TimeRanges> timeRanges = m_player->buffered();
+    OwnPtr<PlatformTimeRanges> timeRanges = m_player->buffered();
+    bool ignored;
     for (unsigned i = 0; i < timeRanges->length(); ++i) {
-        double start = timeRanges->start(i, IGNORE_EXCEPTION);
-        double end = timeRanges->end(i, IGNORE_EXCEPTION);
+        double start = timeRanges->start(i, ignored);
+        double end = timeRanges->end(i, ignored);
         buffered += end - start;
     }
     return buffered / duration;
@@ -3123,7 +3130,7 @@ PassRefPtr<TextTrack> HTMLMediaElement::addTextTrack(const String& kind, const S
 
     // 5. Create a new text track corresponding to the new object, and set its text track kind to kind, its text 
     // track label to label, its text track language to language...
-    RefPtr<TextTrack> textTrack = TextTrack::create(ActiveDOMObject::scriptExecutionContext(), this, kind, label, language);
+    RefPtr<TextTrack> textTrack = TextTrack::create(ActiveDOMObject::scriptExecutionContext(), this, kind, emptyString(), label, language);
 
     // Note, due to side effects when changing track parameters, we have to
     // first append the track to the text track list.
@@ -3883,7 +3890,13 @@ PassRefPtr<TimeRanges> HTMLMediaElement::buffered() const
 {
     if (!m_player)
         return TimeRanges::create();
-    return m_player->buffered();
+
+#if ENABLE(MEDIA_SOURCE)
+    if (m_mediaSource)
+        return TimeRanges::create(*m_mediaSource->buffered());
+#endif
+
+    return TimeRanges::create(*m_player->buffered());
 }
 
 PassRefPtr<TimeRanges> HTMLMediaElement::played()
@@ -3902,7 +3915,10 @@ PassRefPtr<TimeRanges> HTMLMediaElement::played()
 
 PassRefPtr<TimeRanges> HTMLMediaElement::seekable() const
 {
-    return m_player ? m_player->seekable() : TimeRanges::create();
+    if (m_player)
+        return TimeRanges::create(*m_player->seekable());
+
+    return TimeRanges::create();
 }
 
 bool HTMLMediaElement::potentiallyPlaying() const

From 2f203c85921daf14423459e277f7f60cb5174521 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Tue, 18 Nov 2014 10:58:29 +0100
Subject: [PATCH 52/68] Compress iterators code a bit more, fix smart pointers
 usage. WARNING, there are still a few FIXMEs for missing API in
 HTMLMediaElement.

---
 .../WebCore/Modules/mediasource/SourceBuffer.cpp   | 103 +++++++++------------
 Source/WebCore/Modules/mediasource/SourceBuffer.h  |   8 +-
 2 files changed, 50 insertions(+), 61 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index 9e9ead3..648f774 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -100,16 +100,16 @@ struct SourceBuffer::TrackBuffer {
 
 PassRefPtr<SourceBuffer> SourceBuffer::create(PassRefPtr<SourceBufferPrivate> sourceBufferPrivate, PassRefPtr<MediaSource> source)
 {
-    RefPtr<SourceBuffer> sourceBuffer(adoptRef(new SourceBuffer(WTF::move(sourceBufferPrivate), source)));
+    RefPtr<SourceBuffer> sourceBuffer(adoptRef(new SourceBuffer(sourceBufferPrivate, source)));
     sourceBuffer->suspendIfNeeded();
     return sourceBuffer.release();
 }
 
 SourceBuffer::SourceBuffer(PassRefPtr<SourceBufferPrivate> sourceBufferPrivate, PassRefPtr<MediaSource> source)
     : ActiveDOMObject(source->scriptExecutionContext())
-    , m_private(WTF::move(sourceBufferPrivate))
+    , m_private(sourceBufferPrivate)
     , m_source(source)
-    , m_asyncEventQueue(*this)
+    , m_asyncEventQueue(GenericEventQueue::create(this))
     , m_appendBufferTimer(this, &SourceBuffer::appendBufferTimerFired)
     , m_highestPresentationEndTimestamp(MediaTime::invalidTime())
     , m_buffered(TimeRanges::create())
@@ -315,8 +315,7 @@ void SourceBuffer::removedFromMediaSource()
 
     abortIfUpdating();
 
-    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
-    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != m_trackBufferMap.end(); ++it) {
         TrackBuffer& trackBuffer = it->value;
         trackBuffer.samples.clear();
         trackBuffer.decodeQueue.clear();
@@ -330,8 +329,7 @@ void SourceBuffer::seekToTime(const MediaTime& time)
 {
     LOG(MediaSource, "SourceBuffer::seekToTime(%p) - time(%s)", this, toString(time).utf8().data());
 
-    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
-    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != m_trackBufferMap.end(); ++it) {
         TrackBuffer& trackBuffer = it->value;
         const AtomicString& trackID = it->key;
 
@@ -346,8 +344,7 @@ MediaTime SourceBuffer::sourceBufferPrivateFastSeekTimeForMediaTime(SourceBuffer
     MediaTime lowerBoundTime = targetTime - negativeThreshold;
     MediaTime upperBoundTime = targetTime + positiveThreshold;
 
-    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
-    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != m_trackBufferMap.end(); ++it) {
         TrackBuffer& trackBuffer = it->value;
         // Find the sample which contains the target time time.
         DecodeOrderSampleMap::iterator futureSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSampleAfterPresentationTime(targetTime, positiveThreshold);
@@ -380,7 +377,7 @@ MediaTime SourceBuffer::sourceBufferPrivateFastSeekTimeForMediaTime(SourceBuffer
 
 bool SourceBuffer::hasPendingActivity() const
 {
-    return m_source || m_asyncEventQueue.hasPendingEvents();
+    return m_source || m_asyncEventQueue->hasPendingEvents();
 }
 
 void SourceBuffer::stop()
@@ -399,7 +396,7 @@ void SourceBuffer::scheduleEvent(const AtomicString& eventName)
     RefPtr<Event> event = Event::create(eventName, false, false);
     event->setTarget(this);
 
-    m_asyncEventQueue.enqueueEvent(event.release());
+    m_asyncEventQueue->enqueueEvent(event.release());
 }
 
 void SourceBuffer::appendBufferInternal(unsigned char* data, unsigned size, ExceptionCode& ec)
@@ -478,7 +475,7 @@ void SourceBuffer::appendBufferTimerFired(Timer<SourceBuffer>*)
 
     // 1. Loop Top: If the input buffer is empty, then jump to the need more data step below.
     if (!m_pendingAppendData.size()) {
-        sourceBufferPrivateAppendComplete(&m_private.get(), AppendSucceeded);
+        sourceBufferPrivateAppendComplete(m_private.get(), AppendSucceeded);
         return;
     }
 
@@ -525,8 +522,7 @@ void SourceBuffer::sourceBufferPrivateAppendComplete(SourceBufferPrivate*, Appen
         m_source->monitorSourceBuffers();
 
     MediaTime currentMediaTime = m_source->currentTime();
-    HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
-    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != m_trackBufferMap.end(); ++it) {
         TrackBuffer& trackBuffer = it->value;
         const AtomicString& trackID = it->key;
 
@@ -574,8 +570,7 @@ static PassRefPtr<TimeRanges> removeSamplesFromTrackBuffer(const DecodeOrderSamp
 
     RefPtr<TimeRanges> erasedRanges = TimeRanges::create();
     MediaTime microsecond(1, 1000000);
-    DecodeOrderSampleMap::const_iterator end = samples.end();
-    for (DecodeOrderSampleMap::const_iterator it = samples.begin(); it != end; ++it) {
+    for (DecodeOrderSampleMap::const_iterator it = samples.begin(); it != samples.end(); ++it) {
         const DecodeOrderSampleMap::KeyType& decodeKey = it->first;
 #if !LOG_DISABLED
         size_t startBufferSize = trackBuffer.samples.sizeInBytes();
@@ -623,8 +618,7 @@ void SourceBuffer::removeCodedFrames(const MediaTime& start, const MediaTime& en
 
     // 2. Let end be the end presentation timestamp for the removal range.
     // 3. For each track buffer in this source buffer, run the following steps:
-    HashMap<AtomicString, TrackBuffer>::iterator bmend = m_trackBufferMap.end();
-    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != bmend; ++it) {
+    for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != m_trackBufferMap.end(); ++it) {
         TrackBuffer& trackBuffer = it->value;
 
         // 3.1. Let remove end timestamp be the current value of duration
@@ -804,7 +798,8 @@ size_t SourceBuffer::maximumBufferSize() const
     if (!element)
         return 0;
 
-    return element->maximumSourceBufferSize(*this);
+    return 0;
+    // FIXME return element->maximumSourceBufferSize(*this);
 }
 
 const AtomicString& SourceBuffer::decodeError()
@@ -904,8 +899,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         }
         // 3.2 Add the appropriate track descriptions from this initialization segment to each of the track buffers.
         ASSERT(segment.audioTracks.size() == audioTracks()->length());
-        Vector<InitializationSegment::AudioTrackInformation>::const_iterator aend = segment.audioTracks.end();
-        for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != aend; ++it) {
+        for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != segment.audioTracks.end(); ++it) {
             const InitializationSegment::AudioTrackInformation& audioTrackInfo = *it;
 
             if (audioTracks()->length() == 1) {
@@ -920,8 +914,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
 
 
         ASSERT(segment.videoTracks.size() == videoTracks()->length());
-        Vector<InitializationSegment::VideoTrackInformation>::const_iterator vend = segment.videoTracks.end();
-        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != segment.videoTracks.end(); ++it) {
             const InitializationSegment::VideoTrackInformation& videoTrackInfo = *it;
             if (videoTracks()->length() == 1) {
                 videoTracks()->item(0)->setPrivate(videoTrackInfo.track);
@@ -934,21 +927,25 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         }
 
         ASSERT(segment.textTracks.size() == textTracks()->length());
-        Vector<InitializationSegment::TextTrackInformation>::const_iterator tend = segment.textTracks.end();
-        for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != tend; ++it) {
+        for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != segment.textTracks.end(); ++it) {
             const InitializationSegment::TextTrackInformation &textTrackInfo = *it;
             if (textTracks()->length() == 1) {
-                static_cast<InbandTextTrack>(*textTracks()->item(0)).setPrivate(textTrackInfo.track);
+                InbandTextTrack *inbandTextTrack = dynamic_cast<InbandTextTrack *> (textTracks()->item(0));
+                if (inbandTextTrack) {
+                    inbandTextTrack->setPrivate(textTrackInfo.track);
+                }
                 break;
             }
 
             TextTrack *textTrack = textTracks()->getTrackById(textTrackInfo.track->id());
             ASSERT(textTrack);
-            static_cast<InbandTextTrack>(*textTrack).setPrivate(textTrackInfo.track);
+            InbandTextTrack *inbandTextTrack = dynamic_cast<InbandTextTrack *> (textTrack);
+            if (inbandTextTrack) {
+                inbandTextTrack->setPrivate(textTrackInfo.track);
+            }
         }
 
-        HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
-        for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+        for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != m_trackBufferMap.end(); ++it) {
             TrackBuffer& trackBuffer = it->value;
             trackBuffer.needRandomAccessFlag = true;
         }
@@ -964,8 +961,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         // NOTE: This check is the responsibility of the SourceBufferPrivate.
 
         // 5.2 For each audio track in the initialization segment, run following steps:
-        Vector<InitializationSegment::AudioTrackInformation>::const_iterator aend = segment.audioTracks.end();
-        for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != aend; ++it) {
+        for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != segment.audioTracks.end(); ++it) {
             const InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
             AudioTrackPrivate* audioTrackPrivate = audioTrackInfo.track.get();
 
@@ -1006,8 +1002,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         }
 
         // 5.3 For each video track in the initialization segment, run following steps:
-        Vector<InitializationSegment::VideoTrackInformation>::const_iterator vend = segment.videoTracks.end();
-        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != segment.videoTracks.end(); ++it) {
             const InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
             VideoTrackPrivate* videoTrackPrivate = videoTrackInfo.track.get();
 
@@ -1048,8 +1043,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
         }
 
         // 5.4 For each text track in the initialization segment, run following steps:
-        Vector<InitializationSegment::TextTrackInformation>::const_iterator tend = segment.textTracks.end();
-        for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != tend; ++it) {
+        for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != segment.textTracks.end(); ++it) {
             const InitializationSegment::TextTrackInformation & textTrackInfo = *it;
             InbandTextTrackPrivate* textTrackPrivate = textTrackInfo.track.get();
 
@@ -1097,9 +1091,8 @@ void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(SourceBuff
     // 6. If the HTMLMediaElement.readyState attribute is HAVE_NOTHING, then run the following steps:
     if (m_private->readyState() == MediaPlayer::HaveNothing) {
         // 6.1 If one or more objects in sourceBuffers have first initialization segment flag set to false, then abort these steps.
-        Vector<RefPtr <SourceBuffer> >::iterator end = m_source->sourceBuffers()->end();
-        for (Vector<RefPtr <SourceBuffer> >::iterator it = m_source->sourceBuffers()->begin(); it != end; ++it) {
-            SourceBuffer *sourceBuffer = it->value;
+        for (Vector<RefPtr <SourceBuffer> >::iterator it = m_source->sourceBuffers()->begin(); it != m_source->sourceBuffers()->end(); ++it) {
+            SourceBuffer * sourceBuffer = it->get ();
             if (!sourceBuffer->m_receivedFirstInitializationSegment)
                 return;
         }
@@ -1130,22 +1123,19 @@ bool SourceBuffer::validateInitializationSegment(const InitializationSegment& se
         return false;
 
     //   * The codecs for each track, match what was specified in the first initialization segment.
-    Vector<InitializationSegment::AudioTrackInformation>::const_iterator aend = segment.audioTracks.end();
-    for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != aend; ++it) {
+    for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != segment.audioTracks.end(); ++it) {
         const InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
         if (!m_audioCodecs.contains(audioTrackInfo.description->codec()))
             return false;
     }
 
-    Vector<InitializationSegment::VideoTrackInformation>::const_iterator vend = segment.videoTracks.end();
-    for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+    for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != segment.videoTracks.end(); ++it) {
         const InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
         if (!m_videoCodecs.contains(videoTrackInfo.description->codec()))
             return false;
     }
 
-    Vector<InitializationSegment::TextTrackInformation>::const_iterator tend = segment.textTracks.end();
-    for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != tend; ++it) {
+    for (Vector<InitializationSegment::TextTrackInformation>::const_iterator it = segment.textTracks.begin(); it != segment.textTracks.end(); ++it) {
         const InitializationSegment::TextTrackInformation & textTrackInfo = *it;
         if (!m_textCodecs.contains(textTrackInfo.description->codec()))
             return false;
@@ -1154,7 +1144,7 @@ bool SourceBuffer::validateInitializationSegment(const InitializationSegment& se
     //   * If more than one track for a single type are present (ie 2 audio tracks), then the Track
     //   IDs match the ones in the first initialization segment.
     if (segment.audioTracks.size() >= 2) {
-        for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != aend; ++it) {
+        for (Vector<InitializationSegment::AudioTrackInformation>::const_iterator it = segment.audioTracks.begin(); it != segment.audioTracks.end(); ++it) {
             const InitializationSegment::AudioTrackInformation & audioTrackInfo = *it;
             if (!m_trackBufferMap.contains(audioTrackInfo.track->id()))
                 return false;
@@ -1162,7 +1152,7 @@ bool SourceBuffer::validateInitializationSegment(const InitializationSegment& se
     }
 
     if (segment.videoTracks.size() >= 2) {
-        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != segment.videoTracks.end(); ++it) {
             const InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
             if (!m_trackBufferMap.contains(videoTrackInfo.track->id()))
                 return false;
@@ -1171,7 +1161,7 @@ bool SourceBuffer::validateInitializationSegment(const InitializationSegment& se
 
     if (segment.textTracks.size() >= 2) {
         // Don't know why they use the video tracks here
-        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != vend; ++it) {
+        for (Vector<InitializationSegment::VideoTrackInformation>::const_iterator it = segment.videoTracks.begin(); it != segment.videoTracks.end(); ++it) {
             const InitializationSegment::VideoTrackInformation & videoTrackInfo = *it;
             if (!m_trackBufferMap.contains(videoTrackInfo.track->id()))
                 return false;
@@ -1270,8 +1260,7 @@ void SourceBuffer::sourceBufferPrivateDidReceiveSample(SourceBufferPrivate*, Pas
             // Set group start timestamp equal to the highest presentation end timestamp.
             // FIXME: Add support for "sequence" mode.
 
-            HashMap<AtomicString, TrackBuffer>::iterator end = m_trackBufferMap.end();
-            for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+            for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != m_trackBufferMap.end(); ++it) {
                 TrackBuffer& trackBuffer = it->value;
                 // 1.7.2 Unset the last decode timestamp on all track buffers.
                 trackBuffer.lastDecodeTimestamp = MediaTime::invalidTime();
@@ -1691,8 +1680,8 @@ void SourceBuffer::reenqueueMediaForTime(TrackBuffer& trackBuffer, AtomicString
 
 void SourceBuffer::didDropSample()
 {
-    if (!isRemoved())
-        m_source->mediaElement()->incrementDroppedFrameCount();
+    /* FIXME if (!isRemoved())
+        m_source->mediaElement()->incrementDroppedFrameCount(); */
 }
 
 void SourceBuffer::monitorBufferingRate()
@@ -1798,8 +1787,7 @@ bool SourceBuffer::canPlayThrough()
 size_t SourceBuffer::extraMemoryCost() const
 {
     size_t extraMemoryCost = m_pendingAppendData.capacity();
-    HashMap<AtomicString, TrackBuffer>::const_iterator end = m_trackBufferMap.end();
-    for (HashMap<AtomicString, TrackBuffer>::const_iterator it = m_trackBufferMap.begin(); it != end; ++it) {
+    for (HashMap<AtomicString, TrackBuffer>::const_iterator it = m_trackBufferMap.begin(); it != m_trackBufferMap.end(); ++it) {
         const TrackBuffer& trackBuffer = it->value;
         extraMemoryCost += trackBuffer.samples.sizeInBytes();
     }
@@ -1829,9 +1817,8 @@ Vector<String> SourceBuffer::bufferedSamplesForTrackID(const AtomicString& track
 
     TrackBuffer& trackBuffer = it->value;
     Vector<String> sampleDescriptions;
-    DecodeOrderSampleMap::iterator end = trackBuffer.samples.decodeOrder().end();
-    for (DecodeOrderSampleMap::iterator it = trackBuffer.samples.decodeOrder().begin(); it != end; ++it) {
-        sampleDescriptions.append(toString(*it->second));
+    for (DecodeOrderSampleMap::iterator it = trackBuffer.samples.decodeOrder().begin(); it != trackBuffer.samples.decodeOrder().end(); ++it) {
+        //sampleDescriptions.append(toString(*it->second));
     }
 
     return sampleDescriptions;
@@ -1840,7 +1827,9 @@ Vector<String> SourceBuffer::bufferedSamplesForTrackID(const AtomicString& track
 Document& SourceBuffer::document() const
 {
     ASSERT(scriptExecutionContext());
-    return static_cast<Document>(*scriptExecutionContext());
+    Document *document = dynamic_cast<Document *> (scriptExecutionContext());
+    ASSERT(document);
+    return *document;
 }
 
 } // namespace WebCore
diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.h b/Source/WebCore/Modules/mediasource/SourceBuffer.h
index 91b496b..9e7560b 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.h
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.h
@@ -121,7 +121,7 @@ class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, pu
     virtual void derefEventTarget() OVERRIDE { deref(); }
 
 private:
-    SourceBuffer(PassOwnPtr<SourceBufferPrivate>, PassRefPtr<MediaSource>);
+    SourceBuffer(PassRefPtr<SourceBufferPrivate>, PassRefPtr<MediaSource>);
 
     // SourceBufferPrivateClient
     virtual void sourceBufferPrivateDidEndStream(SourceBufferPrivate*, const WTF::AtomicString&);
@@ -181,9 +181,9 @@ class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, pu
     friend class Internals;
     Vector<String> bufferedSamplesForTrackID(const AtomicString&);
 
-    OwnPtr<SourceBufferPrivate> m_private;
-    MediaSource* m_source;
-    GenericEventQueue m_asyncEventQueue;
+    RefPtr<SourceBufferPrivate> m_private;
+    RefPtr<MediaSource> m_source;
+    OwnPtr<GenericEventQueue> m_asyncEventQueue;
 
     Vector<unsigned char> m_pendingAppendData;
     Timer<SourceBuffer> m_appendBufferTimer;

From 76557c29b16a3ca951c08fe695d21f7f2337b4bd Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Wed, 19 Nov 2014 11:44:04 +0100
Subject: [PATCH 53/68] Make sure to build new files from platform/graphics.

---
 Source/WebCore/Target.pri | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/Source/WebCore/Target.pri b/Source/WebCore/Target.pri
index 6d34025..38097ad 100644
--- a/Source/WebCore/Target.pri
+++ b/Source/WebCore/Target.pri
@@ -2229,8 +2229,11 @@ HEADERS += \
     platform/graphics/PathTraversalState.h \
     platform/graphics/Pattern.h \
     platform/graphics/PlatformLayer.h \
+    platform/graphics/PlatformTimeRanges.h \
     platform/graphics/Region.h \
     platform/graphics/RoundedRect.h \
+    platform/graphics/SourceBufferPrivate.h \
+    platform/graphics/SourceBufferPrivateClient.h \
     platform/graphics/qt/FontCustomPlatformData.h \
     platform/graphics/qt/NativeImageQt.h \
     platform/graphics/qt/StillImageQt.h
@@ -3383,6 +3386,7 @@ enable?(VIDEO) {
         html/shadow/MediaControlElements.cpp \
         html/TimeRanges.cpp \
         platform/graphics/MediaPlayer.cpp \
+        platform/graphics/PlatformTimeRanges.cpp \
         rendering/RenderVideo.cpp \
         rendering/RenderMedia.cpp \
         rendering/RenderMediaControls.cpp \

From d5a13bcdf1754e531577037ba4d12ed37f47f3cd Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Wed, 19 Nov 2014 11:44:21 +0100
Subject: [PATCH 54/68] Remove unused method for now.

---
 Source/WebCore/platform/graphics/PlatformTimeRanges.cpp | 9 ---------
 Source/WebCore/platform/graphics/PlatformTimeRanges.h   | 2 --
 2 files changed, 11 deletions(-)

diff --git a/Source/WebCore/platform/graphics/PlatformTimeRanges.cpp b/Source/WebCore/platform/graphics/PlatformTimeRanges.cpp
index 2f319ac..c93bd37 100644
--- a/Source/WebCore/platform/graphics/PlatformTimeRanges.cpp
+++ b/Source/WebCore/platform/graphics/PlatformTimeRanges.cpp
@@ -259,13 +259,4 @@ MediaTime PlatformTimeRanges::totalDuration() const
     return total;
 }
 
-void PlatformTimeRanges::dump(PrintStream& out) const
-{
-    if (!length())
-        return;
-
-    for (size_t i = 0; i < length(); ++i)
-        out.print("[", start(i), "..", end(i), "] ");
-}
-
 }
diff --git a/Source/WebCore/platform/graphics/PlatformTimeRanges.h b/Source/WebCore/platform/graphics/PlatformTimeRanges.h
index 9423ee5..bf34f65 100644
--- a/Source/WebCore/platform/graphics/PlatformTimeRanges.h
+++ b/Source/WebCore/platform/graphics/PlatformTimeRanges.h
@@ -74,8 +74,6 @@ class PlatformTimeRanges {
 
     MediaTime totalDuration() const;
 
-    void dump(WTF::PrintStream&) const;
-
 private:
     PlatformTimeRanges& copy(const PlatformTimeRanges&);
 

From 0d92daba603d38abdac3bce4e1dae743ce0f14f5 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 20 Nov 2014 15:33:59 +0100
Subject: [PATCH 55/68] Fix build for old C++

---
 Source/WebCore/Modules/mediasource/SampleMap.cpp | 34 +++++++++++++-----------
 Source/WebCore/Modules/mediasource/SampleMap.h   |  1 +
 2 files changed, 20 insertions(+), 15 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SampleMap.cpp b/Source/WebCore/Modules/mediasource/SampleMap.cpp
index a8731c1..3e3ad8f 100644
--- a/Source/WebCore/Modules/mediasource/SampleMap.cpp
+++ b/Source/WebCore/Modules/mediasource/SampleMap.cpp
@@ -36,6 +36,8 @@ template <typename M>
 class SampleIsLessThanMediaTimeComparator {
 public:
     typedef typename M::value_type value_type;
+    SampleIsLessThanMediaTimeComparator() : m_mediaTime (MediaTime::zeroTime()) { } 
+    SampleIsLessThanMediaTimeComparator(MediaTime m) : m_mediaTime (m) { } 
     bool operator()(const value_type& value, const MediaTime& time)
     {
         MediaTime presentationEndTime = value.second->presentationTime() + value.second->duration();
@@ -46,6 +48,12 @@ class SampleIsLessThanMediaTimeComparator {
         MediaTime presentationStartTime = value.second->presentationTime();
         return time < presentationStartTime;
     }
+    bool operator()(const value_type& value)
+    {
+        return value.second->presentationTime() <= m_mediaTime;
+    }
+private:
+    MediaTime m_mediaTime;
 };
 
 template <typename M>
@@ -74,11 +82,11 @@ class SampleIsRandomAccess {
 
 // SamplePresentationTimeIsInsideRangeComparator matches (range.first, range.second]
 struct SamplePresentationTimeIsInsideRangeComparator {
-    bool operator()(std::pair<MediaTime, MediaTime> range, const std::pair<MediaTime, RefPtr<MediaSample>>& value)
+    bool operator()(std::pair<MediaTime, MediaTime> range, const std::pair< MediaTime, RefPtr<MediaSample> >& value)
     {
         return range.second < value.first;
     }
-    bool operator()(const std::pair<MediaTime, RefPtr<MediaSample>>& value, std::pair<MediaTime, MediaTime> range)
+    bool operator()(const std::pair< MediaTime, RefPtr<MediaSample> >& value, std::pair<MediaTime, MediaTime> range)
     {
         return value.first <= range.first;
     }
@@ -86,11 +94,11 @@ struct SamplePresentationTimeIsInsideRangeComparator {
 
 // SamplePresentationTimeIsWithinRangeComparator matches [range.first, range.second)
 struct SamplePresentationTimeIsWithinRangeComparator {
-    bool operator()(std::pair<MediaTime, MediaTime> range, const std::pair<MediaTime, RefPtr<MediaSample>>& value)
+    bool operator()(std::pair<MediaTime, MediaTime> range, const std::pair< MediaTime, RefPtr<MediaSample> >& value)
     {
         return range.second <= value.first;
     }
-    bool operator()(const std::pair<MediaTime, RefPtr<MediaSample>>& value, std::pair<MediaTime, MediaTime> range)
+    bool operator()(const std::pair< MediaTime, RefPtr<MediaSample> >& value, std::pair<MediaTime, MediaTime> range)
     {
         return value.first < range.first;
     }
@@ -117,7 +125,7 @@ void SampleMap::addSample(PassRefPtr<MediaSample> prpSample)
 
     presentationOrder().m_samples.insert(PresentationOrderSampleMap::MapType::value_type(presentationTime, sample));
 
-    auto decodeKey = DecodeOrderSampleMap::KeyType(sample->decodeTime(), presentationTime);
+    std::pair<MediaTime, MediaTime> decodeKey = DecodeOrderSampleMap::KeyType(sample->decodeTime(), presentationTime);
     decodeOrder().m_samples.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, sample));
 
     m_totalSize += sample->sizeInBytes();
@@ -130,7 +138,7 @@ void SampleMap::removeSample(MediaSample* sample)
 
     presentationOrder().m_samples.erase(presentationTime);
 
-    auto decodeKey = DecodeOrderSampleMap::KeyType(sample->decodeTime(), presentationTime);
+    std::pair<MediaTime, MediaTime> decodeKey = DecodeOrderSampleMap::KeyType(sample->decodeTime(), presentationTime);
     decodeOrder().m_samples.erase(decodeKey);
 
     m_totalSize -= sample->sizeInBytes();
@@ -138,7 +146,7 @@ void SampleMap::removeSample(MediaSample* sample)
 
 PresentationOrderSampleMap::iterator PresentationOrderSampleMap::findSampleWithPresentationTime(const MediaTime& time)
 {
-    auto range = m_samples.equal_range(time);
+    iterator_range range = m_samples.equal_range(time);
     if (range.first == range.second)
         return end();
     return range.first;
@@ -146,7 +154,7 @@ PresentationOrderSampleMap::iterator PresentationOrderSampleMap::findSampleWithP
 
 PresentationOrderSampleMap::iterator PresentationOrderSampleMap::findSampleContainingPresentationTime(const MediaTime& time)
 {
-    auto range = std::equal_range(begin(), end(), time, SampleIsLessThanMediaTimeComparator<MapType>());
+    iterator_range range = std::equal_range(begin(), end(), time, SampleIsLessThanMediaTimeComparator<MapType>());
     if (range.first == range.second)
         return end();
     return range.first;
@@ -164,7 +172,7 @@ DecodeOrderSampleMap::iterator DecodeOrderSampleMap::findSampleWithDecodeKey(con
 
 PresentationOrderSampleMap::reverse_iterator PresentationOrderSampleMap::reverseFindSampleContainingPresentationTime(const MediaTime& time)
 {
-    auto range = std::equal_range(rbegin(), rend(), time, SampleIsGreaterThanMediaTimeComparator<MapType>());
+    reverse_iterator_range range = std::equal_range(rbegin(), rend(), time, SampleIsGreaterThanMediaTimeComparator<MapType>());
     if (range.first == range.second)
         return rend();
     return range.first;
@@ -244,13 +252,9 @@ PresentationOrderSampleMap::iterator_range PresentationOrderSampleMap::findSampl
 
 PresentationOrderSampleMap::iterator_range PresentationOrderSampleMap::findSamplesWithinPresentationRangeFromEnd(const MediaTime& beginTime, const MediaTime& endTime)
 {
-    reverse_iterator rangeEnd = std::find_if(rbegin(), rend(), [&beginTime] (PresentationOrderSampleMap::MapType::value_type value) {
-        return value.second->presentationTime() <= beginTime;
-    });
+    reverse_iterator rangeEnd = std::find_if(rbegin(), rend(), SampleIsLessThanMediaTimeComparator<MapType>(beginTime));
 
-    reverse_iterator rangeStart = std::find_if(rbegin(), rangeEnd, [&endTime] (PresentationOrderSampleMap::MapType::value_type value) {
-        return value.second->presentationTime() <= endTime;
-    });
+    reverse_iterator rangeStart = std::find_if(rbegin(), rangeEnd, SampleIsLessThanMediaTimeComparator<MapType>(endTime));
 
     return iterator_range(rangeStart.base(), rangeEnd.base());
 }
diff --git a/Source/WebCore/Modules/mediasource/SampleMap.h b/Source/WebCore/Modules/mediasource/SampleMap.h
index 348bdb1..92430d5 100644
--- a/Source/WebCore/Modules/mediasource/SampleMap.h
+++ b/Source/WebCore/Modules/mediasource/SampleMap.h
@@ -44,6 +44,7 @@ class PresentationOrderSampleMap {
     typedef MapType::iterator iterator;
     typedef MapType::reverse_iterator reverse_iterator;
     typedef std::pair<iterator, iterator> iterator_range;
+    typedef std::pair<reverse_iterator, reverse_iterator> reverse_iterator_range;
 
     iterator begin() { return m_samples.begin(); }
     iterator end() { return m_samples.end(); }

From 40ee359a3e1fc1d7eff8453a04a9743f2f180c7b Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 20 Nov 2014 15:34:40 +0100
Subject: [PATCH 56/68] Use existing API from our version

---
 Source/WebCore/Modules/mediasource/DOMURLMediaSource.cpp | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/Source/WebCore/Modules/mediasource/DOMURLMediaSource.cpp b/Source/WebCore/Modules/mediasource/DOMURLMediaSource.cpp
index 2051274..f771b17 100644
--- a/Source/WebCore/Modules/mediasource/DOMURLMediaSource.cpp
+++ b/Source/WebCore/Modules/mediasource/DOMURLMediaSource.cpp
@@ -46,7 +46,7 @@ String DOMURLMediaSource::createObjectURL(ScriptExecutionContext* scriptExecutio
 
     if (!scriptExecutionContext || !source)
         return String();
-    return DOMURL::createPublicURL(scriptExecutionContext, source);
+    return DOMURL::createObjectURL(scriptExecutionContext, source);
 }
 
 } // namespace WebCore

From 30183e542226e4cac5bb4f70f34149d346df598b Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 20 Nov 2014 15:34:54 +0100
Subject: [PATCH 57/68] Add some more files to the build for mediasource

---
 Source/WebCore/Target.pri | 14 ++++++++++++--
 1 file changed, 12 insertions(+), 2 deletions(-)

diff --git a/Source/WebCore/Target.pri b/Source/WebCore/Target.pri
index 38097ad..abdedce 100644
--- a/Source/WebCore/Target.pri
+++ b/Source/WebCore/Target.pri
@@ -3211,15 +3211,24 @@ enable?(FILE_SYSTEM) {
 
 enable?(MEDIA_SOURCE) {
     HEADERS += \
+        Modules/mediasource/AudioTrackMediaSource.h \
+        Modules/mediasource/DOMURLMediaSource.h \
         Modules/mediasource/MediaSource.h \
         Modules/mediasource/MediaSourceRegistry.h \
+        Modules/mediasource/SampleMap.h \
         Modules/mediasource/SourceBuffer.h \
-        Modules/mediasource/SourceBufferList.h
+        Modules/mediasource/SourceBufferList.h \
+        Modules/mediasource/TextTrackMediaSource.h \
+        Modules/mediasource/VideoPlaybackQuality.h \
+        Modules/mediasource/VideoTrackMediaSource.h
     SOURCES += \
+        Modules/mediasource/DOMURLMediaSource.cpp \
         Modules/mediasource/MediaSource.cpp \
         Modules/mediasource/MediaSourceRegistry.cpp \
+        Modules/mediasource/SampleMap.cpp \
         Modules/mediasource/SourceBuffer.cpp \
-        Modules/mediasource/SourceBufferList.cpp
+        Modules/mediasource/SourceBufferList.cpp \
+        Modules/mediasource/VideoPlaybackQuality.cpp
         
     use?(GSTREAMER) {
         HEADERS += \
@@ -3228,6 +3237,7 @@ enable?(MEDIA_SOURCE) {
             platform/graphics/gstreamer/MediaSourceGStreamer.h
         SOURCES += \
             platform/graphics/gstreamer/WebKitMediaSourceGStreamer.cpp \
+            platform/graphics/gstreamer/SourceBufferPrivateGStreamer.cpp \ 
             platform/graphics/gstreamer/MediaSourceGStreamer.cpp
     }
 }

From 14cc0ff59a47b72929382bea8117fc6c1042f803 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 20 Nov 2014 16:22:50 +0100
Subject: [PATCH 58/68] Add missing interfaceName symbol

---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp     | 5 +++++
 Source/WebCore/Modules/mediasource/SourceBuffer.h       | 2 +-
 Source/WebCore/Modules/mediasource/SourceBufferList.cpp | 5 +++++
 Source/WebCore/Modules/mediasource/SourceBufferList.h   | 2 +-
 4 files changed, 12 insertions(+), 2 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index 648f774..ab27631 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -1824,6 +1824,11 @@ Vector<String> SourceBuffer::bufferedSamplesForTrackID(const AtomicString& track
     return sampleDescriptions;
 }
 
+const AtomicString& SourceBuffer::interfaceName() const
+{
+    return eventNames().interfaceForSourceBuffer;
+}
+
 Document& SourceBuffer::document() const
 {
     ASSERT(scriptExecutionContext());
diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.h b/Source/WebCore/Modules/mediasource/SourceBuffer.h
index 9e7560b..1d4bcb9 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.h
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.h
@@ -103,7 +103,7 @@ class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, pu
     virtual void stop() OVERRIDE;
 
     // EventTarget interface
-    virtual const AtomicString& interfaceName() const; 
+    virtual const AtomicString& interfaceName() const OVERRIDE; 
     virtual ScriptExecutionContext* scriptExecutionContext() const OVERRIDE { return ActiveDOMObject::scriptExecutionContext(); }
     virtual EventTargetData* eventTargetData() { return &m_eventTargetData; }
     virtual EventTargetData* ensureEventTargetData() { return &m_eventTargetData; }
diff --git a/Source/WebCore/Modules/mediasource/SourceBufferList.cpp b/Source/WebCore/Modules/mediasource/SourceBufferList.cpp
index 94be379..f65c13b 100644
--- a/Source/WebCore/Modules/mediasource/SourceBufferList.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBufferList.cpp
@@ -96,6 +96,11 @@ void SourceBufferList::scheduleEvent(const AtomicString& eventName)
     m_asyncEventQueue->enqueueEvent(event.release());
 }
 
+const AtomicString& SourceBufferList::interfaceName() const
+{
+    return eventNames().interfaceForSourceBufferList;
+}
+
 
 } // namespace WebCore
 
diff --git a/Source/WebCore/Modules/mediasource/SourceBufferList.h b/Source/WebCore/Modules/mediasource/SourceBufferList.h
index 4ebe9fd..8ef3878 100644
--- a/Source/WebCore/Modules/mediasource/SourceBufferList.h
+++ b/Source/WebCore/Modules/mediasource/SourceBufferList.h
@@ -66,7 +66,7 @@ class SourceBufferList : public RefCounted<SourceBufferList>, public ScriptWrapp
     iterator end() { return m_list.end(); }
 
     // EventTarget interface
-    virtual const AtomicString& interfaceName() const; 
+    virtual const AtomicString& interfaceName() const OVERRIDE; 
     virtual ScriptExecutionContext* scriptExecutionContext() const { return m_scriptExecutionContext; }
     virtual EventTargetData* eventTargetData() { return &m_eventTargetData; }
     virtual EventTargetData* ensureEventTargetData() { return &m_eventTargetData; }

From 302a9335131afbec57198063132c640dc2744061 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 20 Nov 2014 16:23:02 +0100
Subject: [PATCH 59/68] Add missing symbol.

---
 Source/WebCore/html/track/InbandTextTrack.cpp | 28 +++++++++++++++++++++++++++
 1 file changed, 28 insertions(+)

diff --git a/Source/WebCore/html/track/InbandTextTrack.cpp b/Source/WebCore/html/track/InbandTextTrack.cpp
index b395a50..9c292ac 100644
--- a/Source/WebCore/html/track/InbandTextTrack.cpp
+++ b/Source/WebCore/html/track/InbandTextTrack.cpp
@@ -431,6 +431,34 @@ void InbandTextTrack::willRemoveTextTrackPrivate(InbandTextTrackPrivate* trackPr
     mediaElement()->removeTextTrack(this);
 }
 
+void InbandTextTrack::updateKindFromPrivate()
+{
+    switch (m_private->kind()) {
+    case InbandTextTrackPrivate::Subtitles:
+        setKind(TextTrack::subtitlesKeyword());
+        break;
+    case InbandTextTrackPrivate::Captions:
+        setKind(TextTrack::captionsKeyword());
+        break;
+    case InbandTextTrackPrivate::Descriptions:
+        setKind(TextTrack::descriptionsKeyword());
+        break;
+    case InbandTextTrackPrivate::Chapters:
+        setKind(TextTrack::chaptersKeyword());
+        break;
+    case InbandTextTrackPrivate::Metadata:
+        setKind(TextTrack::metadataKeyword());
+        break;
+    case InbandTextTrackPrivate::Forced:
+        setKind(TextTrack::forcedKeyword());
+        break;
+    case InbandTextTrackPrivate::None:
+    default:
+        ASSERT_NOT_REACHED();
+        break;
+    }
+}
+
 } // namespace WebCore
 
 #endif

From 57c93c8cfacb756a5774db7b5d15a5a317114ac0 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 20 Nov 2014 18:43:08 +0100
Subject: [PATCH 60/68] Add SourceBuffer to the list of EventTarget interfaces.

---
 Source/WebCore/dom/EventTargetFactory.in | 1 +
 1 file changed, 1 insertion(+)

diff --git a/Source/WebCore/dom/EventTargetFactory.in b/Source/WebCore/dom/EventTargetFactory.in
index 8ff280f..a0599dc 100644
--- a/Source/WebCore/dom/EventTargetFactory.in
+++ b/Source/WebCore/dom/EventTargetFactory.in
@@ -33,6 +33,7 @@ RTCDTMFSender conditional=MEDIA_STREAM
 RTCPeerConnection conditional=MEDIA_STREAM
 SharedWorker conditional=SHARED_WORKERS
 SharedWorkerGlobalScope conditional=SHARED_WORKERS
+SourceBuffer conditional=MEDIA_SOURCE
 SourceBufferList conditional=MEDIA_SOURCE
 SpeechRecognition conditional=SCRIPTED_SPEECH
 SpeechSynthesisUtterance conditional=SPEECH_SYNTHESIS

From f4e492905ba0153bda4136d8741cdc715db32084 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 20 Nov 2014 18:43:24 +0100
Subject: [PATCH 61/68] Rename MediaSource interface to remove the webkit
 prefix.

---
 Source/WebCore/Modules/mediasource/MediaSource.idl | 1 -
 1 file changed, 1 deletion(-)

diff --git a/Source/WebCore/Modules/mediasource/MediaSource.idl b/Source/WebCore/Modules/mediasource/MediaSource.idl
index ae6f769..da32bb9 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.idl
+++ b/Source/WebCore/Modules/mediasource/MediaSource.idl
@@ -39,7 +39,6 @@ enum EndOfStreamError {
     EventTarget,
     Constructor,
     ConstructorCallWith=ScriptExecutionContext,
-    InterfaceName=WebKitMediaSource
 ] interface MediaSource {
     // All the source buffers created by this object.
     readonly attribute SourceBufferList sourceBuffers;

From c7bd1ef0f1135223f259564af7600fd73832ff0c Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 20 Nov 2014 18:43:46 +0100
Subject: [PATCH 62/68] Fix missing symbols.

---
 Source/WebCore/Modules/mediasource/MediaSource.cpp | 10 ++++++++++
 1 file changed, 10 insertions(+)

diff --git a/Source/WebCore/Modules/mediasource/MediaSource.cpp b/Source/WebCore/Modules/mediasource/MediaSource.cpp
index f433503..e54951e 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.cpp
+++ b/Source/WebCore/Modules/mediasource/MediaSource.cpp
@@ -810,6 +810,16 @@ void MediaSource::stop()
     m_private.clear();
 }
 
+EventTargetData* MediaSource::eventTargetData()
+{
+    return &m_eventTargetData;
+}
+
+EventTargetData* MediaSource::ensureEventTargetData()
+{
+    return &m_eventTargetData;
+}
+
 void MediaSource::onReadyStateChange(const AtomicString& oldState, const AtomicString& newState)
 {
     if (isOpen()) {

From e4baa6f9b0d6b9985301249965da4eda7e76f474 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 20 Nov 2014 18:44:03 +0100
Subject: [PATCH 63/68] Add some logging when loading a media source.

---
 .../WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp  | 1 +
 1 file changed, 1 insertion(+)

diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
index bb7aa9e..637aeee 100644
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
@@ -342,6 +342,7 @@ void MediaPlayerPrivateGStreamer::load(const String& urlString)
 #if ENABLE(MEDIA_SOURCE)
 void MediaPlayerPrivateGStreamer::load(const String& url, MediaSourcePrivateClient* mediaSource)
 {
+    LOG_MEDIA_MESSAGE("Trying to open a mediasource");
     String mediasourceUri = String::format("mediasource%s", url.utf8().data());
     m_mediaSource = mediaSource;
     load(mediasourceUri);

From 937989b7886f78427b79abfc2d1c8dc1d8375af7 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 4 Dec 2014 11:36:29 +0100
Subject: [PATCH 64/68] The need-key event could come as an element or message
 application.

---
 .../WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp  | 1 +
 1 file changed, 1 insertion(+)

diff --git a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
index 637aeee..32d67ef 100644
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
@@ -810,6 +810,7 @@ void MediaPlayerPrivateGStreamer::handleSyncMessage(GstMessage* message)
 {
     switch (GST_MESSAGE_TYPE(message)) {
         case GST_MESSAGE_ELEMENT:
+        case GST_MESSAGE_APPLICATION:
         {
 #if ENABLE(ENCRYPTED_MEDIA) || ENABLE(ENCRYPTED_MEDIA_V2)
             const GstStructure* s = gst_message_get_structure (message);

From eee876b1464b7975fa8e304eaea71fff8cf6bbab Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Thu, 4 Dec 2014 11:39:44 +0100
Subject: [PATCH 65/68] Do not try to generate the challenge ourself. Indeed
 PlayReady has a lot of different versions and ways to send the challenge
 request. What we get here from Discretix can depend on each file. We provide
 the data to the application and it is the application's responsibility to
 format the challenge properly. Also the acknowledge seems to always be in 2
 stages. The Discretix library continues marking that it needs and acknowledge
 event after we received it. Track the current state with a member variable.

---
 .../graphics/gstreamer/CDMSessionGStreamer.cpp     | 29 ++++++++++------------
 .../graphics/gstreamer/CDMSessionGStreamer.h       |  1 +
 2 files changed, 14 insertions(+), 16 deletions(-)

diff --git a/Source/WebCore/platform/graphics/gstreamer/CDMSessionGStreamer.cpp b/Source/WebCore/platform/graphics/gstreamer/CDMSessionGStreamer.cpp
index 25842fc..befd40b 100644
--- a/Source/WebCore/platform/graphics/gstreamer/CDMSessionGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/CDMSessionGStreamer.cpp
@@ -93,16 +93,15 @@ PassRefPtr<Uint8Array> CDMSessionGStreamer::generateKeyRequest(const String& mim
     // Get License URL
     destinationURL = (const char *) DxDrmStream_GetTextAttribute (m_DxDrmStream, DX_ATTR_SILENT_URL, DX_ACTIVE_CONTENT);
     
-    StringBuilder builder;
-    builder.appendLiteral ("challenge=");
-    builder.append ((const char *)challenge);
-    builder.appendLiteral ("\n");
+    GST_DEBUG ("destination URL : %s", destinationURL.utf8 ().data ());
+    GST_MEMDUMP ("generated license request :", (const guint8 *) challenge, challenge_length);
     
-    g_free (challenge);
+    PassRefPtr<Uint8Array> result = Uint8Array::create(reinterpret_cast<const unsigned char *> (challenge), challenge_length);
     
-    GST_MEMDUMP ("generated license request :", (const guint8 *) builder.characters8 (), builder.length ());
+    g_free (challenge);
     
-    PassRefPtr<Uint8Array> result = Uint8Array::create(reinterpret_cast<const unsigned char *>(builder.characters8 ()), builder.length ());
+    // This is the first stage of license aquisition
+    m_waitAck = false;
     
     return result;
 }
@@ -123,27 +122,25 @@ bool CDMSessionGStreamer::update(Uint8Array* key, RefPtr<Uint8Array>& nextMessag
       return false;
     }
     
-    if (isAckRequired) {
+    // We need to trak our state on our own as Discretix library seem to set isAckRequired to true even when processing the ack response..
+    if (!m_waitAck && isAckRequired) {
       guint32 challenge_length = MAX_CHALLENGE_LEN;
       gpointer challenge = g_malloc0 (challenge_length);
       
       status = DxDrmClient_GetLicenseAcq_GenerateAck (&responseResult, challenge, (DxUint32 *) &challenge_length);
       if (status != DX_SUCCESS) {
-        GST_WARNING ("failed generating license ack challenge (%d)", status);
+        GST_WARNING ("failed generating license ack challenge (%d) response result %p", status, responseResult);
         g_free (challenge);
         return false;
       }
       
-      StringBuilder builder;
-      builder.appendLiteral ("challenge=");
-      builder.append ((const char *)challenge);
-      builder.appendLiteral ("\n");
+      GST_MEMDUMP ("generated license ack request :", (const guint8 *) challenge, challenge_length);
       
-      g_free (challenge);
+      nextMessage = Uint8Array::create(reinterpret_cast<const unsigned char *> (challenge), challenge_length);
       
-      GST_MEMDUMP ("generated license ack request :", (const guint8 *) builder.characters8 (), builder.length ());
+      g_free (challenge);
       
-      nextMessage = Uint8Array::create(reinterpret_cast<const unsigned char *>(builder.characters8 ()), builder.length ());
+      m_waitAck = true;
       
       return false;
     }
diff --git a/Source/WebCore/platform/graphics/gstreamer/CDMSessionGStreamer.h b/Source/WebCore/platform/graphics/gstreamer/CDMSessionGStreamer.h
index b99ce6c..d350131 100644
--- a/Source/WebCore/platform/graphics/gstreamer/CDMSessionGStreamer.h
+++ b/Source/WebCore/platform/graphics/gstreamer/CDMSessionGStreamer.h
@@ -55,6 +55,7 @@ class CDMSessionGStreamer : public CDMSession {
     MediaPlayerPrivateGStreamer* m_parent;
     CDMSessionClient* m_client;
     String m_sessionId;
+    bool m_waitAck;
 
 #if USE(DXDRM)
     HDxDrmStream m_DxDrmStream;

From 9ba2fe3bfcc476f10352c2cc0df58247daccfe54 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 5 Dec 2014 18:59:45 +0100
Subject: [PATCH 66/68] Make sure we define the event listeners.

---
 Source/WebCore/Modules/mediasource/MediaSource.h   | 4 ++++
 Source/WebCore/Modules/mediasource/MediaSource.idl | 4 ++++
 2 files changed, 8 insertions(+)

diff --git a/Source/WebCore/Modules/mediasource/MediaSource.h b/Source/WebCore/Modules/mediasource/MediaSource.h
index 20de1cc..5330a87 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.h
+++ b/Source/WebCore/Modules/mediasource/MediaSource.h
@@ -107,6 +107,10 @@ class MediaSource : public MediaSourcePrivateClient, public ActiveDOMObject, pub
     virtual ScriptExecutionContext* scriptExecutionContext() const;
     virtual void refEventTarget() { ref(); }
     virtual void derefEventTarget() { deref(); }
+    
+    DEFINE_ATTRIBUTE_EVENT_LISTENER(sourceopen);
+    DEFINE_ATTRIBUTE_EVENT_LISTENER(sourceended);
+    DEFINE_ATTRIBUTE_EVENT_LISTENER(sourceclose);
 
     // URLRegistrable interface
     virtual URLRegistry& registry() const OVERRIDE;
diff --git a/Source/WebCore/Modules/mediasource/MediaSource.idl b/Source/WebCore/Modules/mediasource/MediaSource.idl
index da32bb9..500f0a9 100644
--- a/Source/WebCore/Modules/mediasource/MediaSource.idl
+++ b/Source/WebCore/Modules/mediasource/MediaSource.idl
@@ -56,6 +56,10 @@ enum EndOfStreamError {
     [RaisesException] void endOfStream(optional EndOfStreamError error);
 
     static boolean isTypeSupported (DOMString type);
+    
+    attribute EventListener onsourceopen;
+    attribute EventListener onsourceended;
+    attribute EventListener onsourceclose;
 
     // EventTarget interface
     void addEventListener(DOMString type,

From e4a6dcd7537d1beccda5f3ad2d222a88508a96db Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 5 Dec 2014 18:59:58 +0100
Subject: [PATCH 67/68] Make sure we define the event listeners.

---
 Source/WebCore/Modules/mediasource/SourceBuffer.h   |  4 ++++
 Source/WebCore/Modules/mediasource/SourceBuffer.idl | 13 +++++++++++++
 2 files changed, 17 insertions(+)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.h b/Source/WebCore/Modules/mediasource/SourceBuffer.h
index 1d4bcb9..fc698f6 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.h
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.h
@@ -108,6 +108,10 @@ class SourceBuffer : public RefCounted<SourceBuffer>, public ActiveDOMObject, pu
     virtual EventTargetData* eventTargetData() { return &m_eventTargetData; }
     virtual EventTargetData* ensureEventTargetData() { return &m_eventTargetData; }
 
+    DEFINE_ATTRIBUTE_EVENT_LISTENER(update);
+    DEFINE_ATTRIBUTE_EVENT_LISTENER(updatestart);
+    DEFINE_ATTRIBUTE_EVENT_LISTENER(updateend);
+
     using RefCounted<SourceBuffer>::ref;
     using RefCounted<SourceBuffer>::deref;
 
diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.idl b/Source/WebCore/Modules/mediasource/SourceBuffer.idl
index 45a465b..decb8b7 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.idl
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.idl
@@ -57,5 +57,18 @@
     [Conditional=VIDEO_TRACK] readonly attribute AudioTrackList audioTracks;
     [Conditional=VIDEO_TRACK] readonly attribute VideoTrackList videoTracks;
     [Conditional=VIDEO_TRACK] readonly attribute TextTrackList textTracks;
+
+    attribute EventListener onupdate;
+    attribute EventListener onupdatestart;
+    attribute EventListener onupdateend;
+
+    // EventTarget interface
+    void addEventListener(DOMString type,
+                          EventListener listener,
+                          optional boolean useCapture);
+    void removeEventListener(DOMString type,
+                             EventListener listener,
+                             optional boolean useCapture);
+    [RaisesException] boolean dispatchEvent(Event event);
 };
 

From 94a550e279667469434df62c47ccc075d1277048 Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Fri, 5 Dec 2014 19:00:11 +0100
Subject: [PATCH 68/68] Make sure we define the event listeners.

---
 Source/WebCore/Modules/mediasource/SourceBufferList.h   |  3 +++
 Source/WebCore/Modules/mediasource/SourceBufferList.idl | 12 ++++++++++++
 2 files changed, 15 insertions(+)

diff --git a/Source/WebCore/Modules/mediasource/SourceBufferList.h b/Source/WebCore/Modules/mediasource/SourceBufferList.h
index 8ef3878..fad0915 100644
--- a/Source/WebCore/Modules/mediasource/SourceBufferList.h
+++ b/Source/WebCore/Modules/mediasource/SourceBufferList.h
@@ -71,6 +71,9 @@ class SourceBufferList : public RefCounted<SourceBufferList>, public ScriptWrapp
     virtual EventTargetData* eventTargetData() { return &m_eventTargetData; }
     virtual EventTargetData* ensureEventTargetData() { return &m_eventTargetData; }
 
+    DEFINE_ATTRIBUTE_EVENT_LISTENER(addsourcebuffer);
+    DEFINE_ATTRIBUTE_EVENT_LISTENER(removesourcebuffer);
+
     using RefCounted<SourceBufferList>::ref;
     using RefCounted<SourceBufferList>::deref;
 
diff --git a/Source/WebCore/Modules/mediasource/SourceBufferList.idl b/Source/WebCore/Modules/mediasource/SourceBufferList.idl
index d3b36df..f44326c 100644
--- a/Source/WebCore/Modules/mediasource/SourceBufferList.idl
+++ b/Source/WebCore/Modules/mediasource/SourceBufferList.idl
@@ -39,5 +39,17 @@
 ] interface SourceBufferList : EventTarget {
     readonly attribute unsigned long length;
     getter SourceBuffer item(unsigned long index);
+    
+    attribute EventListener onaddsourcebuffer;
+    attribute EventListener onremovesourcebuffer;
+
+    // EventTarget interface
+    void addEventListener(DOMString type,
+                          EventListener listener,
+                          optional boolean useCapture);
+    void removeEventListener(DOMString type,
+                             EventListener listener,
+                             optional boolean useCapture);
+    [RaisesException] boolean dispatchEvent(Event event);
 };
 

diff --git a/Source/WebCore/platform/Logging.cpp b/Source/WebCore/platform/Logging.cpp
index 4886446..30795cc 100644
--- a/Source/WebCore/platform/Logging.cpp
+++ b/Source/WebCore/platform/Logging.cpp
@@ -52,6 +52,7 @@ WTFLogChannel LogPageCache =         { 0x00008000, "WebCoreLogLevel", WTFLogChan
 WTFLogChannel LogPlatformLeaks =     { 0x00010000, "WebCoreLogLevel", WTFLogChannelOff };
 WTFLogChannel LogResourceLoading =   { 0x00020000, "WebCoreLogLevel", WTFLogChannelOff };
 WTFLogChannel LogAnimations =        { 0x00040000, "WebCoreLogLevel", WTFLogChannelOff };
+WTFLogChannel LogMediaSource =       { 0x00080000, "WebCoreLogLevel", WTFLogChannelOff };
 
 WTFLogChannel LogNetwork =           { 0x00100000, "WebCoreLogLevel", WTFLogChannelOff };
 WTFLogChannel LogFTP =               { 0x00200000, "WebCoreLogLevel", WTFLogChannelOff };
diff --git a/Source/WebCore/platform/Logging.h b/Source/WebCore/platform/Logging.h
index ee9a34e..4e99c51 100644
--- a/Source/WebCore/platform/Logging.h
+++ b/Source/WebCore/platform/Logging.h
@@ -58,6 +58,7 @@ namespace WebCore {
     extern WTFLogChannel LogThreading;
     extern WTFLogChannel LogStorageAPI;
     extern WTFLogChannel LogMedia;
+    extern WTFLogChannel LogMediaSource;
     extern WTFLogChannel LogPlugins;
     extern WTFLogChannel LogArchives;
     extern WTFLogChannel LogProgress;
From 6e673ce8031699de732cfd206e1c430e933b242a Mon Sep 17 00:00:00 2001
From: Julien Moutte <julien@fluendo.com>
Date: Mon, 22 Dec 2014 16:35:09 +0100
Subject: [PATCH] Fix debug logs to not use toString.

---
 Source/WebCore/Modules/mediasource/SourceBuffer.cpp | 14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
index ab27631..c6fab0e 100644
--- a/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
+++ b/Source/WebCore/Modules/mediasource/SourceBuffer.cpp
@@ -327,7 +327,7 @@ void SourceBuffer::removedFromMediaSource()
 
 void SourceBuffer::seekToTime(const MediaTime& time)
 {
-    LOG(MediaSource, "SourceBuffer::seekToTime(%p) - time(%s)", this, toString(time).utf8().data());
+    LOG(MediaSource, "SourceBuffer::seekToTime(%p) - time(%f)", this, time.toDouble ());
 
     for (HashMap<AtomicString, TrackBuffer>::iterator it = m_trackBufferMap.begin(); it != m_trackBufferMap.end(); ++it) {
         TrackBuffer& trackBuffer = it->value;
@@ -527,7 +527,7 @@ void SourceBuffer::sourceBufferPrivateAppendComplete(SourceBufferPrivate*, Appen
         const AtomicString& trackID = it->key;
 
         if (trackBuffer.needsReenqueueing) {
-            LOG(MediaSource, "SourceBuffer::sourceBufferPrivateAppendComplete(%p) - reenqueuing at time (%s)", this, toString(currentMediaTime).utf8().data());
+            LOG(MediaSource, "SourceBuffer::sourceBufferPrivateAppendComplete(%p) - reenqueuing at time (%f)", this, currentMediaTime.toDouble());
             reenqueueMediaForTime(trackBuffer, trackID, currentMediaTime);
         } else
             provideMediaData(trackBuffer, trackID);
@@ -537,7 +537,7 @@ void SourceBuffer::sourceBufferPrivateAppendComplete(SourceBufferPrivate*, Appen
     if (extraMemoryCost() > this->maximumBufferSize())
         m_bufferFull = true;
 
-    LOG(Media, "SourceBuffer::sourceBufferPrivateAppendComplete(%p) - buffered = %s", this, toString(m_buffered->ranges()).utf8().data());
+    LOG(Media, "SourceBuffer::sourceBufferPrivateAppendComplete(%p) - buffered = %f", this, m_buffered->ranges().totalDuration().toDouble());
 }
 
 void SourceBuffer::sourceBufferPrivateDidReceiveRenderingError(SourceBufferPrivate*, int error)
@@ -576,7 +576,7 @@ static PassRefPtr<TimeRanges> removeSamplesFromTrackBuffer(const DecodeOrderSamp
         size_t startBufferSize = trackBuffer.samples.sizeInBytes();
 #endif
         const RefPtr<MediaSample>& sample = it->second;
-        LOG(MediaSource, "SourceBuffer::%s(%p) - removing sample(%s)", logPrefix, buffer, toString(*it->second).utf8().data());
+        LOG(MediaSource, "SourceBuffer::%s(%p) - removing sample(%f)", logPrefix, buffer, sample->duration().toDouble());
 
         // Remove the erased samples from the TrackBuffer sample map.
         trackBuffer.samples.removeSample(sample.get());
@@ -607,7 +607,7 @@ static PassRefPtr<TimeRanges> removeSamplesFromTrackBuffer(const DecodeOrderSamp
 
 void SourceBuffer::removeCodedFrames(const MediaTime& start, const MediaTime& end)
 {
-    LOG(MediaSource, "SourceBuffer::removeCodedFrames(%p) - start(%s), end(%s)", this, toString(start).utf8().data(), toString(end).utf8().data());
+    LOG(MediaSource, "SourceBuffer::removeCodedFrames(%p) - start(%f), end(%f)", this, start.toDouble(), end.toDouble());
 
     // 3.5.9 Coded Frame Removal Algorithm
     // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#sourcebuffer-coded-frame-removal
@@ -671,7 +671,7 @@ void SourceBuffer::removeCodedFrames(const MediaTime& start, const MediaTime& en
     // 4. If buffer full flag equals true and this object is ready to accept more bytes, then set the buffer full flag to false.
     // No-op
 
-    LOG(Media, "SourceBuffer::removeCodedFrames(%p) - buffered = %s", this, toString(m_buffered->ranges()).utf8().data());
+    LOG(Media, "SourceBuffer::removeCodedFrames(%p) - buffered = %f", this, m_buffered->ranges().totalDuration().toDouble());
 }
 
 void SourceBuffer::removeTimerFired(Timer<SourceBuffer>*)
@@ -860,7 +860,7 @@ void SourceBuffer::setActive(bool active)
 
 void SourceBuffer::sourceBufferPrivateDidEndStream(SourceBufferPrivate*, const WTF::AtomicString& error)
 {
-    LOG(MediaSource, "SourceBuffer::sourceBufferPrivateDidEndStream(%p) - result = %s", this, String(error).utf8().data());
+    LOG(MediaSource, "SourceBuffer::sourceBufferPrivateDidEndStream(%p) - result = %s", this, error.string().utf8().data());
 
     if (!isRemoved())
         m_source->streamEndedWithError(error, IgnorableExceptionCode());
